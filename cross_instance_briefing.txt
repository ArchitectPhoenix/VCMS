VCMS Cross-Instance Briefing: Cross-Game Behavioral Phenotypes
================================================================

For: Main Claude theory instance
From: VCMS development instance
Date: 2026-02-13
Status: Internal working results, not publication-ready


WHAT THIS IS
------------

VCMS (Visibility-Cost-Memory-Strain) is a 20-parameter dynamical
model of individual cooperative behavior. It was originally designed
to predict contributions in public goods games with punishment
(PGG-P). Over the last development cycle we extended it to two
additional game formats — PGG without punishment (PGG-N) and the
iterated prisoner's dilemma (IPD) — using a unified engine with
game-specific adapter configs. The same 15 core parameters are
fitted per subject across all three games.

The main finding: subjects who sustain cooperation across different
games converge to the same region of parameter space, despite being
fitted independently in completely different experimental contexts.
This wasn't engineered. It fell out of the fitting.


THE MODEL
---------

Each subject gets 20 parameters organized into subsystems:

  V (Visibility):    alpha, v_rep, v_ref
                     How the subject perceives others' behavior

  C (Cost):          c_base, p_scale
                     Baseline cooperation propensity, punishment scaling

  M (Memory):        inertia
                     Tendency to repeat previous action regardless of input

  S (Strain):        s_dir, s_rate, s_initial, s_frac, s_thresh
                     Accumulated psychological cost of sustained cooperation
                     s_initial = pre-loaded strain (dispositional)
                     s_frac/s_thresh = discharge through punishment (PGG-P only)

  B (Budget):        b_initial, b_depletion_rate, b_replenish_rate, acute_threshold
                     Finite cooperative capacity that depletes from negative
                     experience and replenishes from positive experience

  M_eval:            facilitation_rate
                     How experience shifts the cost evaluation

  H (Horizon):       h_strength, h_start
                     Endgame discounting as known endpoint approaches

  Self-awareness:    v_self_weight, s_exploitation_rate
                     (v4-only, fixed at 0 for current libraries)

The decision rule each round:

  1. V-channel processes group signals into a reference value
  2. c_base sets a baseline contribution intention
  3. Inertia blends with previous action
  4. Strain accumulates from gap between action and reference
  5. Budget depletes/replenishes from experienced outcomes
  6. Affordability = f(budget, strain) gates the contribution
  7. Horizon discount scales down near known endpoint

Same parameters, same engine. The GameConfig adapter handles
structural differences:

  PGG-P:  max_contrib=20, has_punishment=True,  n_signals=4
  PGG-N:  max_contrib=20, has_punishment=False, n_signals=2
  IPD:    max_contrib=1,  has_punishment=False, n_signals=2

For PGG-N and IPD, punishment parameters (p_scale, s_frac, s_thresh)
are fixed since there's no punishment mechanic. That leaves 15 free
parameters fitted per subject.


THE DATA
--------

596 subjects fitted individually across three experimental datasets:

  PGG with punishment (P-experiment)
    Source:  Herrmann, Thöni, Gächter (2008) — 6 cities
    Subjects: 196
    Rounds: 10 per subject, groups of 4, max contribution 20 MUs
    Mean RMSE: 0.049 (normalized to 0-1 scale)

  PGG without punishment (N-experiment)
    Source:  Same study, no-punishment condition — 7 cities
    Subjects: 212
    Rounds: 10 per subject, groups of 4, max contribution 20 MUs
    Mean RMSE: 1.87 raw / 0.093 normalized

    City breakdown:
      Athens 16, Boston 32, Chengdu 20, Istanbul 20,
      Melbourne 20, Samara 80, St. Gallen 24

    Behavioral types:
      Declining:    130 (61%)  — classic cooperation decay
      Stable-high:   21 (10%)  — sustained cooperators
      Stable-low:    23 (11%)  — consistent defectors
      Stable-mid:    23 (11%)  — intermediate
      Rising:        15  (7%)  — increasing cooperation

  Iterated Prisoner's Dilemma
    Source:  Nay & Vorobeychik (2016) — 188 dyads, 100 rounds
    Subjects: 188
    Binary accuracy: 83.5%
    Mean RMSE: 0.333

    Behavioral types:
      Mixed:      87 (46%)
      Mostly-C:   36 (19%)
      Mostly-D:   65 (35%)


THE FINDING: CROSS-GAME PHENOTYPE CONVERGENCE
----------------------------------------------

When we compare parameter profiles across games, a clear pattern
emerges. Here are the mean fitted values for key parameters by
behavioral type:

                     PGG-P     N-exp      N-exp      IPD
                     all      stable-hi  stable-lo  mostly-C
  ---------------------------------------------------------
  c_base             0.675     0.854      0.324      0.702
  inertia            0.223     0.457      0.225      0.316
  s_initial          1.218     0.147      5.238      1.060
  b_initial          3.338     3.825      1.519      3.002
  b_depletion_rate   0.710     0.547      1.036      0.566
  h_strength         0.177     0.109      0.391      0.157

The N-experiment stable-high cooperators and the IPD mostly-C
subjects occupy the same parameter region:

  HIGH c_base (>0.7):         Strong baseline cooperation intention
  HIGH inertia (0.3-0.5):     Committed to previous action pattern
  LOW s_initial (<1.1):       No pre-loaded strain against cooperating
  HIGH b_initial (>3.0):      Large cooperative budget
  LOW b_depletion (0.5-0.6):  Resilient to negative experience
  LOW h_strength (<0.16):     No endgame defection

This is the "committed cooperator" phenotype. These people cooperate
because of who they are, not because the game incentivizes it. The
mechanism is internal commitment (inertia) + low psychological cost
(strain) + resilient capacity (budget).

Compare with N-experiment stable-low subjects (comfortable defectors):

  LOW c_base (0.324):         Low baseline intention
  HIGH s_initial (5.238):     Pre-strained — dispositionally costly
  LOW b_initial (1.519):      Small capacity
  HIGH b_depletion (1.036):   Fragile budget

And compare with declining subjects (disillusioned cooperators):

  HIGH c_base (0.754):        They WANT to cooperate
  HIGH b_depletion (1.062):   But budget drains fast
  LOW b_replenish (0.953):    And doesn't recover
  HIGH h_strength (0.583):    Plus endgame discounting

The declining type is the most common N-experiment profile (61%).
These subjects have cooperative intentions but can't sustain them —
their budget mechanics don't support it. This is mechanistically
distinct from the stable-low subjects, who never intended to
cooperate (high s_initial).


WHY THE P-EXPERIMENT LIBRARY MISSED THIS
-----------------------------------------

The P-experiment library (196 subjects) never discovered the
high-inertia committed cooperator profile. The reason is structural:

In PGG with punishment, cooperation is maintained externally.
Subjects who cooperate in P-experiment do so partly because
punishment keeps group contributions high, which keeps their
experience positive, which keeps their budget full. The optimizer
can explain their behavior with LOW inertia (0.223) — they're
responsive to group norms, not internally committed.

Remove punishment (N-experiment) and ask "who still cooperates?" —
now the optimizer MUST use high inertia to explain sustained
cooperation in the face of declining group contributions. The
P-experiment selection pressure never required this parameter region.

This is why the N-experiment library matters: it populates a region
of parameter space that punishment-based experiments structurally
cannot access.


CROSS-VALIDATION PERFORMANCE
-----------------------------

PGG P-experiment (leave-one-out):
  VCMS:           0.178 RMSE
  Carry-forward:  0.165
  EWA:            0.346

PGG P→N transfer (P-experiment library predicting N-experiment):
  VCMS:           0.254 RMSE
  Carry-forward:  0.280
  Profile-mean:   0.438

The P→N transfer degrades by only 76 basis points vs within-game
LOO. With the N-experiment library now added, transfer should
improve since the library now covers the high-inertia cooperator
basin.


WHAT NO OTHER MODEL DOES
-------------------------

The standard behavioral game theory models each fail on at least
one axis:

  Reinforcement learning (Roth-Erev, EWA):
    Can fit trajectories. Parameters are learning rates and
    attraction weights — not interpretable as psychological
    constructs. Game-specific state representations prevent
    cross-game parameter comparison.

  Type classification (Fischbacher et al.):
    Interpretable but static. "Conditional cooperator" is a label,
    not a mechanism. No dynamics, no prediction of when cooperation
    breaks down, no cross-game transfer.

  Agent-based models:
    Reproduce aggregate patterns (mean contribution declines over
    rounds). Not fitted to individual subjects. Can't distinguish
    the 130 declining subjects from each other.

  Neural networks / deep learning:
    Can fit anything. Explain nothing. No parameter interpretability,
    no cross-game convergence, no mechanistic insight.

VCMS is the only model we're aware of that simultaneously provides:

  1. Individual-level fitting with interpretable parameters
  2. Cross-game parameter convergence on behavioral phenotypes
  3. Mechanistic explanation of WHY trajectories differ

596 individually fitted subjects, three game formats, 15 shared
parameters, and the cooperator phenotypes align across contexts
without the model being told the games are related.


OPEN QUESTIONS
--------------

- Transfer prediction: With the combined 596-subject library, how
  does cross-game prediction perform? (Fit on PGG, predict IPD
  and vice versa.)

- Phenotype stability: Are the parameter clusters (committed
  cooperator, comfortable defector, disillusioned cooperator)
  stable under different fitting initializations?

- The rising type (n=15): These subjects increase cooperation over
  time in N-experiment. The current model fits them worst
  (RMSE=2.94). Is there a missing mechanism (learning? reciprocal
  signaling?) or is 15 subjects just too few to tell?

- v_self_weight and s_exploitation_rate (v4-only parameters):
  Currently fixed at 0. Are there games where they matter?


FILES
-----

  vcms_engine_v4.py          — Unified engine with GameConfig adapter
  v3_library_fitted.json     — 196 PGG-P subjects
  n_library_fitted.json      — 212 PGG-N subjects
  ipd_library_fitted.json    — 188 IPD subjects
  ipd_fit.py                 — Fast forward pass + DE optimizer
  n_experiment_fit.py        — N-experiment fitting (reuses ipd_fit pass)
