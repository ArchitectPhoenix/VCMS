VCMS Cross-Instance Briefing: Cross-Game Behavioral Phenotypes
================================================================

For: Main Claude theory instance
From: VCMS development instance
Date: 2026-02-13
Status: Internal working results, not publication-ready


WHAT THIS IS
------------

VCMS (Visibility-Cost-Memory-Strain) is a 20-parameter dynamical
model of individual cooperative behavior. It was originally designed
to predict contributions in public goods games with punishment
(PGG-P). Over the last development cycle we extended it to two
additional game formats — PGG without punishment (PGG-N) and the
iterated prisoner's dilemma (IPD) — using a unified engine with
game-specific adapter configs. The same 15 core parameters are
fitted per subject across all three games.

The main finding: subjects who sustain cooperation across different
games converge to the same region of parameter space, despite being
fitted independently in completely different experimental contexts.
This wasn't engineered. It fell out of the fitting.


THE MODEL
---------

Each subject gets 20 parameters organized into subsystems:

  V (Visibility):    alpha, v_rep, v_ref
                     How the subject perceives others' behavior

  C (Cost):          c_base, p_scale
                     Baseline cooperation propensity, punishment scaling

  M (Memory):        inertia
                     Tendency to repeat previous action regardless of input

  S (Strain):        s_dir, s_rate, s_initial, s_frac, s_thresh
                     Accumulated psychological cost of sustained cooperation
                     s_initial = pre-loaded strain (dispositional)
                     s_frac/s_thresh = discharge through punishment (PGG-P only)

  B (Budget):        b_initial, b_depletion_rate, b_replenish_rate, acute_threshold
                     Finite cooperative capacity that depletes from negative
                     experience and replenishes from positive experience

  M_eval:            facilitation_rate
                     How experience shifts the cost evaluation

  H (Horizon):       h_strength, h_start
                     Endgame discounting as known endpoint approaches

  Self-awareness:    v_self_weight, s_exploitation_rate
                     (v4-only, fixed at 0 for current libraries)

The decision rule each round:

  1. V-channel processes group signals into a reference value
  2. c_base sets a baseline contribution intention
  3. Inertia blends with previous action
  4. Strain accumulates from gap between action and reference
  5. Budget depletes/replenishes from experienced outcomes
  6. Affordability = f(budget, strain) gates the contribution
  7. Horizon discount scales down near known endpoint

Same parameters, same engine. The GameConfig adapter handles
structural differences:

  PGG-P:  max_contrib=20, has_punishment=True,  n_signals=4
  PGG-N:  max_contrib=20, has_punishment=False, n_signals=2
  IPD:    max_contrib=1,  has_punishment=False, n_signals=2

For PGG-N and IPD, punishment parameters (p_scale, s_frac, s_thresh)
are fixed since there's no punishment mechanic. That leaves 15 free
parameters fitted per subject.


THE DATA
--------

596 subjects fitted individually across three experimental datasets:

  PGG with punishment (P-experiment)
    Source:  Herrmann, Thöni, Gächter (2008) — 6 cities
    Subjects: 196
    Rounds: 10 per subject, groups of 4, max contribution 20 MUs
    Mean RMSE: 0.049 (normalized to 0-1 scale)

  PGG without punishment (N-experiment)
    Source:  Same study, no-punishment condition — 7 cities
    Subjects: 212
    Rounds: 10 per subject, groups of 4, max contribution 20 MUs
    Mean RMSE: 1.87 raw / 0.093 normalized

    City breakdown:
      Athens 16, Boston 32, Chengdu 20, Istanbul 20,
      Melbourne 20, Samara 80, St. Gallen 24

    Behavioral types:
      Declining:    130 (61%)  — classic cooperation decay
      Stable-high:   21 (10%)  — sustained cooperators
      Stable-low:    23 (11%)  — consistent defectors
      Stable-mid:    23 (11%)  — intermediate
      Rising:        15  (7%)  — increasing cooperation

  Iterated Prisoner's Dilemma
    Source:  Nay & Vorobeychik (2016) — 188 dyads, 100 rounds
    Subjects: 188
    Binary accuracy: 83.5%
    Mean RMSE: 0.333

    Behavioral types:
      Mixed:      87 (46%)
      Mostly-C:   36 (19%)
      Mostly-D:   65 (35%)


THE FINDING: CROSS-GAME PHENOTYPE CONVERGENCE
----------------------------------------------

When we compare parameter profiles across games, a clear pattern
emerges. Here are the mean fitted values for key parameters by
behavioral type:

                     PGG-P     N-exp      N-exp      IPD
                     all      stable-hi  stable-lo  mostly-C
  ---------------------------------------------------------
  c_base             0.675     0.854      0.324      0.702
  inertia            0.223     0.457      0.225      0.316
  s_initial          1.218     0.147      5.238      1.060
  b_initial          3.338     3.825      1.519      3.002
  b_depletion_rate   0.710     0.547      1.036      0.566
  h_strength         0.177     0.109      0.391      0.157

The N-experiment stable-high cooperators and the IPD mostly-C
subjects occupy the same parameter region:

  HIGH c_base (>0.7):         Strong baseline cooperation intention
  HIGH inertia (0.3-0.5):     Committed to previous action pattern
  LOW s_initial (<1.1):       No pre-loaded strain against cooperating
  HIGH b_initial (>3.0):      Large cooperative budget
  LOW b_depletion (0.5-0.6):  Resilient to negative experience
  LOW h_strength (<0.16):     No endgame defection

This is the "committed cooperator" phenotype. These people cooperate
because of who they are, not because the game incentivizes it. The
mechanism is internal commitment (inertia) + low psychological cost
(strain) + resilient capacity (budget).

Compare with N-experiment stable-low subjects (comfortable defectors):

  LOW c_base (0.324):         Low baseline intention
  HIGH s_initial (5.238):     Pre-strained — dispositionally costly
  LOW b_initial (1.519):      Small capacity
  HIGH b_depletion (1.036):   Fragile budget

And compare with declining subjects (disillusioned cooperators):

  HIGH c_base (0.754):        They WANT to cooperate
  HIGH b_depletion (1.062):   But budget drains fast
  LOW b_replenish (0.953):    And doesn't recover
  HIGH h_strength (0.583):    Plus endgame discounting

The declining type is the most common N-experiment profile (61%).
These subjects have cooperative intentions but can't sustain them —
their budget mechanics don't support it. This is mechanistically
distinct from the stable-low subjects, who never intended to
cooperate (high s_initial).


WHY THE P-EXPERIMENT LIBRARY MISSED THIS
-----------------------------------------

The P-experiment library (196 subjects) never discovered the
high-inertia committed cooperator profile. The reason is structural:

In PGG with punishment, cooperation is maintained externally.
Subjects who cooperate in P-experiment do so partly because
punishment keeps group contributions high, which keeps their
experience positive, which keeps their budget full. The optimizer
can explain their behavior with LOW inertia (0.223) — they're
responsive to group norms, not internally committed.

Remove punishment (N-experiment) and ask "who still cooperates?" —
now the optimizer MUST use high inertia to explain sustained
cooperation in the face of declining group contributions. The
P-experiment selection pressure never required this parameter region.

This is why the N-experiment library matters: it populates a region
of parameter space that punishment-based experiments structurally
cannot access.


CROSS-VALIDATION PERFORMANCE
-----------------------------

PGG P-experiment (leave-one-out):
  VCMS:           0.178 RMSE
  Carry-forward:  0.165
  EWA:            0.346

PGG P→N transfer (P-experiment library predicting N-experiment):
  VCMS:           0.254 RMSE
  Carry-forward:  0.280
  Profile-mean:   0.438

The P→N transfer degrades by only 76 basis points vs within-game
LOO. With the N-experiment library now added, transfer should
improve since the library now covers the high-inertia cooperator
basin.


WHAT NO OTHER MODEL DOES
-------------------------

The standard behavioral game theory models each fail on at least
one axis:

  Reinforcement learning (Roth-Erev, EWA):
    Can fit trajectories. Parameters are learning rates and
    attraction weights — not interpretable as psychological
    constructs. Game-specific state representations prevent
    cross-game parameter comparison.

  Type classification (Fischbacher et al.):
    Interpretable but static. "Conditional cooperator" is a label,
    not a mechanism. No dynamics, no prediction of when cooperation
    breaks down, no cross-game transfer.

  Agent-based models:
    Reproduce aggregate patterns (mean contribution declines over
    rounds). Not fitted to individual subjects. Can't distinguish
    the 130 declining subjects from each other.

  Neural networks / deep learning:
    Can fit anything. Explain nothing. No parameter interpretability,
    no cross-game convergence, no mechanistic insight.

VCMS is the only model we're aware of that simultaneously provides:

  1. Individual-level fitting with interpretable parameters
  2. Cross-game parameter convergence on behavioral phenotypes
  3. Mechanistic explanation of WHY trajectories differ

596 individually fitted subjects, three game formats, 15 shared
parameters, and the cooperator phenotypes align across contexts
without the model being told the games are related.


UPDATE: NORMALIZED GAME TIME
-----------------------------
(Added after theory instance identified temporal unit mismatch)

PROBLEM: Budget parameters fitted on 10-round PGG games collapsed
when run on 100-round IPD games. b_depletion_rate of 0.7 means
"lose 70% of B-impact per round" — over 10 rounds that's gradual
decline, over 100 rounds it's instant collapse.

FIX: Engine now supports normalized game time. When enabled,
dt = 1/(n_rounds-1) per step. All temporal rates (s_rate,
b_depletion_rate, b_replenish_rate, facilitation_rate) are
multiplied by dt each step. h_start operates in [0,1] game
progress rather than absolute round index.

This subsumes two earlier patches (horizon_scaling, strain_decay)
that were workarounds for the same temporal unit mismatch.

RE-FIT RESULTS:

  P-experiment (176 subjects, dt=1/9):
    Zero RMSE degradation. Rate parameters scale exactly 9.0x.
    Every subject matches v3 quality within 0.001 RMSE.

  N-experiment (212 subjects, dt=1/9):
    Zero RMSE degradation. Same exact 9x scaling.

  IPD (188 subjects, dt=1/99):
    Fitting accuracy improves 83.5% → 88.2% (+4.6%).
    mostly-C accuracy: 96.6%. Budget can now sustain
    100-round cooperation.

IPD TRANSFER WITH NORMALIZED TIME:

  mostly-C accuracy: 17.9% → 67.2% (SP), 70.4% → 81.3% (FP)
  Overall accuracy:  69.2% → 70.7% (SP), 68.9% → 73.1% (FP)
  Trajectory RMSE:   0.341 → 0.309 (SP), 0.336 → 0.286 (FP)

  Budget no longer collapses on 100-round games. The temporal
  normalization specifically fixes the committed cooperator
  failure mode identified by the theory instance.


UPDATE: PHENOTYPE GEOMETRY ANALYSIS
-------------------------------------
(576 subjects × 15 parameters × 3 games, all normalized time)

THE QUESTION: Do cooperator phenotypes converge to the same
parameter-space region across games, or was the alignment an
artifact of game-specific fitting?

METHOD: Unified cooperation axis:
  HIGH: P:cooperator+enforcer, N:stable-high, IPD:mostly-C
  LOW:  P:free-rider+antisocial, N:stable-low, IPD:mostly-D
  MID:  everything else

RESULT 1 — ALIGNMENT TABLE (mean parameter values):

                    PGG-P   PGG-N   IPD    spread
  HIGH cooperators:
    c_base           0.77    0.85   0.71    0.15
    inertia          0.28    0.46   0.41    0.18
    s_initial        0.77    0.15   0.72    0.63
    b_initial        3.49    3.83   3.49    0.34
    h_strength       0.10    0.11   0.14    0.05

  LOW cooperators:
    c_base           0.33    0.32   0.57    0.25
    inertia          0.22    0.23   0.35    0.13
    s_initial        3.76    5.24   3.76    1.48
    b_initial        2.32    1.52   3.10    1.58
    h_strength       0.63    0.39   0.50    0.24

The signature holds: high cooperators converge on high c_base,
high inertia, low s_initial, high b_initial, low h_strength.
Low cooperators converge on the opposite. The cross-game spread
on c_base (0.15 for HIGH) is much smaller than the phenotype gap
(0.77 HIGH vs 0.33 LOW = 0.44 difference).

RESULT 2 — DISTANCE ANALYSIS (z-scored parameter space):

  Same phenotype, cross-game centroid distance:    1.64
  Different phenotype, same game centroid distance: 2.23
  Different phenotype, cross-game:                 2.38

  Separation ratio: 1.36x

  Phenotype identity explains MORE of the parameter-space structure
  than game identity. A high cooperator in PGG-P is closer to a
  high cooperator in IPD than to a low cooperator in PGG-P.

RESULT 3 — CROSS-GAME DISCRIMINANT ANALYSIS:

  Train on one game, classify subjects from another:

                 Train→   PGG-P   PGG-N   IPD
    Test PGG-P:           (80%)    38%    41%
    Test PGG-N:            29%    (90%)   62%
    Test IPD:              41%     55%   (67%)

  Chance baseline: 33%. Cross-game accuracy averages 44%.

  N→IPD transfer is strongest (62%) — consistent with both being
  no-punishment games with the same V-channel structure.

  P→others is weakest (29-41%) — punishment creates a different
  selection pressure on parameters, so the P-experiment phenotype
  boundaries don't map cleanly to no-punishment games.

  Top discriminating parameters (LD1 loadings):
    c_base (-1.35) and h_strength (+1.31) carry most of the
    phenotype signal. s_initial, v_ref, and inertia contribute.

RESULT 4 — BUDGET CURVE SHAPE:

  Replenish/deplete ratio by phenotype:
    HIGH: 1.50-2.49 across games (replenish > deplete)
    MID:  1.01-2.56 (variable)
    LOW:  0.67-1.34 (deplete ≥ replenish)

  N-experiment LOW cooperators have ratio 0.67 — budget
  systematically drains. This is the "disillusioned cooperator"
  mechanism: they want to cooperate (c_base=0.32 is low but
  s_initial=5.24 is the real story — massive pre-loaded strain)
  and their budget can't sustain it.

INTERPRETATION:

The phenotype geometry is real but noisy. The clusters don't
collapse onto each other perfectly — game context still matters.
But the dominant axis of variation in 15-dimensional parameter
space is cooperation type, not game format. This is the
scale-invariance claim: normalized time makes the parameter
space commensurate, and in that commensurate space, cooperators
look like cooperators regardless of whether the game had 10
rounds, 100 rounds, punishment, or binary actions.

The weakest link is P→others transfer. Punishment creates a
structurally different optimization landscape (s_frac, s_thresh,
p_scale are all active) that shifts where the other 15 parameters
settle. This is why the P-experiment library was a poor starting
point for N-experiment prediction — it's not just missing the
high-inertia cooperator, it's fitting parameters under a different
constraint set.


OPEN QUESTIONS (UPDATED)
-------------------------

- Combined library transfer: The full 576-subject v4 library
  in normalized time should be tested for combined cross-game
  prediction. Particularly: does adding N-experiment subjects
  to the P-experiment library improve IPD transfer?

- The rising type (n=15): Still the hardest to fit. May need
  a learning/reciprocity mechanism not in the current model.

- V-channel for dyadic games: Theory instance noted that IPD
  should preserve partner-specific sequential information, not
  just aggregate cooperation level. TFT's 63%→81% jump on FP
  proves partner sequence matters. This is architecturally
  independent from temporal normalization.

- Parameter-space phenotyping of non-experimental data:
  Normalized time makes parameters scale-invariant. In principle,
  any cooperative trajectory (regardless of time granularity) can
  be fitted and mapped into the same parameter space. The question
  is identifiability: can budget parameters be recovered from
  contribution data alone, without the others_mean signal?


FILES (UPDATED)
---------------

  vcms_engine_v4.py              — Engine with normalized_time support
  v4_library_fitted.json         — 176 PGG-P subjects (normalized time)
  v4_n_library_fitted.json       — 212 PGG-N subjects (normalized time)
  v4_ipd_library_fitted.json     — 188 IPD subjects (normalized time)
  normalized_fit.py              — Shared fast forward pass + fitting
  refit_p_normalized.py          — P-experiment re-fit script
  refit_n_normalized.py          — N-experiment re-fit script
  refit_ipd_normalized.py        — IPD re-fit script
  ipd_transfer_test_v4.py        — V4 normalized transfer test
  phenotype_geometry.py          — Cross-library geometry analysis

  (Legacy v3 libraries preserved for comparison:
   v3_library_fitted.json, n_library_fitted.json, ipd_library_fitted.json)
