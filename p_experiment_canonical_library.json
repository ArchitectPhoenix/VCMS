{
  "701": {
    "params": {
      "p_base": 0.12288072674429756,
      "p_scale": 4.011766958541401,
      "gap_weight": 0.5487044522633747,
      "gap_direction": -0.7687323186382227,
      "retaliation_w": 0.9201598915622797,
      "strain_rate": 2.0394985037088276,
      "strain_initial": 1.2486671825629294,
      "discharge_thresh": 3.3431286160394644,
      "discharge_frac": 0.4592255991150377,
      "inertia_w": 0.03188043288503123,
      "decay_rate": 0.3693719565299357
    },
    "params_list": [
      0.12288072674429756,
      4.011766958541401,
      0.5487044522633747,
      -0.7687323186382227,
      0.9201598915622797,
      2.0394985037088276,
      1.2486671825629294,
      3.3431286160394644,
      0.4592255991150377,
      0.03188043288503123,
      0.3693719565299357
    ],
    "actual": [
      0,
      3,
      10,
      7,
      3,
      3,
      4,
      4,
      6,
      3
    ],
    "predicted": [
      1,
      3,
      8,
      7,
      3,
      3,
      5,
      3,
      7,
      3
    ],
    "rmse": 0.8944271909999159,
    "method": "de_full_11D",
    "n_free": 11,
    "null_channels": [
      "gap",
      "retaliation",
      "inertia"
    ],
    "population": "Samara",
    "session": "Samara_P_S1",
    "knockout_active_channels": [
      "strain"
    ],
    "knockout_null_channels": [
      "no_gap",
      "no_retaliation",
      "no_inertia"
    ],
    "active_channels": [
      "strain"
    ],
    "gap_classification": "antisocial",
    "behavioral_profile": "antisocial-controller",
    "contribution_trajectory": [
      1,
      0,
      2,
      0,
      0,
      20,
      0,
      0,
      1,
      0
    ],
    "punishment_sent_trajectory": [
      0,
      3,
      10,
      7,
      3,
      3,
      4,
      4,
      6,
      3
    ],
    "punishment_received_trajectory": [
      5,
      10,
      5,
      9,
      9,
      1,
      8,
      7,
      6,
      7
    ],
    "total_voluntary_spend_trajectory": [
      1,
      3,
      12,
      7,
      3,
      23,
      4,
      4,
      7,
      3
    ],
    "others_mean_trajectory": [
      11.0,
      12.7,
      15.0,
      11.7,
      5.7,
      3.7,
      9.7,
      10.0,
      14.0,
      9.7
    ],
    "mean_contribution": 2.4,
    "mean_punishment_sent": 4.3,
    "mean_punishment_received": 6.7,
    "mean_total_voluntary_spend": 6.7,
    "antisocial_punishment_total": 40,
    "prosocial_punishment_total": 3,
    "antisocial_ratio": 0.93,
    "group_id": "701"
  },
  "702": {
    "params": {
      "p_base": 0.027910636295437163,
      "p_scale": 8.015372265777671,
      "gap_weight": 0.3397325182588058,
      "gap_direction": -0.14735079215746993,
      "retaliation_w": 0.9799898286845556,
      "strain_rate": 0.34577157735750985,
      "strain_initial": 1.4313850863364905,
      "discharge_thresh": 2.142982200562425,
      "discharge_frac": 0.2507813728215848,
      "inertia_w": -0.14273934534490518,
      "decay_rate": 0.11390201987171239
    },
    "params_list": [
      0.027910636295437163,
      8.015372265777671,
      0.3397325182588058,
      -0.14735079215746993,
      0.9799898286845556,
      0.34577157735750985,
      1.4313850863364905,
      2.142982200562425,
      0.2507813728215848,
      -0.14273934534490518,
      0.11390201987171239
    ],
    "actual": [
      0,
      3,
      1,
      5,
      7,
      3,
      0,
      1,
      3,
      0
    ],
    "predicted": [
      0,
      3,
      1,
      5,
      7,
      2,
      0,
      1,
      4,
      0
    ],
    "rmse": 0.4472135954999579,
    "method": "de_full_11D",
    "n_free": 11,
    "null_channels": [
      "gap",
      "inertia"
    ],
    "population": "Samara",
    "session": "Samara_P_S1",
    "knockout_active_channels": [
      "retaliation",
      "strain"
    ],
    "knockout_null_channels": [
      "no_gap",
      "no_inertia"
    ],
    "active_channels": [
      "retaliation",
      "strain"
    ],
    "gap_classification": "neutral",
    "behavioral_profile": "antisocial-controller",
    "contribution_trajectory": [
      0,
      5,
      20,
      0,
      2,
      1,
      4,
      0,
      10,
      0
    ],
    "punishment_sent_trajectory": [
      0,
      3,
      1,
      5,
      7,
      3,
      0,
      1,
      3,
      0
    ],
    "punishment_received_trajectory": [
      5,
      3,
      10,
      9,
      5,
      1,
      2,
      9,
      0,
      8
    ],
    "total_voluntary_spend_trajectory": [
      0,
      8,
      21,
      5,
      9,
      4,
      4,
      1,
      13,
      0
    ],
    "others_mean_trajectory": [
      11.3,
      11.0,
      9.0,
      11.7,
      5.0,
      10.0,
      8.3,
      10.0,
      11.0,
      9.7
    ],
    "mean_contribution": 4.2,
    "mean_punishment_sent": 2.3,
    "mean_punishment_received": 5.2,
    "mean_total_voluntary_spend": 6.5,
    "antisocial_punishment_total": 14,
    "prosocial_punishment_total": 9,
    "antisocial_ratio": 0.609,
    "group_id": "701"
  },
  "703": {
    "params": {
      "p_base": 0.012468728981126664,
      "p_scale": 25.572214472134846,
      "gap_weight": 0.4722845240126723,
      "gap_direction": 0.31386582532717267,
      "retaliation_w": 0.8546822631526615,
      "strain_rate": 0.3070172670117255,
      "strain_initial": 3.7061804185200886,
      "discharge_thresh": 4.2609013777869755,
      "discharge_frac": 0.36345909904169954,
      "inertia_w": -0.022007836138734194,
      "decay_rate": 0.41244321454684774
    },
    "params_list": [
      0.012468728981126664,
      25.572214472134846,
      0.4722845240126723,
      0.31386582532717267,
      0.8546822631526615,
      0.3070172670117255,
      3.7061804185200886,
      4.2609013777869755,
      0.36345909904169954,
      -0.022007836138734194,
      0.41244321454684774
    ],
    "actual": [
      1,
      0,
      0,
      0,
      0,
      0,
      0,
      2,
      0,
      0
    ],
    "predicted": [
      1,
      0,
      0,
      0,
      0,
      0,
      0,
      2,
      0,
      0
    ],
    "rmse": 0.0,
    "method": "de_full_11D",
    "n_free": 11,
    "null_channels": [
      "gap",
      "strain",
      "inertia"
    ],
    "population": "Samara",
    "session": "Samara_P_S1",
    "knockout_active_channels": [
      "retaliation"
    ],
    "knockout_null_channels": [
      "no_gap",
      "no_strain",
      "no_inertia"
    ],
    "active_channels": [
      "retaliation"
    ],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperator",
    "contribution_trajectory": [
      20,
      20,
      20,
      20,
      20,
      20,
      19,
      20,
      20,
      20
    ],
    "punishment_sent_trajectory": [
      1,
      0,
      0,
      0,
      0,
      0,
      0,
      2,
      0,
      0
    ],
    "punishment_received_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      1,
      0,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      21,
      20,
      20,
      20,
      20,
      20,
      19,
      22,
      20,
      20
    ],
    "others_mean_trajectory": [
      15.7,
      20.0,
      19.7,
      19.7,
      19.7,
      19.7,
      19.7,
      19.3,
      20.0,
      20.0
    ],
    "mean_contribution": 19.9,
    "mean_punishment_sent": 0.3,
    "mean_punishment_received": 0.1,
    "mean_total_voluntary_spend": 20.2,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 3,
    "antisocial_ratio": 0.0,
    "group_id": "704"
  },
  "704": {
    "params": {
      "p_base": 0.19294299214462274,
      "p_scale": 1.973228540975235,
      "gap_weight": 0.0,
      "gap_direction": 0.019150235768730095,
      "retaliation_w": 0.0,
      "strain_rate": 2.5898730496838223,
      "strain_initial": 3.6581751544858365,
      "discharge_thresh": 2.2284775690153054,
      "discharge_frac": 0.6068135664665247,
      "inertia_w": 0.0,
      "decay_rate": 0.585224802780552
    },
    "params_list": [
      0.19294299214462274,
      1.973228540975235,
      0.0,
      0.019150235768730095,
      0.0,
      2.5898730496838223,
      3.6581751544858365,
      2.2284775690153054,
      0.6068135664665247,
      0.0,
      0.585224802780552
    ],
    "actual": [
      2,
      2,
      0,
      0,
      0,
      0,
      0,
      2,
      0,
      0
    ],
    "predicted": [
      2,
      2,
      0,
      0,
      0,
      0,
      0,
      2,
      0,
      0
    ],
    "rmse": 0.0,
    "method": "de_channel_selective",
    "n_free": 8,
    "null_channels": [
      "gap",
      "retaliation",
      "inertia"
    ],
    "population": "Samara",
    "session": "Samara_P_S1",
    "knockout_active_channels": [
      "strain"
    ],
    "knockout_null_channels": [
      "no_gap",
      "no_retaliation",
      "no_inertia"
    ],
    "active_channels": [
      "strain"
    ],
    "gap_classification": "gap-null",
    "behavioral_profile": "punitive-free-rider",
    "contribution_trajectory": [
      15,
      10,
      0,
      1,
      0,
      2,
      0,
      5,
      0,
      0
    ],
    "punishment_sent_trajectory": [
      2,
      2,
      0,
      0,
      0,
      0,
      0,
      2,
      0,
      0
    ],
    "punishment_received_trajectory": [
      11,
      5,
      1,
      0,
      0,
      2,
      2,
      1,
      1,
      4
    ],
    "total_voluntary_spend_trajectory": [
      17,
      12,
      0,
      1,
      0,
      2,
      0,
      7,
      0,
      0
    ],
    "others_mean_trajectory": [
      5.0,
      1.0,
      1.7,
      3.3,
      1.0,
      0.3,
      0.3,
      0.7,
      0.0,
      1.7
    ],
    "mean_contribution": 3.3,
    "mean_punishment_sent": 0.6,
    "mean_punishment_received": 2.7,
    "mean_total_voluntary_spend": 3.9,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 6,
    "antisocial_ratio": 0.0,
    "group_id": "702"
  },
  "705": {
    "params": {
      "p_base": 0.1093990556401877,
      "p_scale": 16.30750108846867,
      "gap_weight": 0.94357465258566,
      "gap_direction": 0.8238517957300981,
      "retaliation_w": 0.0,
      "strain_rate": 0.17440450955747733,
      "strain_initial": 1.2017542599538955,
      "discharge_thresh": 1.249706560870629,
      "discharge_frac": 0.1637589801530001,
      "inertia_w": 0.0,
      "decay_rate": 0.6594462039831394
    },
    "params_list": [
      0.1093990556401877,
      16.30750108846867,
      0.94357465258566,
      0.8238517957300981,
      0.0,
      0.17440450955747733,
      1.2017542599538955,
      1.249706560870629,
      0.1637589801530001,
      0.0,
      0.6594462039831394
    ],
    "actual": [
      6,
      6,
      3,
      10,
      8,
      0,
      4,
      8,
      4,
      8
    ],
    "predicted": [
      7,
      6,
      2,
      10,
      7,
      2,
      4,
      8,
      5,
      8
    ],
    "rmse": 0.8944271909999159,
    "method": "de_channel_selective",
    "n_free": 9,
    "null_channels": [
      "retaliation",
      "inertia"
    ],
    "population": "Samara",
    "session": "Samara_P_S1",
    "knockout_active_channels": [
      "gap",
      "strain"
    ],
    "knockout_null_channels": [
      "no_retaliation",
      "no_inertia"
    ],
    "active_channels": [
      "gap",
      "strain"
    ],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperative-enforcer",
    "contribution_trajectory": [
      15,
      15,
      10,
      15,
      10,
      0,
      10,
      15,
      15,
      10
    ],
    "punishment_sent_trajectory": [
      6,
      6,
      3,
      10,
      8,
      0,
      4,
      8,
      4,
      8
    ],
    "punishment_received_trajectory": [
      0,
      2,
      0,
      4,
      2,
      9,
      1,
      1,
      3,
      2
    ],
    "total_voluntary_spend_trajectory": [
      21,
      21,
      13,
      25,
      18,
      0,
      14,
      23,
      19,
      18
    ],
    "others_mean_trajectory": [
      6.3,
      7.7,
      12.3,
      6.7,
      2.3,
      10.3,
      6.3,
      5.0,
      9.3,
      6.3
    ],
    "mean_contribution": 11.5,
    "mean_punishment_sent": 5.7,
    "mean_punishment_received": 2.4,
    "mean_total_voluntary_spend": 17.2,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 57,
    "antisocial_ratio": 0.0,
    "group_id": "701"
  },
  "706": {
    "params": {
      "p_base": 0.12943513974996756,
      "p_scale": 3.9582151756544555,
      "gap_weight": 0.7773716166083374,
      "gap_direction": 0.7826591220254098,
      "retaliation_w": 0.5853484126937403,
      "strain_rate": 2.7800624420810767,
      "strain_initial": 9.819506671326572,
      "discharge_thresh": 3.5566193675707103,
      "discharge_frac": 0.23296122661268476,
      "inertia_w": 0.10391350257315894,
      "decay_rate": 0.9154452588192081
    },
    "params_list": [
      0.12943513974996756,
      3.9582151756544555,
      0.7773716166083374,
      0.7826591220254098,
      0.5853484126937403,
      2.7800624420810767,
      9.819506671326572,
      3.5566193675707103,
      0.23296122661268476,
      0.10391350257315894,
      0.9154452588192081
    ],
    "actual": [
      3,
      6,
      6,
      6,
      6,
      1,
      0,
      2,
      5,
      1
    ],
    "predicted": [
      4,
      5,
      5,
      6,
      6,
      1,
      1,
      1,
      5,
      1
    ],
    "rmse": 0.7071067811865476,
    "method": "de_full_11D",
    "n_free": 11,
    "null_channels": [
      "gap",
      "retaliation",
      "inertia"
    ],
    "population": "Samara",
    "session": "Samara_P_S1",
    "knockout_active_channels": [
      "strain"
    ],
    "knockout_null_channels": [
      "no_gap",
      "no_retaliation",
      "no_inertia"
    ],
    "active_channels": [
      "strain"
    ],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperative-enforcer",
    "contribution_trajectory": [
      10,
      13,
      5,
      9,
      15,
      7,
      10,
      12,
      20,
      5
    ],
    "punishment_sent_trajectory": [
      3,
      6,
      6,
      6,
      6,
      1,
      0,
      2,
      5,
      1
    ],
    "punishment_received_trajectory": [
      1,
      0,
      5,
      1,
      0,
      1,
      0,
      1,
      1,
      3
    ],
    "total_voluntary_spend_trajectory": [
      13,
      19,
      11,
      15,
      21,
      8,
      10,
      14,
      25,
      6
    ],
    "others_mean_trajectory": [
      11.3,
      9.3,
      9.0,
      6.3,
      7.0,
      10.0,
      15.0,
      14.7,
      11.7,
      14.3
    ],
    "mean_contribution": 10.6,
    "mean_punishment_sent": 3.6,
    "mean_punishment_received": 1.3,
    "mean_total_voluntary_spend": 14.2,
    "antisocial_punishment_total": 8,
    "prosocial_punishment_total": 28,
    "antisocial_ratio": 0.222,
    "group_id": "703"
  },
  "707": {
    "params": {
      "p_base": 0.326060102622573,
      "p_scale": 4.591419886454734,
      "gap_weight": 0.9345973569385672,
      "gap_direction": 0.9699279630741571,
      "retaliation_w": 0.31957021490167237,
      "strain_rate": 1.1729538427835238,
      "strain_initial": 0.9909883340002832,
      "discharge_thresh": 1.077164185241028,
      "discharge_frac": 0.40428615088533204,
      "inertia_w": -0.0164360593367186,
      "decay_rate": 0.511385893399087
    },
    "params_list": [
      0.326060102622573,
      4.591419886454734,
      0.9345973569385672,
      0.9699279630741571,
      0.31957021490167237,
      1.1729538427835238,
      0.9909883340002832,
      1.077164185241028,
      0.40428615088533204,
      -0.0164360593367186,
      0.511385893399087
    ],
    "actual": [
      4,
      6,
      2,
      6,
      2,
      6,
      6,
      6,
      1,
      6
    ],
    "predicted": [
      4,
      6,
      3,
      7,
      2,
      5,
      4,
      6,
      3,
      5
    ],
    "rmse": 1.0954451150103321,
    "method": "de_full_11D",
    "n_free": 11,
    "null_channels": [
      "gap",
      "retaliation",
      "inertia"
    ],
    "population": "Samara",
    "session": "Samara_P_S1",
    "knockout_active_channels": [
      "strain"
    ],
    "knockout_null_channels": [
      "no_gap",
      "no_retaliation",
      "no_inertia"
    ],
    "active_channels": [
      "strain"
    ],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperative-enforcer",
    "contribution_trajectory": [
      18,
      18,
      15,
      20,
      5,
      10,
      15,
      15,
      17,
      19
    ],
    "punishment_sent_trajectory": [
      4,
      6,
      2,
      6,
      2,
      6,
      6,
      6,
      1,
      6
    ],
    "punishment_received_trajectory": [
      0,
      3,
      1,
      6,
      4,
      1,
      3,
      2,
      5,
      0
    ],
    "total_voluntary_spend_trajectory": [
      22,
      24,
      17,
      26,
      7,
      16,
      21,
      21,
      18,
      25
    ],
    "others_mean_trajectory": [
      5.3,
      6.7,
      10.7,
      5.0,
      4.0,
      7.0,
      4.7,
      5.0,
      8.7,
      3.3
    ],
    "mean_contribution": 15.2,
    "mean_punishment_sent": 4.5,
    "mean_punishment_received": 2.5,
    "mean_total_voluntary_spend": 19.7,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 45,
    "antisocial_ratio": 0.0,
    "group_id": "701"
  },
  "708": {
    "params": {
      "p_base": 0.030074387023816485,
      "p_scale": 11.880848402885873,
      "gap_weight": 0.9762903499820447,
      "gap_direction": 0.944011489171348,
      "retaliation_w": 0.0,
      "strain_rate": 0.5564945778929606,
      "strain_initial": 4.3143455144196885,
      "discharge_thresh": 4.970589165237522,
      "discharge_frac": 0.3306544959201658,
      "inertia_w": -0.49989218983943706,
      "decay_rate": 0.5250441049495734
    },
    "params_list": [
      0.030074387023816485,
      11.880848402885873,
      0.9762903499820447,
      0.944011489171348,
      0.0,
      0.5564945778929606,
      4.3143455144196885,
      4.970589165237522,
      0.3306544959201658,
      -0.49989218983943706,
      0.5250441049495734
    ],
    "actual": [
      3,
      0,
      6,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "predicted": [
      3,
      0,
      6,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "rmse": 0.0,
    "method": "de_channel_selective",
    "n_free": 10,
    "null_channels": [
      "retaliation"
    ],
    "population": "Samara",
    "session": "Samara_P_S1",
    "knockout_active_channels": [
      "gap",
      "strain",
      "inertia"
    ],
    "knockout_null_channels": [
      "no_retaliation"
    ],
    "active_channels": [
      "gap",
      "strain",
      "inertia"
    ],
    "gap_classification": "prosocial",
    "behavioral_profile": "mixed",
    "contribution_trajectory": [
      14,
      5,
      3,
      5,
      2,
      9,
      13,
      15,
      11,
      12
    ],
    "punishment_sent_trajectory": [
      3,
      0,
      6,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "punishment_received_trajectory": [
      3,
      9,
      9,
      4,
      9,
      1,
      0,
      0,
      2,
      1
    ],
    "total_voluntary_spend_trajectory": [
      17,
      5,
      9,
      5,
      2,
      9,
      13,
      15,
      11,
      12
    ],
    "others_mean_trajectory": [
      10.0,
      12.0,
      9.7,
      7.7,
      11.3,
      9.3,
      14.0,
      13.7,
      14.7,
      12.0
    ],
    "mean_contribution": 8.9,
    "mean_punishment_sent": 0.9,
    "mean_punishment_received": 3.8,
    "mean_total_voluntary_spend": 9.8,
    "antisocial_punishment_total": 6,
    "prosocial_punishment_total": 3,
    "antisocial_ratio": 0.667,
    "group_id": "703"
  },
  "709": {
    "params": {
      "p_base": 0.024056954129808072,
      "p_scale": 4.5856809410895725,
      "gap_weight": 0.29750491644140326,
      "gap_direction": 0.8880876773402029,
      "retaliation_w": 0.8907727325164814,
      "strain_rate": 1.2777178953665775,
      "strain_initial": 0.7599525807373215,
      "discharge_thresh": 1.9603934688449063,
      "discharge_frac": 0.11802286616008756,
      "inertia_w": 0.0,
      "decay_rate": 0.18288047180822742
    },
    "params_list": [
      0.024056954129808072,
      4.5856809410895725,
      0.29750491644140326,
      0.8880876773402029,
      0.8907727325164814,
      1.2777178953665775,
      0.7599525807373215,
      1.9603934688449063,
      0.11802286616008756,
      0.0,
      0.18288047180822742
    ],
    "actual": [
      0,
      4,
      1,
      1,
      1,
      0,
      2,
      0,
      0,
      2
    ],
    "predicted": [
      0,
      4,
      1,
      1,
      1,
      0,
      2,
      0,
      0,
      2
    ],
    "rmse": 0.0,
    "method": "de_channel_selective",
    "n_free": 10,
    "null_channels": [
      "inertia"
    ],
    "population": "Samara",
    "session": "Samara_P_S1",
    "knockout_active_channels": [
      "gap",
      "retaliation",
      "strain"
    ],
    "knockout_null_channels": [
      "no_inertia"
    ],
    "active_channels": [
      "gap",
      "retaliation",
      "strain"
    ],
    "gap_classification": "prosocial",
    "behavioral_profile": "punitive-free-rider",
    "contribution_trajectory": [
      5,
      3,
      0,
      10,
      3,
      0,
      1,
      2,
      0,
      5
    ],
    "punishment_sent_trajectory": [
      0,
      4,
      1,
      1,
      1,
      0,
      2,
      0,
      0,
      2
    ],
    "punishment_received_trajectory": [
      11,
      5,
      1,
      0,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "total_voluntary_spend_trajectory": [
      5,
      7,
      1,
      11,
      4,
      0,
      3,
      2,
      0,
      7
    ],
    "others_mean_trajectory": [
      8.3,
      3.3,
      1.7,
      0.3,
      0.0,
      1.0,
      0.0,
      1.7,
      0.0,
      0.0
    ],
    "mean_contribution": 2.9,
    "mean_punishment_sent": 1.1,
    "mean_punishment_received": 2.3,
    "mean_total_voluntary_spend": 4.0,
    "antisocial_punishment_total": 1,
    "prosocial_punishment_total": 10,
    "antisocial_ratio": 0.091,
    "group_id": "702"
  },
  "710": {
    "params": {
      "p_base": 0.017374692012904924,
      "p_scale": 22.271728303418556,
      "gap_weight": 0.9001067975047689,
      "gap_direction": 0.21934788389426618,
      "retaliation_w": 0.0,
      "strain_rate": 0.05,
      "strain_initial": 0.0,
      "discharge_thresh": 5.0,
      "discharge_frac": 0.1,
      "inertia_w": 0.0,
      "decay_rate": 0.07324816161992503
    },
    "params_list": [
      0.017374692012904924,
      22.271728303418556,
      0.9001067975047689,
      0.21934788389426618,
      0.0,
      0.05,
      0.0,
      5.0,
      0.1,
      0.0,
      0.07324816161992503
    ],
    "actual": [
      0,
      0,
      0,
      0,
      0,
      0,
      2,
      2,
      0,
      0
    ],
    "predicted": [
      1,
      0,
      0,
      0,
      0,
      0,
      1,
      1,
      0,
      0
    ],
    "rmse": 0.5477225575051661,
    "method": "de_channel_selective",
    "n_free": 5,
    "null_channels": [
      "retaliation",
      "strain",
      "inertia"
    ],
    "population": "Samara",
    "session": "Samara_P_S1",
    "knockout_active_channels": [
      "gap"
    ],
    "knockout_null_channels": [
      "no_retaliation",
      "no_strain",
      "no_inertia"
    ],
    "active_channels": [
      "gap"
    ],
    "gap_classification": "neutral",
    "behavioral_profile": "cooperator",
    "contribution_trajectory": [
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "punishment_sent_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      2,
      2,
      0,
      0
    ],
    "punishment_received_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      20,
      20,
      20,
      20,
      20,
      20,
      22,
      22,
      20,
      20
    ],
    "others_mean_trajectory": [
      15.7,
      20.0,
      19.7,
      19.7,
      19.7,
      19.7,
      19.3,
      19.3,
      20.0,
      20.0
    ],
    "mean_contribution": 20.0,
    "mean_punishment_sent": 0.4,
    "mean_punishment_received": 0.0,
    "mean_total_voluntary_spend": 20.4,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 4,
    "antisocial_ratio": 0.0,
    "group_id": "704"
  },
  "711": {
    "params": {
      "p_base": 0.0,
      "p_scale": 1.0,
      "gap_weight": 0.0,
      "gap_direction": 0.0,
      "retaliation_w": 0.0,
      "strain_rate": 0.05,
      "strain_initial": 0.0,
      "discharge_thresh": 5.0,
      "discharge_frac": 0.1,
      "inertia_w": 0.0,
      "decay_rate": 1.0
    },
    "params_list": [
      0.0,
      1.0,
      0.0,
      0.0,
      0.0,
      0.05,
      0.0,
      5.0,
      0.1,
      0.0,
      1.0
    ],
    "actual": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "predicted": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "rmse": 0.0,
    "method": "zero_shortcut",
    "n_free": 0,
    "null_channels": [
      "gap",
      "retaliation",
      "strain",
      "inertia"
    ],
    "population": "Samara",
    "session": "Samara_P_S1",
    "knockout_active_channels": [
      "gap",
      "retaliation",
      "strain",
      "inertia"
    ],
    "knockout_null_channels": [
      "gap",
      "retaliation",
      "strain",
      "inertia"
    ],
    "active_channels": [
      "gap",
      "retaliation",
      "strain",
      "inertia"
    ],
    "gap_classification": "gap-null",
    "behavioral_profile": "cooperator",
    "contribution_trajectory": [
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      19,
      20,
      20
    ],
    "punishment_sent_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "punishment_received_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      2,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      19,
      20,
      20
    ],
    "others_mean_trajectory": [
      15.7,
      20.0,
      19.7,
      19.7,
      19.7,
      19.7,
      19.3,
      19.7,
      20.0,
      20.0
    ],
    "mean_contribution": 19.9,
    "mean_punishment_sent": 0.0,
    "mean_punishment_received": 0.2,
    "mean_total_voluntary_spend": 19.9,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 0,
    "antisocial_ratio": 0.0,
    "group_id": "704"
  },
  "712": {
    "params": {
      "p_base": 0.0,
      "p_scale": 1.0,
      "gap_weight": 0.0,
      "gap_direction": 0.0,
      "retaliation_w": 0.0,
      "strain_rate": 0.05,
      "strain_initial": 0.0,
      "discharge_thresh": 5.0,
      "discharge_frac": 0.1,
      "inertia_w": 0.0,
      "decay_rate": 1.0
    },
    "params_list": [
      0.0,
      1.0,
      0.0,
      0.0,
      0.0,
      0.05,
      0.0,
      5.0,
      0.1,
      0.0,
      1.0
    ],
    "actual": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "predicted": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "rmse": 0.0,
    "method": "zero_shortcut",
    "n_free": 0,
    "null_channels": [
      "gap",
      "retaliation",
      "strain",
      "inertia"
    ],
    "population": "Samara",
    "session": "Samara_P_S1",
    "knockout_active_channels": [
      "gap",
      "retaliation",
      "strain",
      "inertia"
    ],
    "knockout_null_channels": [
      "gap",
      "retaliation",
      "strain",
      "inertia"
    ],
    "active_channels": [
      "gap",
      "retaliation",
      "strain",
      "inertia"
    ],
    "gap_classification": "gap-null",
    "behavioral_profile": "cooperator",
    "contribution_trajectory": [
      7,
      20,
      19,
      19,
      19,
      19,
      19,
      19,
      20,
      20
    ],
    "punishment_sent_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "punishment_received_trajectory": [
      1,
      0,
      0,
      0,
      0,
      0,
      1,
      2,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      7,
      20,
      19,
      19,
      19,
      19,
      19,
      19,
      20,
      20
    ],
    "others_mean_trajectory": [
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      19.7,
      19.7,
      20.0,
      20.0
    ],
    "mean_contribution": 18.1,
    "mean_punishment_sent": 0.0,
    "mean_punishment_received": 0.4,
    "mean_total_voluntary_spend": 18.1,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 0,
    "antisocial_ratio": 0.0,
    "group_id": "704"
  },
  "713": {
    "params": {
      "p_base": 0.2748597543667385,
      "p_scale": 1.9388975307271288,
      "gap_weight": 0.6509172379739067,
      "gap_direction": 0.8159111451631422,
      "retaliation_w": 0.6891699005539709,
      "strain_rate": 1.3647713034394742,
      "strain_initial": 9.873340171287389,
      "discharge_thresh": 2.698256600555074,
      "discharge_frac": 0.264068070660905,
      "inertia_w": -0.0389712863048986,
      "decay_rate": 0.4573697047505052
    },
    "params_list": [
      0.2748597543667385,
      1.9388975307271288,
      0.6509172379739067,
      0.8159111451631422,
      0.6891699005539709,
      1.3647713034394742,
      9.873340171287389,
      2.698256600555074,
      0.264068070660905,
      -0.0389712863048986,
      0.4573697047505052
    ],
    "actual": [
      1,
      2,
      3,
      3,
      2,
      0,
      1,
      1,
      0,
      1
    ],
    "predicted": [
      2,
      2,
      3,
      3,
      2,
      0,
      1,
      1,
      0,
      1
    ],
    "rmse": 0.31622776601683794,
    "method": "de_full_11D",
    "n_free": 11,
    "null_channels": [
      "gap",
      "retaliation",
      "strain",
      "inertia"
    ],
    "population": "Samara",
    "session": "Samara_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [
      "no_gap",
      "no_retaliation",
      "no_strain",
      "no_inertia"
    ],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperative-enforcer",
    "contribution_trajectory": [
      10,
      10,
      10,
      10,
      10,
      10,
      20,
      15,
      10,
      15
    ],
    "punishment_sent_trajectory": [
      1,
      2,
      3,
      3,
      2,
      0,
      1,
      1,
      0,
      1
    ],
    "punishment_received_trajectory": [
      1,
      3,
      2,
      0,
      0,
      0,
      0,
      0,
      3,
      0
    ],
    "total_voluntary_spend_trajectory": [
      11,
      12,
      13,
      13,
      12,
      10,
      21,
      16,
      10,
      16
    ],
    "others_mean_trajectory": [
      11.3,
      10.3,
      7.3,
      6.0,
      8.7,
      9.0,
      11.7,
      13.7,
      15.0,
      11.0
    ],
    "mean_contribution": 12.0,
    "mean_punishment_sent": 1.4,
    "mean_punishment_received": 0.9,
    "mean_total_voluntary_spend": 13.4,
    "antisocial_punishment_total": 1,
    "prosocial_punishment_total": 13,
    "antisocial_ratio": 0.071,
    "group_id": "703"
  },
  "714": {
    "params": {
      "p_base": 0.0006722360750490708,
      "p_scale": 19.65047566830713,
      "gap_weight": 0.765972112140317,
      "gap_direction": 0.7743822448698152,
      "retaliation_w": 0.4494806492420073,
      "strain_rate": 0.33681470870836683,
      "strain_initial": 3.2733570563792567,
      "discharge_thresh": 4.696718254228969,
      "discharge_frac": 0.3311376564780323,
      "inertia_w": -0.21763561250759322,
      "decay_rate": 0.9600753161832273
    },
    "params_list": [
      0.0006722360750490708,
      19.65047566830713,
      0.765972112140317,
      0.7743822448698152,
      0.4494806492420073,
      0.33681470870836683,
      3.2733570563792567,
      4.696718254228969,
      0.3311376564780323,
      -0.21763561250759322,
      0.9600753161832273
    ],
    "actual": [
      0,
      4,
      3,
      0,
      2,
      1,
      0,
      0,
      1,
      2
    ],
    "predicted": [
      0,
      3,
      3,
      0,
      2,
      1,
      0,
      0,
      1,
      2
    ],
    "rmse": 0.31622776601683794,
    "method": "de_full_11D",
    "n_free": 11,
    "null_channels": [
      "strain",
      "inertia"
    ],
    "population": "Samara",
    "session": "Samara_P_S1",
    "knockout_active_channels": [
      "gap",
      "retaliation"
    ],
    "knockout_null_channels": [
      "no_strain",
      "no_inertia"
    ],
    "active_channels": [
      "gap",
      "retaliation"
    ],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperative-enforcer",
    "contribution_trajectory": [
      10,
      13,
      14,
      4,
      9,
      11,
      12,
      14,
      14,
      16
    ],
    "punishment_sent_trajectory": [
      0,
      4,
      3,
      0,
      2,
      1,
      0,
      0,
      1,
      2
    ],
    "punishment_received_trajectory": [
      2,
      0,
      2,
      4,
      1,
      0,
      1,
      2,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      10,
      17,
      17,
      4,
      11,
      12,
      12,
      14,
      15,
      18
    ],
    "others_mean_trajectory": [
      11.3,
      9.3,
      6.0,
      8.0,
      9.0,
      8.7,
      14.3,
      14.0,
      13.7,
      10.7
    ],
    "mean_contribution": 11.7,
    "mean_punishment_sent": 1.3,
    "mean_punishment_received": 1.2,
    "mean_total_voluntary_spend": 13.0,
    "antisocial_punishment_total": 1,
    "prosocial_punishment_total": 12,
    "antisocial_ratio": 0.077,
    "group_id": "703"
  },
  "715": {
    "params": {
      "p_base": 0.9461065635766155,
      "p_scale": 2.761614106469411,
      "gap_weight": 0.5857851170995945,
      "gap_direction": 0.7616020057566308,
      "retaliation_w": 0.2844219763978205,
      "strain_rate": 2.5215635286395783,
      "strain_initial": 0.287669488087853,
      "discharge_thresh": 3.7187816865210666,
      "discharge_frac": 0.6903216009720352,
      "inertia_w": -0.4736926464550635,
      "decay_rate": 0.9456145018730016
    },
    "params_list": [
      0.9461065635766155,
      2.761614106469411,
      0.5857851170995945,
      0.7616020057566308,
      0.2844219763978205,
      2.5215635286395783,
      0.287669488087853,
      3.7187816865210666,
      0.6903216009720352,
      -0.4736926464550635,
      0.9456145018730016
    ],
    "actual": [
      3,
      0,
      2,
      0,
      1,
      1,
      2,
      2,
      0,
      1
    ],
    "predicted": [
      3,
      0,
      2,
      0,
      1,
      1,
      1,
      2,
      0,
      1
    ],
    "rmse": 0.31622776601683794,
    "method": "de_full_11D",
    "n_free": 11,
    "null_channels": [
      "gap",
      "retaliation",
      "strain"
    ],
    "population": "Samara",
    "session": "Samara_P_S1",
    "knockout_active_channels": [
      "inertia"
    ],
    "knockout_null_channels": [
      "no_gap",
      "no_retaliation",
      "no_strain"
    ],
    "active_channels": [
      "inertia"
    ],
    "gap_classification": "prosocial",
    "behavioral_profile": "antisocial-controller",
    "contribution_trajectory": [
      10,
      0,
      0,
      0,
      0,
      1,
      0,
      0,
      0,
      0
    ],
    "punishment_sent_trajectory": [
      3,
      0,
      2,
      0,
      1,
      1,
      2,
      2,
      0,
      1
    ],
    "punishment_received_trajectory": [
      10,
      7,
      0,
      0,
      0,
      1,
      2,
      1,
      1,
      1
    ],
    "total_voluntary_spend_trajectory": [
      13,
      0,
      2,
      0,
      1,
      2,
      2,
      2,
      0,
      1
    ],
    "others_mean_trajectory": [
      6.7,
      4.3,
      1.7,
      3.7,
      1.0,
      0.7,
      0.3,
      2.3,
      0.0,
      1.7
    ],
    "mean_contribution": 1.1,
    "mean_punishment_sent": 1.2,
    "mean_punishment_received": 2.3,
    "mean_total_voluntary_spend": 2.3,
    "antisocial_punishment_total": 10,
    "prosocial_punishment_total": 2,
    "antisocial_ratio": 0.833,
    "group_id": "702"
  },
  "716": {
    "params": {
      "p_base": 0.02255805087299073,
      "p_scale": 29.00183599539045,
      "gap_weight": 0.0,
      "gap_direction": 0.13957634881385217,
      "retaliation_w": 0.0,
      "strain_rate": 0.11422797222752301,
      "strain_initial": 4.160749369535876,
      "discharge_thresh": 0.10400129577201644,
      "discharge_frac": 0.8752077686425823,
      "inertia_w": 0.0,
      "decay_rate": 0.21684994597734775
    },
    "params_list": [
      0.02255805087299073,
      29.00183599539045,
      0.0,
      0.13957634881385217,
      0.0,
      0.11422797222752301,
      4.160749369535876,
      0.10400129577201644,
      0.8752077686425823,
      0.0,
      0.21684994597734775
    ],
    "actual": [
      30,
      15,
      0,
      0,
      0,
      3,
      3,
      0,
      3,
      3
    ],
    "predicted": [
      30,
      15,
      1,
      1,
      1,
      1,
      3,
      1,
      1,
      1
    ],
    "rmse": 1.2649110640673518,
    "method": "de_channel_selective",
    "n_free": 8,
    "null_channels": [
      "gap",
      "retaliation",
      "inertia"
    ],
    "population": "Samara",
    "session": "Samara_P_S1",
    "knockout_active_channels": [
      "strain"
    ],
    "knockout_null_channels": [
      "no_gap",
      "no_retaliation",
      "no_inertia"
    ],
    "active_channels": [
      "strain"
    ],
    "gap_classification": "gap-null",
    "behavioral_profile": "antisocial-controller",
    "contribution_trajectory": [
      0,
      0,
      5,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "punishment_sent_trajectory": [
      30,
      15,
      0,
      0,
      0,
      3,
      3,
      0,
      3,
      3
    ],
    "punishment_received_trajectory": [
      3,
      4,
      1,
      1,
      1,
      0,
      2,
      1,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      30,
      15,
      5,
      0,
      0,
      3,
      3,
      0,
      3,
      3
    ],
    "others_mean_trajectory": [
      10.0,
      4.3,
      0.0,
      3.7,
      1.0,
      1.0,
      0.3,
      2.3,
      0.0,
      1.7
    ],
    "mean_contribution": 0.5,
    "mean_punishment_sent": 5.7,
    "mean_punishment_received": 1.3,
    "mean_total_voluntary_spend": 6.2,
    "antisocial_punishment_total": 57,
    "prosocial_punishment_total": 0,
    "antisocial_ratio": 1.0,
    "group_id": "702"
  },
  "801": {
    "params": {
      "p_base": 0.0,
      "p_scale": 1.0,
      "gap_weight": 0.0,
      "gap_direction": 0.0,
      "retaliation_w": 0.0,
      "strain_rate": 0.05,
      "strain_initial": 0.0,
      "discharge_thresh": 5.0,
      "discharge_frac": 0.1,
      "inertia_w": 0.0,
      "decay_rate": 1.0
    },
    "params_list": [
      0.0,
      1.0,
      0.0,
      0.0,
      0.0,
      0.05,
      0.0,
      5.0,
      0.1,
      0.0,
      1.0
    ],
    "actual": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "predicted": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "rmse": 0.0,
    "method": "zero_shortcut",
    "n_free": 0,
    "null_channels": [
      "no_gap",
      "no_retaliation",
      "no_strain",
      "no_inertia"
    ],
    "population": "Samara",
    "session": "Samara_P_S2",
    "knockout_active_channels": [],
    "knockout_null_channels": [
      "no_gap",
      "no_retaliation",
      "no_strain",
      "no_inertia"
    ],
    "active_channels": [],
    "gap_classification": "gap-null",
    "behavioral_profile": "cooperator",
    "contribution_trajectory": [
      10,
      10,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "punishment_sent_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "punishment_received_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      10,
      10,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "others_mean_trajectory": [
      11.7,
      16.7,
      19.3,
      19.7,
      18.3,
      18.7,
      19.7,
      19.3,
      20.0,
      20.0
    ],
    "mean_contribution": 18.0,
    "mean_punishment_sent": 0.0,
    "mean_punishment_received": 0.0,
    "mean_total_voluntary_spend": 18.0,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 0,
    "antisocial_ratio": 0.0,
    "group_id": "801"
  },
  "807": {
    "params": {
      "p_base": 0.0,
      "p_scale": 1.0,
      "gap_weight": 0.0,
      "gap_direction": 0.0,
      "retaliation_w": 0.0,
      "strain_rate": 0.05,
      "strain_initial": 0.0,
      "discharge_thresh": 5.0,
      "discharge_frac": 0.1,
      "inertia_w": 0.0,
      "decay_rate": 1.0
    },
    "params_list": [
      0.0,
      1.0,
      0.0,
      0.0,
      0.0,
      0.05,
      0.0,
      5.0,
      0.1,
      0.0,
      1.0
    ],
    "actual": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "predicted": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "rmse": 0.0,
    "method": "zero_shortcut",
    "n_free": 0,
    "null_channels": [
      "no_gap",
      "no_retaliation",
      "no_strain",
      "no_inertia"
    ],
    "population": "Samara",
    "session": "Samara_P_S2",
    "knockout_active_channels": [],
    "knockout_null_channels": [
      "no_gap",
      "no_retaliation",
      "no_strain",
      "no_inertia"
    ],
    "active_channels": [],
    "gap_classification": "gap-null",
    "behavioral_profile": "cooperator",
    "contribution_trajectory": [
      10,
      15,
      20,
      19,
      20,
      19,
      19,
      19,
      20,
      20
    ],
    "punishment_sent_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "punishment_received_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      10,
      15,
      20,
      19,
      20,
      19,
      19,
      19,
      20,
      20
    ],
    "others_mean_trajectory": [
      11.7,
      15.0,
      19.3,
      20.0,
      18.3,
      19.0,
      20.0,
      19.7,
      20.0,
      20.0
    ],
    "mean_contribution": 18.1,
    "mean_punishment_sent": 0.0,
    "mean_punishment_received": 0.0,
    "mean_total_voluntary_spend": 18.1,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 0,
    "antisocial_ratio": 0.0,
    "group_id": "801"
  },
  "809": {
    "params": {
      "p_base": 0.0,
      "p_scale": 1.0,
      "gap_weight": 0.0,
      "gap_direction": 0.0,
      "retaliation_w": 0.0,
      "strain_rate": 0.05,
      "strain_initial": 0.0,
      "discharge_thresh": 5.0,
      "discharge_frac": 0.1,
      "inertia_w": 0.0,
      "decay_rate": 1.0
    },
    "params_list": [
      0.0,
      1.0,
      0.0,
      0.0,
      0.0,
      0.05,
      0.0,
      5.0,
      0.1,
      0.0,
      1.0
    ],
    "actual": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "predicted": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "rmse": 0.0,
    "method": "zero_shortcut",
    "n_free": 0,
    "null_channels": [
      "no_gap",
      "no_retaliation",
      "no_strain",
      "no_inertia"
    ],
    "population": "Samara",
    "session": "Samara_P_S2",
    "knockout_active_channels": [],
    "knockout_null_channels": [
      "no_gap",
      "no_retaliation",
      "no_strain",
      "no_inertia"
    ],
    "active_channels": [],
    "gap_classification": "gap-null",
    "behavioral_profile": "cooperator",
    "contribution_trajectory": [
      20,
      20,
      20,
      20,
      15,
      10,
      10,
      10,
      15,
      10
    ],
    "punishment_sent_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "punishment_received_trajectory": [
      2,
      0,
      0,
      0,
      0,
      1,
      0,
      0,
      0,
      1
    ],
    "total_voluntary_spend_trajectory": [
      20,
      20,
      20,
      20,
      15,
      10,
      10,
      10,
      15,
      10
    ],
    "others_mean_trajectory": [
      8.7,
      5.0,
      7.7,
      8.7,
      3.7,
      9.0,
      8.3,
      8.3,
      7.0,
      11.3
    ],
    "mean_contribution": 15.0,
    "mean_punishment_sent": 0.0,
    "mean_punishment_received": 0.4,
    "mean_total_voluntary_spend": 15.0,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 0,
    "antisocial_ratio": 0.0,
    "group_id": "804"
  },
  "814": {
    "params": {
      "p_base": 0.0,
      "p_scale": 1.0,
      "gap_weight": 0.0,
      "gap_direction": 0.0,
      "retaliation_w": 0.0,
      "strain_rate": 0.05,
      "strain_initial": 0.0,
      "discharge_thresh": 5.0,
      "discharge_frac": 0.1,
      "inertia_w": 0.0,
      "decay_rate": 1.0
    },
    "params_list": [
      0.0,
      1.0,
      0.0,
      0.0,
      0.0,
      0.05,
      0.0,
      5.0,
      0.1,
      0.0,
      1.0
    ],
    "actual": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "predicted": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "rmse": 0.0,
    "method": "zero_shortcut",
    "n_free": 0,
    "null_channels": [
      "no_gap",
      "no_retaliation",
      "no_strain",
      "no_inertia"
    ],
    "population": "Samara",
    "session": "Samara_P_S2",
    "knockout_active_channels": [],
    "knockout_null_channels": [
      "no_gap",
      "no_retaliation",
      "no_strain",
      "no_inertia"
    ],
    "active_channels": [],
    "gap_classification": "gap-null",
    "behavioral_profile": "cooperator",
    "contribution_trajectory": [
      10,
      15,
      18,
      20,
      20,
      17,
      20,
      20,
      20,
      20
    ],
    "punishment_sent_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "punishment_received_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      10,
      15,
      18,
      20,
      20,
      17,
      20,
      20,
      20,
      20
    ],
    "others_mean_trajectory": [
      11.7,
      15.0,
      20.0,
      19.7,
      18.3,
      19.7,
      19.7,
      19.3,
      20.0,
      20.0
    ],
    "mean_contribution": 18.0,
    "mean_punishment_sent": 0.0,
    "mean_punishment_received": 0.0,
    "mean_total_voluntary_spend": 18.0,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 0,
    "antisocial_ratio": 0.0,
    "group_id": "801"
  },
  "816": {
    "params": {
      "p_base": 0.0,
      "p_scale": 1.0,
      "gap_weight": 0.0,
      "gap_direction": 0.0,
      "retaliation_w": 0.0,
      "strain_rate": 0.05,
      "strain_initial": 0.0,
      "discharge_thresh": 5.0,
      "discharge_frac": 0.1,
      "inertia_w": 0.0,
      "decay_rate": 1.0
    },
    "params_list": [
      0.0,
      1.0,
      0.0,
      0.0,
      0.0,
      0.05,
      0.0,
      5.0,
      0.1,
      0.0,
      1.0
    ],
    "actual": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "predicted": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "rmse": 0.0,
    "method": "zero_shortcut",
    "n_free": 0,
    "null_channels": [
      "no_gap",
      "no_retaliation",
      "no_strain",
      "no_inertia"
    ],
    "population": "Samara",
    "session": "Samara_P_S2",
    "knockout_active_channels": [],
    "knockout_null_channels": [
      "no_gap",
      "no_retaliation",
      "no_strain",
      "no_inertia"
    ],
    "active_channels": [],
    "gap_classification": "gap-null",
    "behavioral_profile": "cooperator",
    "contribution_trajectory": [
      15,
      20,
      20,
      20,
      15,
      20,
      20,
      19,
      20,
      20
    ],
    "punishment_sent_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "punishment_received_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      15,
      20,
      20,
      20,
      15,
      20,
      20,
      19,
      20,
      20
    ],
    "others_mean_trajectory": [
      10.0,
      13.3,
      19.3,
      19.7,
      20.0,
      18.7,
      19.7,
      19.7,
      20.0,
      20.0
    ],
    "mean_contribution": 18.9,
    "mean_punishment_sent": 0.0,
    "mean_punishment_received": 0.0,
    "mean_total_voluntary_spend": 18.9,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 0,
    "antisocial_ratio": 0.0,
    "group_id": "801"
  },
  "806": {
    "params": {
      "p_base": 0.01784607036150382,
      "p_scale": 29.460329271428996,
      "gap_weight": 0.9900001632063075,
      "gap_direction": 0.9668918402727598,
      "retaliation_w": 0.008325837797812208,
      "strain_rate": 1.3203647631783437,
      "strain_initial": 1.664374954106746,
      "discharge_thresh": 3.9845022548661664,
      "discharge_frac": 0.9162503876065521,
      "inertia_w": -0.18270796238845666,
      "decay_rate": 0.9615944410917767
    },
    "params_list": [
      0.01784607036150382,
      29.460329271428996,
      0.9900001632063075,
      0.9668918402727598,
      0.008325837797812208,
      1.3203647631783437,
      1.664374954106746,
      3.9845022548661664,
      0.9162503876065521,
      -0.18270796238845666,
      0.9615944410917767
    ],
    "actual": [
      1,
      0,
      0,
      0,
      0,
      3,
      0,
      0,
      0,
      0
    ],
    "predicted": [
      1,
      0,
      0,
      0,
      0,
      2,
      0,
      0,
      0,
      0
    ],
    "rmse": 0.31622776601683794,
    "method": "de_full_11D",
    "n_free": 11,
    "null_channels": [],
    "population": "Samara",
    "session": "Samara_P_S2",
    "knockout_active_channels": [
      "gap"
    ],
    "knockout_null_channels": [
      "no_retaliation",
      "no_strain",
      "no_inertia"
    ],
    "active_channels": [
      "gap"
    ],
    "gap_classification": "prosocial",
    "behavioral_profile": "free-rider",
    "contribution_trajectory": [
      5,
      4,
      5,
      5,
      5,
      8,
      5,
      5,
      5,
      3
    ],
    "punishment_sent_trajectory": [
      1,
      0,
      0,
      0,
      0,
      3,
      0,
      0,
      0,
      0
    ],
    "punishment_received_trajectory": [
      1,
      2,
      0,
      1,
      2,
      0,
      1,
      0,
      0,
      1
    ],
    "total_voluntary_spend_trajectory": [
      6,
      4,
      5,
      5,
      5,
      11,
      5,
      5,
      5,
      3
    ],
    "others_mean_trajectory": [
      7.7,
      7.7,
      5.3,
      8.3,
      6.7,
      7.0,
      6.7,
      6.0,
      6.3,
      4.7
    ],
    "mean_contribution": 5.0,
    "mean_punishment_sent": 0.4,
    "mean_punishment_received": 0.8,
    "mean_total_voluntary_spend": 5.4,
    "antisocial_punishment_total": 1,
    "prosocial_punishment_total": 3,
    "antisocial_ratio": 0.25,
    "group_id": "803"
  },
  "810": {
    "params": {
      "p_base": 0.41652920530281556,
      "p_scale": 7.053662942916356,
      "gap_weight": 0.7181229167291434,
      "gap_direction": 0.71754322875924,
      "retaliation_w": 0.8358580111844969,
      "strain_rate": 0.8641540641067654,
      "strain_initial": 0.851706462874696,
      "discharge_thresh": 3.3456665448873943,
      "discharge_frac": 0.5395256700763176,
      "inertia_w": -0.26249498166581703,
      "decay_rate": 0.2965232479221341
    },
    "params_list": [
      0.41652920530281556,
      7.053662942916356,
      0.7181229167291434,
      0.71754322875924,
      0.8358580111844969,
      0.8641540641067654,
      0.851706462874696,
      3.3456665448873943,
      0.5395256700763176,
      -0.26249498166581703,
      0.2965232479221341
    ],
    "actual": [
      3,
      0,
      5,
      1,
      2,
      3,
      3,
      2,
      3,
      0
    ],
    "predicted": [
      3,
      1,
      3,
      1,
      3,
      3,
      2,
      2,
      3,
      1
    ],
    "rmse": 0.8944271909999159,
    "method": "de_full_11D",
    "n_free": 11,
    "null_channels": [],
    "population": "Samara",
    "session": "Samara_P_S2",
    "knockout_active_channels": [],
    "knockout_null_channels": [
      "no_gap",
      "no_retaliation",
      "no_strain",
      "no_inertia"
    ],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "mixed",
    "contribution_trajectory": [
      10,
      0,
      10,
      6,
      0,
      12,
      10,
      0,
      9,
      9
    ],
    "punishment_sent_trajectory": [
      3,
      0,
      5,
      1,
      2,
      3,
      3,
      2,
      3,
      0
    ],
    "punishment_received_trajectory": [
      0,
      3,
      0,
      5,
      3,
      0,
      0,
      6,
      0,
      3
    ],
    "total_voluntary_spend_trajectory": [
      13,
      0,
      15,
      7,
      2,
      15,
      13,
      2,
      12,
      9
    ],
    "others_mean_trajectory": [
      12.0,
      11.7,
      11.0,
      13.3,
      8.7,
      8.3,
      8.3,
      11.7,
      9.0,
      11.7
    ],
    "mean_contribution": 6.6,
    "mean_punishment_sent": 2.2,
    "mean_punishment_received": 2.0,
    "mean_total_voluntary_spend": 8.8,
    "antisocial_punishment_total": 6,
    "prosocial_punishment_total": 16,
    "antisocial_ratio": 0.273,
    "group_id": "804"
  },
  "811": {
    "params": {
      "p_base": 0.07577683716966538,
      "p_scale": 11.747354887000515,
      "gap_weight": 0.5243415016694984,
      "gap_direction": 0.6889912664394493,
      "retaliation_w": 0.9040825244683653,
      "strain_rate": 1.6791140637412842,
      "strain_initial": 0.45568634158429244,
      "discharge_thresh": 4.302818288600777,
      "discharge_frac": 0.45670619370654775,
      "inertia_w": -0.06319771537644386,
      "decay_rate": 0.48125525029205185
    },
    "params_list": [
      0.07577683716966538,
      11.747354887000515,
      0.5243415016694984,
      0.6889912664394493,
      0.9040825244683653,
      1.6791140637412842,
      0.45568634158429244,
      4.302818288600777,
      0.45670619370654775,
      -0.06319771537644386,
      0.48125525029205185
    ],
    "actual": [
      1,
      2,
      0,
      7,
      2,
      0,
      0,
      6,
      0,
      2
    ],
    "predicted": [
      1,
      1,
      1,
      5,
      1,
      2,
      2,
      6,
      0,
      3
    ],
    "rmse": 1.2649110640673518,
    "method": "de_full_11D",
    "n_free": 11,
    "null_channels": [],
    "population": "Samara",
    "session": "Samara_P_S2",
    "knockout_active_channels": [
      "retaliation"
    ],
    "knockout_null_channels": [
      "no_gap",
      "no_strain",
      "no_inertia"
    ],
    "active_channels": [
      "retaliation"
    ],
    "gap_classification": "prosocial",
    "behavioral_profile": "mixed",
    "contribution_trajectory": [
      10,
      5,
      3,
      10,
      5,
      5,
      5,
      20,
      2,
      5
    ],
    "punishment_sent_trajectory": [
      1,
      2,
      0,
      7,
      2,
      0,
      0,
      6,
      0,
      2
    ],
    "punishment_received_trajectory": [
      0,
      1,
      6,
      0,
      2,
      2,
      3,
      0,
      4,
      1
    ],
    "total_voluntary_spend_trajectory": [
      11,
      7,
      3,
      17,
      7,
      5,
      5,
      26,
      2,
      7
    ],
    "others_mean_trajectory": [
      12.0,
      10.0,
      13.3,
      12.0,
      7.0,
      10.7,
      10.0,
      5.0,
      11.3,
      13.0
    ],
    "mean_contribution": 7.0,
    "mean_punishment_sent": 2.0,
    "mean_punishment_received": 1.9,
    "mean_total_voluntary_spend": 9.0,
    "antisocial_punishment_total": 5,
    "prosocial_punishment_total": 15,
    "antisocial_ratio": 0.25,
    "group_id": "804"
  },
  "815": {
    "params": {
      "p_base": 0.03172944336467698,
      "p_scale": 12.776791177063144,
      "gap_weight": 0.7357250804304821,
      "gap_direction": 0.8343213903748452,
      "retaliation_w": 0.8757531901528899,
      "strain_rate": 0.8787300410663188,
      "strain_initial": 0.04508641097656607,
      "discharge_thresh": 0.4808114622642137,
      "discharge_frac": 0.20345992078122022,
      "inertia_w": -0.4101298653589276,
      "decay_rate": 0.5435719756965887
    },
    "params_list": [
      0.03172944336467698,
      12.776791177063144,
      0.7357250804304821,
      0.8343213903748452,
      0.8757531901528899,
      0.8787300410663188,
      0.04508641097656607,
      0.4808114622642137,
      0.20345992078122022,
      -0.4101298653589276,
      0.5435719756965887
    ],
    "actual": [
      0,
      2,
      1,
      0,
      2,
      0,
      0,
      1,
      1,
      3
    ],
    "predicted": [
      0,
      2,
      0,
      0,
      2,
      0,
      0,
      1,
      1,
      3
    ],
    "rmse": 0.31622776601683794,
    "method": "de_full_11D",
    "n_free": 11,
    "null_channels": [],
    "population": "Samara",
    "session": "Samara_P_S2",
    "knockout_active_channels": [
      "gap"
    ],
    "knockout_null_channels": [
      "no_retaliation",
      "no_strain",
      "no_inertia"
    ],
    "active_channels": [
      "gap"
    ],
    "gap_classification": "prosocial",
    "behavioral_profile": "mixed",
    "contribution_trajectory": [
      6,
      10,
      10,
      10,
      6,
      10,
      10,
      5,
      10,
      20
    ],
    "punishment_sent_trajectory": [
      0,
      2,
      1,
      0,
      2,
      0,
      0,
      1,
      1,
      3
    ],
    "punishment_received_trajectory": [
      2,
      0,
      0,
      3,
      1,
      0,
      0,
      3,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      6,
      12,
      11,
      10,
      8,
      10,
      10,
      6,
      11,
      23
    ],
    "others_mean_trajectory": [
      13.3,
      8.3,
      11.0,
      12.0,
      6.7,
      9.0,
      8.3,
      10.0,
      8.7,
      8.0
    ],
    "mean_contribution": 9.7,
    "mean_punishment_sent": 1.0,
    "mean_punishment_received": 0.9,
    "mean_total_voluntary_spend": 10.7,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 10,
    "antisocial_ratio": 0.0,
    "group_id": "804"
  },
  "804": {
    "params": {
      "p_base": 0.12469163814984718,
      "p_scale": 1.1523051652629412,
      "gap_weight": 0.0,
      "gap_direction": -0.0042026032031633465,
      "retaliation_w": 0.0,
      "strain_rate": 1.7027799814672948,
      "strain_initial": 2.7606878058370734,
      "discharge_thresh": 2.9774770281740364,
      "discharge_frac": 0.7638981428596533,
      "inertia_w": 0.0,
      "decay_rate": 0.5637298403162688
    },
    "params_list": [
      0.12469163814984718,
      1.1523051652629412,
      0.0,
      -0.0042026032031633465,
      0.0,
      1.7027799814672948,
      2.7606878058370734,
      2.9774770281740364,
      0.7638981428596533,
      0.0,
      0.5637298403162688
    ],
    "actual": [
      0,
      1,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "predicted": [
      0,
      1,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "rmse": 0.0,
    "method": "de_channel_selective",
    "n_free": 8,
    "null_channels": [
      "no_gap",
      "no_retaliation",
      "no_inertia"
    ],
    "population": "Samara",
    "session": "Samara_P_S2",
    "knockout_active_channels": [
      "strain"
    ],
    "knockout_null_channels": [
      "no_gap",
      "no_retaliation",
      "no_inertia"
    ],
    "active_channels": [
      "strain"
    ],
    "gap_classification": "gap-null",
    "behavioral_profile": "mixed",
    "contribution_trajectory": [
      8,
      8,
      8,
      5,
      8,
      10,
      5,
      8,
      8,
      0
    ],
    "punishment_sent_trajectory": [
      0,
      1,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "punishment_received_trajectory": [
      1,
      1,
      1,
      0,
      0,
      0,
      2,
      2,
      0,
      5
    ],
    "total_voluntary_spend_trajectory": [
      8,
      9,
      8,
      5,
      8,
      10,
      5,
      8,
      8,
      0
    ],
    "others_mean_trajectory": [
      6.7,
      6.3,
      4.3,
      8.3,
      5.7,
      6.3,
      6.7,
      5.0,
      5.3,
      5.7
    ],
    "mean_contribution": 6.8,
    "mean_punishment_sent": 0.1,
    "mean_punishment_received": 1.2,
    "mean_total_voluntary_spend": 6.9,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 1,
    "antisocial_ratio": 0.0,
    "group_id": "803"
  },
  "802": {
    "params": {
      "p_base": 0.0024837500820601432,
      "p_scale": 13.103447736293198,
      "gap_weight": 0.598028135136631,
      "gap_direction": 0.9476763508572008,
      "retaliation_w": 0.10692715026784722,
      "strain_rate": 0.059715255134070944,
      "strain_initial": 0.2295790523828254,
      "discharge_thresh": 0.27295247523212973,
      "discharge_frac": 0.24265346354371076,
      "inertia_w": 0.004292003849814124,
      "decay_rate": 0.13400070047395696
    },
    "params_list": [
      0.0024837500820601432,
      13.103447736293198,
      0.598028135136631,
      0.9476763508572008,
      0.10692715026784722,
      0.059715255134070944,
      0.2295790523828254,
      0.27295247523212973,
      0.24265346354371076,
      0.004292003849814124,
      0.13400070047395696
    ],
    "actual": [
      0,
      0,
      0,
      1,
      1,
      1,
      1,
      0,
      0,
      1
    ],
    "predicted": [
      0,
      0,
      0,
      1,
      1,
      1,
      1,
      0,
      0,
      1
    ],
    "rmse": 0.0,
    "method": "de_full_11D",
    "n_free": 11,
    "null_channels": [],
    "population": "Samara",
    "session": "Samara_P_S2",
    "knockout_active_channels": [],
    "knockout_null_channels": [
      "no_gap",
      "no_retaliation",
      "no_strain",
      "no_inertia"
    ],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperative-enforcer",
    "contribution_trajectory": [
      8,
      10,
      10,
      15,
      10,
      15,
      15,
      20,
      20,
      20
    ],
    "punishment_sent_trajectory": [
      0,
      0,
      0,
      1,
      1,
      1,
      1,
      0,
      0,
      1
    ],
    "punishment_received_trajectory": [
      3,
      2,
      3,
      0,
      3,
      0,
      1,
      0,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      8,
      10,
      10,
      16,
      11,
      16,
      16,
      20,
      20,
      21
    ],
    "others_mean_trajectory": [
      16.7,
      14.0,
      18.3,
      13.3,
      12.3,
      13.3,
      13.3,
      20.0,
      18.7,
      18.3
    ],
    "mean_contribution": 14.3,
    "mean_punishment_sent": 0.5,
    "mean_punishment_received": 1.2,
    "mean_total_voluntary_spend": 14.8,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 5,
    "antisocial_ratio": 0.0,
    "group_id": "802"
  },
  "813": {
    "params": {
      "p_base": 0.14765819040450545,
      "p_scale": 5.395816141727577,
      "gap_weight": 0.715893793061138,
      "gap_direction": 0.25694310131665876,
      "retaliation_w": 0.26985960435195155,
      "strain_rate": 2.9773372404536067,
      "strain_initial": 3.925228922704591,
      "discharge_thresh": 4.8578502426262915,
      "discharge_frac": 0.8474606979475565,
      "inertia_w": 0.2545012245418061,
      "decay_rate": 0.6793710425406478
    },
    "params_list": [
      0.14765819040450545,
      5.395816141727577,
      0.715893793061138,
      0.25694310131665876,
      0.26985960435195155,
      2.9773372404536067,
      3.925228922704591,
      4.8578502426262915,
      0.8474606979475565,
      0.2545012245418061,
      0.6793710425406478
    ],
    "actual": [
      1,
      5,
      2,
      1,
      1,
      0,
      1,
      2,
      0,
      2
    ],
    "predicted": [
      1,
      5,
      2,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "rmse": 0.6324555320336759,
    "method": "de_full_11D",
    "n_free": 11,
    "null_channels": [],
    "population": "Samara",
    "session": "Samara_P_S2",
    "knockout_active_channels": [
      "strain"
    ],
    "knockout_null_channels": [
      "no_gap",
      "no_retaliation",
      "no_inertia"
    ],
    "active_channels": [
      "strain"
    ],
    "gap_classification": "neutral",
    "behavioral_profile": "antisocial-controller",
    "contribution_trajectory": [
      5,
      0,
      0,
      10,
      1,
      1,
      5,
      2,
      3,
      3
    ],
    "punishment_sent_trajectory": [
      1,
      5,
      2,
      1,
      1,
      0,
      1,
      2,
      0,
      2
    ],
    "punishment_received_trajectory": [
      2,
      3,
      2,
      0,
      1,
      5,
      2,
      1,
      1,
      1
    ],
    "total_voluntary_spend_trajectory": [
      6,
      5,
      2,
      11,
      2,
      1,
      6,
      4,
      3,
      5
    ],
    "others_mean_trajectory": [
      7.7,
      9.0,
      7.0,
      6.7,
      8.0,
      9.3,
      6.7,
      7.0,
      7.0,
      4.7
    ],
    "mean_contribution": 3.0,
    "mean_punishment_sent": 1.5,
    "mean_punishment_received": 1.8,
    "mean_total_voluntary_spend": 4.5,
    "antisocial_punishment_total": 12,
    "prosocial_punishment_total": 3,
    "antisocial_ratio": 0.8,
    "group_id": "803"
  },
  "812": {
    "params": {
      "p_base": 0.238356827007208,
      "p_scale": 1.8792752886193256,
      "gap_weight": 0.9903771939179802,
      "gap_direction": 0.9927035005155884,
      "retaliation_w": 0.7184003367369088,
      "strain_rate": 0.21197374811943615,
      "strain_initial": 9.660487141522545,
      "discharge_thresh": 0.7799657328136369,
      "discharge_frac": 0.45247116368581797,
      "inertia_w": -0.031032645483989707,
      "decay_rate": 0.2615926751783425
    },
    "params_list": [
      0.238356827007208,
      1.8792752886193256,
      0.9903771939179802,
      0.9927035005155884,
      0.7184003367369088,
      0.21197374811943615,
      9.660487141522545,
      0.7799657328136369,
      0.45247116368581797,
      -0.031032645483989707,
      0.2615926751783425
    ],
    "actual": [
      2,
      4,
      3,
      2,
      2,
      1,
      1,
      0,
      3,
      0
    ],
    "predicted": [
      2,
      3,
      3,
      2,
      2,
      1,
      1,
      0,
      1,
      0
    ],
    "rmse": 0.7071067811865476,
    "method": "de_full_11D",
    "n_free": 11,
    "null_channels": [],
    "population": "Samara",
    "session": "Samara_P_S2",
    "knockout_active_channels": [],
    "knockout_null_channels": [
      "no_gap",
      "no_retaliation",
      "no_strain",
      "no_inertia"
    ],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperative-enforcer",
    "contribution_trajectory": [
      15,
      20,
      20,
      20,
      15,
      20,
      20,
      20,
      20,
      15
    ],
    "punishment_sent_trajectory": [
      2,
      4,
      3,
      2,
      2,
      1,
      1,
      0,
      3,
      0
    ],
    "punishment_received_trajectory": [
      0,
      0,
      1,
      1,
      0,
      0,
      1,
      0,
      0,
      4
    ],
    "total_voluntary_spend_trajectory": [
      17,
      24,
      23,
      22,
      17,
      21,
      21,
      20,
      23,
      15
    ],
    "others_mean_trajectory": [
      14.3,
      10.7,
      15.0,
      11.7,
      10.7,
      11.7,
      11.7,
      20.0,
      18.7,
      20.0
    ],
    "mean_contribution": 18.5,
    "mean_punishment_sent": 1.8,
    "mean_punishment_received": 0.7,
    "mean_total_voluntary_spend": 20.3,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 18,
    "antisocial_ratio": 0.0,
    "group_id": "802"
  },
  "805": {
    "params": {
      "p_base": 0.20703254934841475,
      "p_scale": 2.332624475941902,
      "gap_weight": 0.4044311928563631,
      "gap_direction": 0.9829165906601041,
      "retaliation_w": 0.34036431966466657,
      "strain_rate": 0.6449281599496411,
      "strain_initial": 2.438109878852624,
      "discharge_thresh": 3.1635774727698736,
      "discharge_frac": 0.4592438960587464,
      "inertia_w": -0.30442002063282525,
      "decay_rate": 0.5388878823455827
    },
    "params_list": [
      0.20703254934841475,
      2.332624475941902,
      0.4044311928563631,
      0.9829165906601041,
      0.34036431966466657,
      0.6449281599496411,
      2.438109878852624,
      3.1635774727698736,
      0.4592438960587464,
      -0.30442002063282525,
      0.5388878823455827
    ],
    "actual": [
      0,
      0,
      1,
      1,
      2,
      0,
      1,
      0,
      0,
      2
    ],
    "predicted": [
      0,
      0,
      1,
      0,
      2,
      0,
      1,
      0,
      0,
      1
    ],
    "rmse": 0.4472135954999579,
    "method": "de_full_11D",
    "n_free": 11,
    "null_channels": [],
    "population": "Samara",
    "session": "Samara_P_S2",
    "knockout_active_channels": [],
    "knockout_null_channels": [
      "no_gap",
      "no_retaliation",
      "no_strain",
      "no_inertia"
    ],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "mixed",
    "contribution_trajectory": [
      15,
      2,
      15,
      0,
      2,
      0,
      0,
      20,
      16,
      20
    ],
    "punishment_sent_trajectory": [
      0,
      0,
      1,
      1,
      2,
      0,
      1,
      0,
      0,
      2
    ],
    "punishment_received_trajectory": [
      0,
      6,
      1,
      8,
      5,
      8,
      11,
      0,
      4,
      0
    ],
    "total_voluntary_spend_trajectory": [
      15,
      2,
      16,
      1,
      4,
      0,
      1,
      20,
      16,
      22
    ],
    "others_mean_trajectory": [
      14.3,
      16.7,
      16.7,
      18.3,
      15.0,
      18.3,
      18.3,
      20.0,
      20.0,
      18.3
    ],
    "mean_contribution": 9.0,
    "mean_punishment_sent": 0.7,
    "mean_punishment_received": 4.3,
    "mean_total_voluntary_spend": 9.7,
    "antisocial_punishment_total": 5,
    "prosocial_punishment_total": 2,
    "antisocial_ratio": 0.714,
    "group_id": "802"
  },
  "803": {
    "params": {
      "p_base": 0.03678864954085792,
      "p_scale": 28.878273387128665,
      "gap_weight": 0.9981546947405553,
      "gap_direction": 0.2624616956695247,
      "retaliation_w": 0.8511846851578667,
      "strain_rate": 2.73778077005856,
      "strain_initial": 0.24460320657429602,
      "discharge_thresh": 0.24833432284604084,
      "discharge_frac": 0.11960755537772577,
      "inertia_w": 0.09324802070231455,
      "decay_rate": 0.9411641692225253
    },
    "params_list": [
      0.03678864954085792,
      28.878273387128665,
      0.9981546947405553,
      0.2624616956695247,
      0.8511846851578667,
      2.73778077005856,
      0.24460320657429602,
      0.24833432284604084,
      0.11960755537772577,
      0.09324802070231455,
      0.9411641692225253
    ],
    "actual": [
      1,
      4,
      1,
      5,
      4,
      6,
      10,
      0,
      1,
      1
    ],
    "predicted": [
      1,
      4,
      1,
      4,
      6,
      7,
      6,
      2,
      2,
      1
    ],
    "rmse": 1.6431676725154984,
    "method": "de_full_11D",
    "n_free": 11,
    "null_channels": [],
    "population": "Samara",
    "session": "Samara_P_S2",
    "knockout_active_channels": [
      "gap"
    ],
    "knockout_null_channels": [
      "no_retaliation",
      "no_strain",
      "no_inertia"
    ],
    "active_channels": [
      "gap"
    ],
    "gap_classification": "neutral",
    "behavioral_profile": "cooperative-enforcer",
    "contribution_trajectory": [
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "punishment_sent_trajectory": [
      1,
      4,
      1,
      5,
      4,
      6,
      10,
      0,
      1,
      1
    ],
    "punishment_received_trajectory": [
      0,
      0,
      0,
      0,
      1,
      0,
      0,
      0,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      21,
      24,
      21,
      25,
      24,
      26,
      30,
      20,
      21,
      21
    ],
    "others_mean_trajectory": [
      12.7,
      10.7,
      15.0,
      11.7,
      9.0,
      11.7,
      11.7,
      20.0,
      18.7,
      18.3
    ],
    "mean_contribution": 20.0,
    "mean_punishment_sent": 3.3,
    "mean_punishment_received": 0.1,
    "mean_total_voluntary_spend": 23.3,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 33,
    "antisocial_ratio": 0.0,
    "group_id": "802"
  },
  "808": {
    "params": {
      "p_base": 0.18230774455587956,
      "p_scale": 4.452863286106959,
      "gap_weight": 0.9586978677897318,
      "gap_direction": 0.9363075095595832,
      "retaliation_w": 0.0,
      "strain_rate": 2.8392695431852966,
      "strain_initial": 0.7817790981877586,
      "discharge_thresh": 1.487191611592594,
      "discharge_frac": 0.5057214591887251,
      "inertia_w": 0.0,
      "decay_rate": 0.21712110762382097
    },
    "params_list": [
      0.18230774455587956,
      4.452863286106959,
      0.9586978677897318,
      0.9363075095595832,
      0.0,
      2.8392695431852966,
      0.7817790981877586,
      1.487191611592594,
      0.5057214591887251,
      0.0,
      0.21712110762382097
    ],
    "actual": [
      2,
      2,
      2,
      0,
      2,
      2,
      5,
      1,
      1,
      5
    ],
    "predicted": [
      2,
      3,
      2,
      1,
      2,
      2,
      5,
      1,
      1,
      3
    ],
    "rmse": 0.7745966692414834,
    "method": "de_channel_selective",
    "n_free": 9,
    "null_channels": [
      "no_retaliation",
      "no_inertia"
    ],
    "population": "Samara",
    "session": "Samara_P_S2",
    "knockout_active_channels": [
      "gap",
      "strain"
    ],
    "knockout_null_channels": [
      "no_retaliation",
      "no_inertia"
    ],
    "active_channels": [
      "gap",
      "strain"
    ],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperative-enforcer",
    "contribution_trajectory": [
      10,
      15,
      8,
      10,
      11,
      10,
      10,
      8,
      8,
      11
    ],
    "punishment_sent_trajectory": [
      2,
      2,
      2,
      0,
      2,
      2,
      5,
      1,
      1,
      5
    ],
    "punishment_received_trajectory": [
      0,
      2,
      1,
      0,
      0,
      0,
      1,
      0,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      12,
      17,
      10,
      10,
      13,
      12,
      15,
      9,
      9,
      16
    ],
    "others_mean_trajectory": [
      6.0,
      4.0,
      4.3,
      6.7,
      4.7,
      6.3,
      5.0,
      5.0,
      5.3,
      2.0
    ],
    "mean_contribution": 10.1,
    "mean_punishment_sent": 2.2,
    "mean_punishment_received": 0.4,
    "mean_total_voluntary_spend": 12.3,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 22,
    "antisocial_ratio": 0.0,
    "group_id": "803"
  }
}