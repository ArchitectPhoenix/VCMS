{
  "701": {
    "params": {
      "p_base": 0.12288072674429756,
      "p_scale": 4.011766958541401,
      "gap_weight": 0.5487044522633747,
      "gap_direction": -0.7687323186382227,
      "retaliation_w": 0.9201598915622797,
      "strain_rate": 2.0394985037088276,
      "strain_initial": 1.2486671825629294,
      "discharge_thresh": 3.3431286160394644,
      "discharge_frac": 0.4592255991150377,
      "inertia_w": 0.03188043288503123,
      "decay_rate": 0.3693719565299357
    },
    "params_list": [
      0.12288072674429756,
      4.011766958541401,
      0.5487044522633747,
      -0.7687323186382227,
      0.9201598915622797,
      2.0394985037088276,
      1.2486671825629294,
      3.3431286160394644,
      0.4592255991150377,
      0.03188043288503123,
      0.3693719565299357
    ],
    "actual": [
      0,
      3,
      10,
      7,
      3,
      3,
      4,
      4,
      6,
      3
    ],
    "predicted": [
      1,
      3,
      8,
      7,
      3,
      3,
      5,
      3,
      7,
      3
    ],
    "rmse": 0.8944271909999159,
    "method": "de_full_11D",
    "n_free": 11,
    "null_channels": [
      "gap",
      "retaliation",
      "inertia"
    ],
    "population": "Samara",
    "session": "Samara_P_S1",
    "knockout_active_channels": [
      "strain"
    ],
    "knockout_null_channels": [
      "no_gap",
      "no_retaliation",
      "no_inertia"
    ],
    "active_channels": [
      "strain"
    ],
    "gap_classification": "antisocial",
    "behavioral_profile": "antisocial-controller",
    "contribution_trajectory": [
      1,
      0,
      2,
      0,
      0,
      20,
      0,
      0,
      1,
      0
    ],
    "punishment_sent_trajectory": [
      0,
      3,
      10,
      7,
      3,
      3,
      4,
      4,
      6,
      3
    ],
    "punishment_received_trajectory": [
      5,
      10,
      5,
      9,
      9,
      1,
      8,
      7,
      6,
      7
    ],
    "total_voluntary_spend_trajectory": [
      1,
      3,
      12,
      7,
      3,
      23,
      4,
      4,
      7,
      3
    ],
    "others_mean_trajectory": [
      11.0,
      12.7,
      15.0,
      11.7,
      5.7,
      3.7,
      9.7,
      10.0,
      14.0,
      9.7
    ],
    "mean_contribution": 2.4,
    "mean_punishment_sent": 4.3,
    "mean_punishment_received": 6.7,
    "mean_total_voluntary_spend": 6.7,
    "antisocial_punishment_total": 40,
    "prosocial_punishment_total": 3,
    "antisocial_ratio": 0.93,
    "group_id": "701"
  },
  "702": {
    "params": {
      "p_base": 0.027910636295437163,
      "p_scale": 8.015372265777671,
      "gap_weight": 0.3397325182588058,
      "gap_direction": -0.14735079215746993,
      "retaliation_w": 0.9799898286845556,
      "strain_rate": 0.34577157735750985,
      "strain_initial": 1.4313850863364905,
      "discharge_thresh": 2.142982200562425,
      "discharge_frac": 0.2507813728215848,
      "inertia_w": -0.14273934534490518,
      "decay_rate": 0.11390201987171239
    },
    "params_list": [
      0.027910636295437163,
      8.015372265777671,
      0.3397325182588058,
      -0.14735079215746993,
      0.9799898286845556,
      0.34577157735750985,
      1.4313850863364905,
      2.142982200562425,
      0.2507813728215848,
      -0.14273934534490518,
      0.11390201987171239
    ],
    "actual": [
      0,
      3,
      1,
      5,
      7,
      3,
      0,
      1,
      3,
      0
    ],
    "predicted": [
      0,
      3,
      1,
      5,
      7,
      2,
      0,
      1,
      4,
      0
    ],
    "rmse": 0.4472135954999579,
    "method": "de_full_11D",
    "n_free": 11,
    "null_channels": [
      "gap",
      "inertia"
    ],
    "population": "Samara",
    "session": "Samara_P_S1",
    "knockout_active_channels": [
      "retaliation",
      "strain"
    ],
    "knockout_null_channels": [
      "no_gap",
      "no_inertia"
    ],
    "active_channels": [
      "retaliation",
      "strain"
    ],
    "gap_classification": "neutral",
    "behavioral_profile": "antisocial-controller",
    "contribution_trajectory": [
      0,
      5,
      20,
      0,
      2,
      1,
      4,
      0,
      10,
      0
    ],
    "punishment_sent_trajectory": [
      0,
      3,
      1,
      5,
      7,
      3,
      0,
      1,
      3,
      0
    ],
    "punishment_received_trajectory": [
      5,
      3,
      10,
      9,
      5,
      1,
      2,
      9,
      0,
      8
    ],
    "total_voluntary_spend_trajectory": [
      0,
      8,
      21,
      5,
      9,
      4,
      4,
      1,
      13,
      0
    ],
    "others_mean_trajectory": [
      11.3,
      11.0,
      9.0,
      11.7,
      5.0,
      10.0,
      8.3,
      10.0,
      11.0,
      9.7
    ],
    "mean_contribution": 4.2,
    "mean_punishment_sent": 2.3,
    "mean_punishment_received": 5.2,
    "mean_total_voluntary_spend": 6.5,
    "antisocial_punishment_total": 14,
    "prosocial_punishment_total": 9,
    "antisocial_ratio": 0.609,
    "group_id": "701"
  },
  "703": {
    "params": {
      "p_base": 0.012468728981126664,
      "p_scale": 25.572214472134846,
      "gap_weight": 0.4722845240126723,
      "gap_direction": 0.31386582532717267,
      "retaliation_w": 0.8546822631526615,
      "strain_rate": 0.3070172670117255,
      "strain_initial": 3.7061804185200886,
      "discharge_thresh": 4.2609013777869755,
      "discharge_frac": 0.36345909904169954,
      "inertia_w": -0.022007836138734194,
      "decay_rate": 0.41244321454684774
    },
    "params_list": [
      0.012468728981126664,
      25.572214472134846,
      0.4722845240126723,
      0.31386582532717267,
      0.8546822631526615,
      0.3070172670117255,
      3.7061804185200886,
      4.2609013777869755,
      0.36345909904169954,
      -0.022007836138734194,
      0.41244321454684774
    ],
    "actual": [
      1,
      0,
      0,
      0,
      0,
      0,
      0,
      2,
      0,
      0
    ],
    "predicted": [
      1,
      0,
      0,
      0,
      0,
      0,
      0,
      2,
      0,
      0
    ],
    "rmse": 0.0,
    "method": "de_full_11D",
    "n_free": 11,
    "null_channels": [
      "gap",
      "strain",
      "inertia"
    ],
    "population": "Samara",
    "session": "Samara_P_S1",
    "knockout_active_channels": [
      "retaliation"
    ],
    "knockout_null_channels": [
      "no_gap",
      "no_strain",
      "no_inertia"
    ],
    "active_channels": [
      "retaliation"
    ],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperator",
    "contribution_trajectory": [
      20,
      20,
      20,
      20,
      20,
      20,
      19,
      20,
      20,
      20
    ],
    "punishment_sent_trajectory": [
      1,
      0,
      0,
      0,
      0,
      0,
      0,
      2,
      0,
      0
    ],
    "punishment_received_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      1,
      0,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      21,
      20,
      20,
      20,
      20,
      20,
      19,
      22,
      20,
      20
    ],
    "others_mean_trajectory": [
      15.7,
      20.0,
      19.7,
      19.7,
      19.7,
      19.7,
      19.7,
      19.3,
      20.0,
      20.0
    ],
    "mean_contribution": 19.9,
    "mean_punishment_sent": 0.3,
    "mean_punishment_received": 0.1,
    "mean_total_voluntary_spend": 20.2,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 3,
    "antisocial_ratio": 0.0,
    "group_id": "704"
  },
  "704": {
    "params": {
      "p_base": 0.19294299214462274,
      "p_scale": 1.973228540975235,
      "gap_weight": 0.0,
      "gap_direction": 0.019150235768730095,
      "retaliation_w": 0.0,
      "strain_rate": 2.5898730496838223,
      "strain_initial": 3.6581751544858365,
      "discharge_thresh": 2.2284775690153054,
      "discharge_frac": 0.6068135664665247,
      "inertia_w": 0.0,
      "decay_rate": 0.585224802780552
    },
    "params_list": [
      0.19294299214462274,
      1.973228540975235,
      0.0,
      0.019150235768730095,
      0.0,
      2.5898730496838223,
      3.6581751544858365,
      2.2284775690153054,
      0.6068135664665247,
      0.0,
      0.585224802780552
    ],
    "actual": [
      2,
      2,
      0,
      0,
      0,
      0,
      0,
      2,
      0,
      0
    ],
    "predicted": [
      2,
      2,
      0,
      0,
      0,
      0,
      0,
      2,
      0,
      0
    ],
    "rmse": 0.0,
    "method": "de_channel_selective",
    "n_free": 8,
    "null_channels": [
      "gap",
      "retaliation",
      "inertia"
    ],
    "population": "Samara",
    "session": "Samara_P_S1",
    "knockout_active_channels": [
      "strain"
    ],
    "knockout_null_channels": [
      "no_gap",
      "no_retaliation",
      "no_inertia"
    ],
    "active_channels": [
      "strain"
    ],
    "gap_classification": "gap-null",
    "behavioral_profile": "punitive-free-rider",
    "contribution_trajectory": [
      15,
      10,
      0,
      1,
      0,
      2,
      0,
      5,
      0,
      0
    ],
    "punishment_sent_trajectory": [
      2,
      2,
      0,
      0,
      0,
      0,
      0,
      2,
      0,
      0
    ],
    "punishment_received_trajectory": [
      11,
      5,
      1,
      0,
      0,
      2,
      2,
      1,
      1,
      4
    ],
    "total_voluntary_spend_trajectory": [
      17,
      12,
      0,
      1,
      0,
      2,
      0,
      7,
      0,
      0
    ],
    "others_mean_trajectory": [
      5.0,
      1.0,
      1.7,
      3.3,
      1.0,
      0.3,
      0.3,
      0.7,
      0.0,
      1.7
    ],
    "mean_contribution": 3.3,
    "mean_punishment_sent": 0.6,
    "mean_punishment_received": 2.7,
    "mean_total_voluntary_spend": 3.9,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 6,
    "antisocial_ratio": 0.0,
    "group_id": "702"
  },
  "705": {
    "params": {
      "p_base": 0.1093990556401877,
      "p_scale": 16.30750108846867,
      "gap_weight": 0.94357465258566,
      "gap_direction": 0.8238517957300981,
      "retaliation_w": 0.0,
      "strain_rate": 0.17440450955747733,
      "strain_initial": 1.2017542599538955,
      "discharge_thresh": 1.249706560870629,
      "discharge_frac": 0.1637589801530001,
      "inertia_w": 0.0,
      "decay_rate": 0.6594462039831394
    },
    "params_list": [
      0.1093990556401877,
      16.30750108846867,
      0.94357465258566,
      0.8238517957300981,
      0.0,
      0.17440450955747733,
      1.2017542599538955,
      1.249706560870629,
      0.1637589801530001,
      0.0,
      0.6594462039831394
    ],
    "actual": [
      6,
      6,
      3,
      10,
      8,
      0,
      4,
      8,
      4,
      8
    ],
    "predicted": [
      7,
      6,
      2,
      10,
      7,
      2,
      4,
      8,
      5,
      8
    ],
    "rmse": 0.8944271909999159,
    "method": "de_channel_selective",
    "n_free": 9,
    "null_channels": [
      "retaliation",
      "inertia"
    ],
    "population": "Samara",
    "session": "Samara_P_S1",
    "knockout_active_channels": [
      "gap",
      "strain"
    ],
    "knockout_null_channels": [
      "no_retaliation",
      "no_inertia"
    ],
    "active_channels": [
      "gap",
      "strain"
    ],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperative-enforcer",
    "contribution_trajectory": [
      15,
      15,
      10,
      15,
      10,
      0,
      10,
      15,
      15,
      10
    ],
    "punishment_sent_trajectory": [
      6,
      6,
      3,
      10,
      8,
      0,
      4,
      8,
      4,
      8
    ],
    "punishment_received_trajectory": [
      0,
      2,
      0,
      4,
      2,
      9,
      1,
      1,
      3,
      2
    ],
    "total_voluntary_spend_trajectory": [
      21,
      21,
      13,
      25,
      18,
      0,
      14,
      23,
      19,
      18
    ],
    "others_mean_trajectory": [
      6.3,
      7.7,
      12.3,
      6.7,
      2.3,
      10.3,
      6.3,
      5.0,
      9.3,
      6.3
    ],
    "mean_contribution": 11.5,
    "mean_punishment_sent": 5.7,
    "mean_punishment_received": 2.4,
    "mean_total_voluntary_spend": 17.2,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 57,
    "antisocial_ratio": 0.0,
    "group_id": "701"
  },
  "706": {
    "params": {
      "p_base": 0.12943513974996756,
      "p_scale": 3.9582151756544555,
      "gap_weight": 0.7773716166083374,
      "gap_direction": 0.7826591220254098,
      "retaliation_w": 0.5853484126937403,
      "strain_rate": 2.7800624420810767,
      "strain_initial": 9.819506671326572,
      "discharge_thresh": 3.5566193675707103,
      "discharge_frac": 0.23296122661268476,
      "inertia_w": 0.10391350257315894,
      "decay_rate": 0.9154452588192081
    },
    "params_list": [
      0.12943513974996756,
      3.9582151756544555,
      0.7773716166083374,
      0.7826591220254098,
      0.5853484126937403,
      2.7800624420810767,
      9.819506671326572,
      3.5566193675707103,
      0.23296122661268476,
      0.10391350257315894,
      0.9154452588192081
    ],
    "actual": [
      3,
      6,
      6,
      6,
      6,
      1,
      0,
      2,
      5,
      1
    ],
    "predicted": [
      4,
      5,
      5,
      6,
      6,
      1,
      1,
      1,
      5,
      1
    ],
    "rmse": 0.7071067811865476,
    "method": "de_full_11D",
    "n_free": 11,
    "null_channels": [
      "gap",
      "retaliation",
      "inertia"
    ],
    "population": "Samara",
    "session": "Samara_P_S1",
    "knockout_active_channels": [
      "strain"
    ],
    "knockout_null_channels": [
      "no_gap",
      "no_retaliation",
      "no_inertia"
    ],
    "active_channels": [
      "strain"
    ],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperative-enforcer",
    "contribution_trajectory": [
      10,
      13,
      5,
      9,
      15,
      7,
      10,
      12,
      20,
      5
    ],
    "punishment_sent_trajectory": [
      3,
      6,
      6,
      6,
      6,
      1,
      0,
      2,
      5,
      1
    ],
    "punishment_received_trajectory": [
      1,
      0,
      5,
      1,
      0,
      1,
      0,
      1,
      1,
      3
    ],
    "total_voluntary_spend_trajectory": [
      13,
      19,
      11,
      15,
      21,
      8,
      10,
      14,
      25,
      6
    ],
    "others_mean_trajectory": [
      11.3,
      9.3,
      9.0,
      6.3,
      7.0,
      10.0,
      15.0,
      14.7,
      11.7,
      14.3
    ],
    "mean_contribution": 10.6,
    "mean_punishment_sent": 3.6,
    "mean_punishment_received": 1.3,
    "mean_total_voluntary_spend": 14.2,
    "antisocial_punishment_total": 8,
    "prosocial_punishment_total": 28,
    "antisocial_ratio": 0.222,
    "group_id": "703"
  },
  "707": {
    "params": {
      "p_base": 0.326060102622573,
      "p_scale": 4.591419886454734,
      "gap_weight": 0.9345973569385672,
      "gap_direction": 0.9699279630741571,
      "retaliation_w": 0.31957021490167237,
      "strain_rate": 1.1729538427835238,
      "strain_initial": 0.9909883340002832,
      "discharge_thresh": 1.077164185241028,
      "discharge_frac": 0.40428615088533204,
      "inertia_w": -0.0164360593367186,
      "decay_rate": 0.511385893399087
    },
    "params_list": [
      0.326060102622573,
      4.591419886454734,
      0.9345973569385672,
      0.9699279630741571,
      0.31957021490167237,
      1.1729538427835238,
      0.9909883340002832,
      1.077164185241028,
      0.40428615088533204,
      -0.0164360593367186,
      0.511385893399087
    ],
    "actual": [
      4,
      6,
      2,
      6,
      2,
      6,
      6,
      6,
      1,
      6
    ],
    "predicted": [
      4,
      6,
      3,
      7,
      2,
      5,
      4,
      6,
      3,
      5
    ],
    "rmse": 1.0954451150103321,
    "method": "de_full_11D",
    "n_free": 11,
    "null_channels": [
      "gap",
      "retaliation",
      "inertia"
    ],
    "population": "Samara",
    "session": "Samara_P_S1",
    "knockout_active_channels": [
      "strain"
    ],
    "knockout_null_channels": [
      "no_gap",
      "no_retaliation",
      "no_inertia"
    ],
    "active_channels": [
      "strain"
    ],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperative-enforcer",
    "contribution_trajectory": [
      18,
      18,
      15,
      20,
      5,
      10,
      15,
      15,
      17,
      19
    ],
    "punishment_sent_trajectory": [
      4,
      6,
      2,
      6,
      2,
      6,
      6,
      6,
      1,
      6
    ],
    "punishment_received_trajectory": [
      0,
      3,
      1,
      6,
      4,
      1,
      3,
      2,
      5,
      0
    ],
    "total_voluntary_spend_trajectory": [
      22,
      24,
      17,
      26,
      7,
      16,
      21,
      21,
      18,
      25
    ],
    "others_mean_trajectory": [
      5.3,
      6.7,
      10.7,
      5.0,
      4.0,
      7.0,
      4.7,
      5.0,
      8.7,
      3.3
    ],
    "mean_contribution": 15.2,
    "mean_punishment_sent": 4.5,
    "mean_punishment_received": 2.5,
    "mean_total_voluntary_spend": 19.7,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 45,
    "antisocial_ratio": 0.0,
    "group_id": "701"
  },
  "708": {
    "params": {
      "p_base": 0.030074387023816485,
      "p_scale": 11.880848402885873,
      "gap_weight": 0.9762903499820447,
      "gap_direction": 0.944011489171348,
      "retaliation_w": 0.0,
      "strain_rate": 0.5564945778929606,
      "strain_initial": 4.3143455144196885,
      "discharge_thresh": 4.970589165237522,
      "discharge_frac": 0.3306544959201658,
      "inertia_w": -0.49989218983943706,
      "decay_rate": 0.5250441049495734
    },
    "params_list": [
      0.030074387023816485,
      11.880848402885873,
      0.9762903499820447,
      0.944011489171348,
      0.0,
      0.5564945778929606,
      4.3143455144196885,
      4.970589165237522,
      0.3306544959201658,
      -0.49989218983943706,
      0.5250441049495734
    ],
    "actual": [
      3,
      0,
      6,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "predicted": [
      3,
      0,
      6,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "rmse": 0.0,
    "method": "de_channel_selective",
    "n_free": 10,
    "null_channels": [
      "retaliation"
    ],
    "population": "Samara",
    "session": "Samara_P_S1",
    "knockout_active_channels": [
      "gap",
      "strain",
      "inertia"
    ],
    "knockout_null_channels": [
      "no_retaliation"
    ],
    "active_channels": [
      "gap",
      "strain",
      "inertia"
    ],
    "gap_classification": "prosocial",
    "behavioral_profile": "mixed",
    "contribution_trajectory": [
      14,
      5,
      3,
      5,
      2,
      9,
      13,
      15,
      11,
      12
    ],
    "punishment_sent_trajectory": [
      3,
      0,
      6,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "punishment_received_trajectory": [
      3,
      9,
      9,
      4,
      9,
      1,
      0,
      0,
      2,
      1
    ],
    "total_voluntary_spend_trajectory": [
      17,
      5,
      9,
      5,
      2,
      9,
      13,
      15,
      11,
      12
    ],
    "others_mean_trajectory": [
      10.0,
      12.0,
      9.7,
      7.7,
      11.3,
      9.3,
      14.0,
      13.7,
      14.7,
      12.0
    ],
    "mean_contribution": 8.9,
    "mean_punishment_sent": 0.9,
    "mean_punishment_received": 3.8,
    "mean_total_voluntary_spend": 9.8,
    "antisocial_punishment_total": 6,
    "prosocial_punishment_total": 3,
    "antisocial_ratio": 0.667,
    "group_id": "703"
  },
  "709": {
    "params": {
      "p_base": 0.024056954129808072,
      "p_scale": 4.5856809410895725,
      "gap_weight": 0.29750491644140326,
      "gap_direction": 0.8880876773402029,
      "retaliation_w": 0.8907727325164814,
      "strain_rate": 1.2777178953665775,
      "strain_initial": 0.7599525807373215,
      "discharge_thresh": 1.9603934688449063,
      "discharge_frac": 0.11802286616008756,
      "inertia_w": 0.0,
      "decay_rate": 0.18288047180822742
    },
    "params_list": [
      0.024056954129808072,
      4.5856809410895725,
      0.29750491644140326,
      0.8880876773402029,
      0.8907727325164814,
      1.2777178953665775,
      0.7599525807373215,
      1.9603934688449063,
      0.11802286616008756,
      0.0,
      0.18288047180822742
    ],
    "actual": [
      0,
      4,
      1,
      1,
      1,
      0,
      2,
      0,
      0,
      2
    ],
    "predicted": [
      0,
      4,
      1,
      1,
      1,
      0,
      2,
      0,
      0,
      2
    ],
    "rmse": 0.0,
    "method": "de_channel_selective",
    "n_free": 10,
    "null_channels": [
      "inertia"
    ],
    "population": "Samara",
    "session": "Samara_P_S1",
    "knockout_active_channels": [
      "gap",
      "retaliation",
      "strain"
    ],
    "knockout_null_channels": [
      "no_inertia"
    ],
    "active_channels": [
      "gap",
      "retaliation",
      "strain"
    ],
    "gap_classification": "prosocial",
    "behavioral_profile": "punitive-free-rider",
    "contribution_trajectory": [
      5,
      3,
      0,
      10,
      3,
      0,
      1,
      2,
      0,
      5
    ],
    "punishment_sent_trajectory": [
      0,
      4,
      1,
      1,
      1,
      0,
      2,
      0,
      0,
      2
    ],
    "punishment_received_trajectory": [
      11,
      5,
      1,
      0,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "total_voluntary_spend_trajectory": [
      5,
      7,
      1,
      11,
      4,
      0,
      3,
      2,
      0,
      7
    ],
    "others_mean_trajectory": [
      8.3,
      3.3,
      1.7,
      0.3,
      0.0,
      1.0,
      0.0,
      1.7,
      0.0,
      0.0
    ],
    "mean_contribution": 2.9,
    "mean_punishment_sent": 1.1,
    "mean_punishment_received": 2.3,
    "mean_total_voluntary_spend": 4.0,
    "antisocial_punishment_total": 1,
    "prosocial_punishment_total": 10,
    "antisocial_ratio": 0.091,
    "group_id": "702"
  },
  "710": {
    "params": {
      "p_base": 0.017374692012904924,
      "p_scale": 22.271728303418556,
      "gap_weight": 0.9001067975047689,
      "gap_direction": 0.21934788389426618,
      "retaliation_w": 0.0,
      "strain_rate": 0.05,
      "strain_initial": 0.0,
      "discharge_thresh": 5.0,
      "discharge_frac": 0.1,
      "inertia_w": 0.0,
      "decay_rate": 0.07324816161992503
    },
    "params_list": [
      0.017374692012904924,
      22.271728303418556,
      0.9001067975047689,
      0.21934788389426618,
      0.0,
      0.05,
      0.0,
      5.0,
      0.1,
      0.0,
      0.07324816161992503
    ],
    "actual": [
      0,
      0,
      0,
      0,
      0,
      0,
      2,
      2,
      0,
      0
    ],
    "predicted": [
      1,
      0,
      0,
      0,
      0,
      0,
      1,
      1,
      0,
      0
    ],
    "rmse": 0.5477225575051661,
    "method": "de_channel_selective",
    "n_free": 5,
    "null_channels": [
      "retaliation",
      "strain",
      "inertia"
    ],
    "population": "Samara",
    "session": "Samara_P_S1",
    "knockout_active_channels": [
      "gap"
    ],
    "knockout_null_channels": [
      "no_retaliation",
      "no_strain",
      "no_inertia"
    ],
    "active_channels": [
      "gap"
    ],
    "gap_classification": "neutral",
    "behavioral_profile": "cooperator",
    "contribution_trajectory": [
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "punishment_sent_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      2,
      2,
      0,
      0
    ],
    "punishment_received_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      20,
      20,
      20,
      20,
      20,
      20,
      22,
      22,
      20,
      20
    ],
    "others_mean_trajectory": [
      15.7,
      20.0,
      19.7,
      19.7,
      19.7,
      19.7,
      19.3,
      19.3,
      20.0,
      20.0
    ],
    "mean_contribution": 20.0,
    "mean_punishment_sent": 0.4,
    "mean_punishment_received": 0.0,
    "mean_total_voluntary_spend": 20.4,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 4,
    "antisocial_ratio": 0.0,
    "group_id": "704"
  },
  "711": {
    "params": {
      "p_base": 0.0,
      "p_scale": 1.0,
      "gap_weight": 0.0,
      "gap_direction": 0.0,
      "retaliation_w": 0.0,
      "strain_rate": 0.05,
      "strain_initial": 0.0,
      "discharge_thresh": 5.0,
      "discharge_frac": 0.1,
      "inertia_w": 0.0,
      "decay_rate": 1.0
    },
    "params_list": [
      0.0,
      1.0,
      0.0,
      0.0,
      0.0,
      0.05,
      0.0,
      5.0,
      0.1,
      0.0,
      1.0
    ],
    "actual": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "predicted": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "rmse": 0.0,
    "method": "zero_shortcut",
    "n_free": 0,
    "null_channels": [
      "gap",
      "retaliation",
      "strain",
      "inertia"
    ],
    "population": "Samara",
    "session": "Samara_P_S1",
    "knockout_active_channels": [
      "gap",
      "retaliation",
      "strain",
      "inertia"
    ],
    "knockout_null_channels": [
      "gap",
      "retaliation",
      "strain",
      "inertia"
    ],
    "active_channels": [
      "gap",
      "retaliation",
      "strain",
      "inertia"
    ],
    "gap_classification": "gap-null",
    "behavioral_profile": "cooperator",
    "contribution_trajectory": [
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      19,
      20,
      20
    ],
    "punishment_sent_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "punishment_received_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      2,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      19,
      20,
      20
    ],
    "others_mean_trajectory": [
      15.7,
      20.0,
      19.7,
      19.7,
      19.7,
      19.7,
      19.3,
      19.7,
      20.0,
      20.0
    ],
    "mean_contribution": 19.9,
    "mean_punishment_sent": 0.0,
    "mean_punishment_received": 0.2,
    "mean_total_voluntary_spend": 19.9,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 0,
    "antisocial_ratio": 0.0,
    "group_id": "704"
  },
  "712": {
    "params": {
      "p_base": 0.0,
      "p_scale": 1.0,
      "gap_weight": 0.0,
      "gap_direction": 0.0,
      "retaliation_w": 0.0,
      "strain_rate": 0.05,
      "strain_initial": 0.0,
      "discharge_thresh": 5.0,
      "discharge_frac": 0.1,
      "inertia_w": 0.0,
      "decay_rate": 1.0
    },
    "params_list": [
      0.0,
      1.0,
      0.0,
      0.0,
      0.0,
      0.05,
      0.0,
      5.0,
      0.1,
      0.0,
      1.0
    ],
    "actual": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "predicted": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "rmse": 0.0,
    "method": "zero_shortcut",
    "n_free": 0,
    "null_channels": [
      "gap",
      "retaliation",
      "strain",
      "inertia"
    ],
    "population": "Samara",
    "session": "Samara_P_S1",
    "knockout_active_channels": [
      "gap",
      "retaliation",
      "strain",
      "inertia"
    ],
    "knockout_null_channels": [
      "gap",
      "retaliation",
      "strain",
      "inertia"
    ],
    "active_channels": [
      "gap",
      "retaliation",
      "strain",
      "inertia"
    ],
    "gap_classification": "gap-null",
    "behavioral_profile": "cooperator",
    "contribution_trajectory": [
      7,
      20,
      19,
      19,
      19,
      19,
      19,
      19,
      20,
      20
    ],
    "punishment_sent_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "punishment_received_trajectory": [
      1,
      0,
      0,
      0,
      0,
      0,
      1,
      2,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      7,
      20,
      19,
      19,
      19,
      19,
      19,
      19,
      20,
      20
    ],
    "others_mean_trajectory": [
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      19.7,
      19.7,
      20.0,
      20.0
    ],
    "mean_contribution": 18.1,
    "mean_punishment_sent": 0.0,
    "mean_punishment_received": 0.4,
    "mean_total_voluntary_spend": 18.1,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 0,
    "antisocial_ratio": 0.0,
    "group_id": "704"
  },
  "713": {
    "params": {
      "p_base": 0.2748597543667385,
      "p_scale": 1.9388975307271288,
      "gap_weight": 0.6509172379739067,
      "gap_direction": 0.8159111451631422,
      "retaliation_w": 0.6891699005539709,
      "strain_rate": 1.3647713034394742,
      "strain_initial": 9.873340171287389,
      "discharge_thresh": 2.698256600555074,
      "discharge_frac": 0.264068070660905,
      "inertia_w": -0.0389712863048986,
      "decay_rate": 0.4573697047505052
    },
    "params_list": [
      0.2748597543667385,
      1.9388975307271288,
      0.6509172379739067,
      0.8159111451631422,
      0.6891699005539709,
      1.3647713034394742,
      9.873340171287389,
      2.698256600555074,
      0.264068070660905,
      -0.0389712863048986,
      0.4573697047505052
    ],
    "actual": [
      1,
      2,
      3,
      3,
      2,
      0,
      1,
      1,
      0,
      1
    ],
    "predicted": [
      2,
      2,
      3,
      3,
      2,
      0,
      1,
      1,
      0,
      1
    ],
    "rmse": 0.31622776601683794,
    "method": "de_full_11D",
    "n_free": 11,
    "null_channels": [
      "gap",
      "retaliation",
      "strain",
      "inertia"
    ],
    "population": "Samara",
    "session": "Samara_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [
      "no_gap",
      "no_retaliation",
      "no_strain",
      "no_inertia"
    ],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperative-enforcer",
    "contribution_trajectory": [
      10,
      10,
      10,
      10,
      10,
      10,
      20,
      15,
      10,
      15
    ],
    "punishment_sent_trajectory": [
      1,
      2,
      3,
      3,
      2,
      0,
      1,
      1,
      0,
      1
    ],
    "punishment_received_trajectory": [
      1,
      3,
      2,
      0,
      0,
      0,
      0,
      0,
      3,
      0
    ],
    "total_voluntary_spend_trajectory": [
      11,
      12,
      13,
      13,
      12,
      10,
      21,
      16,
      10,
      16
    ],
    "others_mean_trajectory": [
      11.3,
      10.3,
      7.3,
      6.0,
      8.7,
      9.0,
      11.7,
      13.7,
      15.0,
      11.0
    ],
    "mean_contribution": 12.0,
    "mean_punishment_sent": 1.4,
    "mean_punishment_received": 0.9,
    "mean_total_voluntary_spend": 13.4,
    "antisocial_punishment_total": 1,
    "prosocial_punishment_total": 13,
    "antisocial_ratio": 0.071,
    "group_id": "703"
  },
  "714": {
    "params": {
      "p_base": 0.0006722360750490708,
      "p_scale": 19.65047566830713,
      "gap_weight": 0.765972112140317,
      "gap_direction": 0.7743822448698152,
      "retaliation_w": 0.4494806492420073,
      "strain_rate": 0.33681470870836683,
      "strain_initial": 3.2733570563792567,
      "discharge_thresh": 4.696718254228969,
      "discharge_frac": 0.3311376564780323,
      "inertia_w": -0.21763561250759322,
      "decay_rate": 0.9600753161832273
    },
    "params_list": [
      0.0006722360750490708,
      19.65047566830713,
      0.765972112140317,
      0.7743822448698152,
      0.4494806492420073,
      0.33681470870836683,
      3.2733570563792567,
      4.696718254228969,
      0.3311376564780323,
      -0.21763561250759322,
      0.9600753161832273
    ],
    "actual": [
      0,
      4,
      3,
      0,
      2,
      1,
      0,
      0,
      1,
      2
    ],
    "predicted": [
      0,
      3,
      3,
      0,
      2,
      1,
      0,
      0,
      1,
      2
    ],
    "rmse": 0.31622776601683794,
    "method": "de_full_11D",
    "n_free": 11,
    "null_channels": [
      "strain",
      "inertia"
    ],
    "population": "Samara",
    "session": "Samara_P_S1",
    "knockout_active_channels": [
      "gap",
      "retaliation"
    ],
    "knockout_null_channels": [
      "no_strain",
      "no_inertia"
    ],
    "active_channels": [
      "gap",
      "retaliation"
    ],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperative-enforcer",
    "contribution_trajectory": [
      10,
      13,
      14,
      4,
      9,
      11,
      12,
      14,
      14,
      16
    ],
    "punishment_sent_trajectory": [
      0,
      4,
      3,
      0,
      2,
      1,
      0,
      0,
      1,
      2
    ],
    "punishment_received_trajectory": [
      2,
      0,
      2,
      4,
      1,
      0,
      1,
      2,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      10,
      17,
      17,
      4,
      11,
      12,
      12,
      14,
      15,
      18
    ],
    "others_mean_trajectory": [
      11.3,
      9.3,
      6.0,
      8.0,
      9.0,
      8.7,
      14.3,
      14.0,
      13.7,
      10.7
    ],
    "mean_contribution": 11.7,
    "mean_punishment_sent": 1.3,
    "mean_punishment_received": 1.2,
    "mean_total_voluntary_spend": 13.0,
    "antisocial_punishment_total": 1,
    "prosocial_punishment_total": 12,
    "antisocial_ratio": 0.077,
    "group_id": "703"
  },
  "715": {
    "params": {
      "p_base": 0.9461065635766155,
      "p_scale": 2.761614106469411,
      "gap_weight": 0.5857851170995945,
      "gap_direction": 0.7616020057566308,
      "retaliation_w": 0.2844219763978205,
      "strain_rate": 2.5215635286395783,
      "strain_initial": 0.287669488087853,
      "discharge_thresh": 3.7187816865210666,
      "discharge_frac": 0.6903216009720352,
      "inertia_w": -0.4736926464550635,
      "decay_rate": 0.9456145018730016
    },
    "params_list": [
      0.9461065635766155,
      2.761614106469411,
      0.5857851170995945,
      0.7616020057566308,
      0.2844219763978205,
      2.5215635286395783,
      0.287669488087853,
      3.7187816865210666,
      0.6903216009720352,
      -0.4736926464550635,
      0.9456145018730016
    ],
    "actual": [
      3,
      0,
      2,
      0,
      1,
      1,
      2,
      2,
      0,
      1
    ],
    "predicted": [
      3,
      0,
      2,
      0,
      1,
      1,
      1,
      2,
      0,
      1
    ],
    "rmse": 0.31622776601683794,
    "method": "de_full_11D",
    "n_free": 11,
    "null_channels": [
      "gap",
      "retaliation",
      "strain"
    ],
    "population": "Samara",
    "session": "Samara_P_S1",
    "knockout_active_channels": [
      "inertia"
    ],
    "knockout_null_channels": [
      "no_gap",
      "no_retaliation",
      "no_strain"
    ],
    "active_channels": [
      "inertia"
    ],
    "gap_classification": "prosocial",
    "behavioral_profile": "antisocial-controller",
    "contribution_trajectory": [
      10,
      0,
      0,
      0,
      0,
      1,
      0,
      0,
      0,
      0
    ],
    "punishment_sent_trajectory": [
      3,
      0,
      2,
      0,
      1,
      1,
      2,
      2,
      0,
      1
    ],
    "punishment_received_trajectory": [
      10,
      7,
      0,
      0,
      0,
      1,
      2,
      1,
      1,
      1
    ],
    "total_voluntary_spend_trajectory": [
      13,
      0,
      2,
      0,
      1,
      2,
      2,
      2,
      0,
      1
    ],
    "others_mean_trajectory": [
      6.7,
      4.3,
      1.7,
      3.7,
      1.0,
      0.7,
      0.3,
      2.3,
      0.0,
      1.7
    ],
    "mean_contribution": 1.1,
    "mean_punishment_sent": 1.2,
    "mean_punishment_received": 2.3,
    "mean_total_voluntary_spend": 2.3,
    "antisocial_punishment_total": 10,
    "prosocial_punishment_total": 2,
    "antisocial_ratio": 0.833,
    "group_id": "702"
  },
  "716": {
    "params": {
      "p_base": 0.02255805087299073,
      "p_scale": 29.00183599539045,
      "gap_weight": 0.0,
      "gap_direction": 0.13957634881385217,
      "retaliation_w": 0.0,
      "strain_rate": 0.11422797222752301,
      "strain_initial": 4.160749369535876,
      "discharge_thresh": 0.10400129577201644,
      "discharge_frac": 0.8752077686425823,
      "inertia_w": 0.0,
      "decay_rate": 0.21684994597734775
    },
    "params_list": [
      0.02255805087299073,
      29.00183599539045,
      0.0,
      0.13957634881385217,
      0.0,
      0.11422797222752301,
      4.160749369535876,
      0.10400129577201644,
      0.8752077686425823,
      0.0,
      0.21684994597734775
    ],
    "actual": [
      30,
      15,
      0,
      0,
      0,
      3,
      3,
      0,
      3,
      3
    ],
    "predicted": [
      30,
      15,
      1,
      1,
      1,
      1,
      3,
      1,
      1,
      1
    ],
    "rmse": 1.2649110640673518,
    "method": "de_channel_selective",
    "n_free": 8,
    "null_channels": [
      "gap",
      "retaliation",
      "inertia"
    ],
    "population": "Samara",
    "session": "Samara_P_S1",
    "knockout_active_channels": [
      "strain"
    ],
    "knockout_null_channels": [
      "no_gap",
      "no_retaliation",
      "no_inertia"
    ],
    "active_channels": [
      "strain"
    ],
    "gap_classification": "gap-null",
    "behavioral_profile": "antisocial-controller",
    "contribution_trajectory": [
      0,
      0,
      5,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "punishment_sent_trajectory": [
      30,
      15,
      0,
      0,
      0,
      3,
      3,
      0,
      3,
      3
    ],
    "punishment_received_trajectory": [
      3,
      4,
      1,
      1,
      1,
      0,
      2,
      1,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      30,
      15,
      5,
      0,
      0,
      3,
      3,
      0,
      3,
      3
    ],
    "others_mean_trajectory": [
      10.0,
      4.3,
      0.0,
      3.7,
      1.0,
      1.0,
      0.3,
      2.3,
      0.0,
      1.7
    ],
    "mean_contribution": 0.5,
    "mean_punishment_sent": 5.7,
    "mean_punishment_received": 1.3,
    "mean_total_voluntary_spend": 6.2,
    "antisocial_punishment_total": 57,
    "prosocial_punishment_total": 0,
    "antisocial_ratio": 1.0,
    "group_id": "702"
  },
  "801": {
    "params": {
      "p_base": 0.0,
      "p_scale": 1.0,
      "gap_weight": 0.0,
      "gap_direction": 0.0,
      "retaliation_w": 0.0,
      "strain_rate": 0.05,
      "strain_initial": 0.0,
      "discharge_thresh": 5.0,
      "discharge_frac": 0.1,
      "inertia_w": 0.0,
      "decay_rate": 1.0
    },
    "params_list": [
      0.0,
      1.0,
      0.0,
      0.0,
      0.0,
      0.05,
      0.0,
      5.0,
      0.1,
      0.0,
      1.0
    ],
    "actual": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "predicted": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "rmse": 0.0,
    "method": "zero_shortcut",
    "n_free": 0,
    "null_channels": [
      "no_gap",
      "no_retaliation",
      "no_strain",
      "no_inertia"
    ],
    "population": "Samara",
    "session": "Samara_P_S2",
    "knockout_active_channels": [],
    "knockout_null_channels": [
      "no_gap",
      "no_retaliation",
      "no_strain",
      "no_inertia"
    ],
    "active_channels": [],
    "gap_classification": "gap-null",
    "behavioral_profile": "cooperator",
    "contribution_trajectory": [
      10,
      10,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "punishment_sent_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "punishment_received_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      10,
      10,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "others_mean_trajectory": [
      11.7,
      16.7,
      19.3,
      19.7,
      18.3,
      18.7,
      19.7,
      19.3,
      20.0,
      20.0
    ],
    "mean_contribution": 18.0,
    "mean_punishment_sent": 0.0,
    "mean_punishment_received": 0.0,
    "mean_total_voluntary_spend": 18.0,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 0,
    "antisocial_ratio": 0.0,
    "group_id": "801"
  },
  "807": {
    "params": {
      "p_base": 0.0,
      "p_scale": 1.0,
      "gap_weight": 0.0,
      "gap_direction": 0.0,
      "retaliation_w": 0.0,
      "strain_rate": 0.05,
      "strain_initial": 0.0,
      "discharge_thresh": 5.0,
      "discharge_frac": 0.1,
      "inertia_w": 0.0,
      "decay_rate": 1.0
    },
    "params_list": [
      0.0,
      1.0,
      0.0,
      0.0,
      0.0,
      0.05,
      0.0,
      5.0,
      0.1,
      0.0,
      1.0
    ],
    "actual": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "predicted": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "rmse": 0.0,
    "method": "zero_shortcut",
    "n_free": 0,
    "null_channels": [
      "no_gap",
      "no_retaliation",
      "no_strain",
      "no_inertia"
    ],
    "population": "Samara",
    "session": "Samara_P_S2",
    "knockout_active_channels": [],
    "knockout_null_channels": [
      "no_gap",
      "no_retaliation",
      "no_strain",
      "no_inertia"
    ],
    "active_channels": [],
    "gap_classification": "gap-null",
    "behavioral_profile": "cooperator",
    "contribution_trajectory": [
      10,
      15,
      20,
      19,
      20,
      19,
      19,
      19,
      20,
      20
    ],
    "punishment_sent_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "punishment_received_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      10,
      15,
      20,
      19,
      20,
      19,
      19,
      19,
      20,
      20
    ],
    "others_mean_trajectory": [
      11.7,
      15.0,
      19.3,
      20.0,
      18.3,
      19.0,
      20.0,
      19.7,
      20.0,
      20.0
    ],
    "mean_contribution": 18.1,
    "mean_punishment_sent": 0.0,
    "mean_punishment_received": 0.0,
    "mean_total_voluntary_spend": 18.1,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 0,
    "antisocial_ratio": 0.0,
    "group_id": "801"
  },
  "809": {
    "params": {
      "p_base": 0.0,
      "p_scale": 1.0,
      "gap_weight": 0.0,
      "gap_direction": 0.0,
      "retaliation_w": 0.0,
      "strain_rate": 0.05,
      "strain_initial": 0.0,
      "discharge_thresh": 5.0,
      "discharge_frac": 0.1,
      "inertia_w": 0.0,
      "decay_rate": 1.0
    },
    "params_list": [
      0.0,
      1.0,
      0.0,
      0.0,
      0.0,
      0.05,
      0.0,
      5.0,
      0.1,
      0.0,
      1.0
    ],
    "actual": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "predicted": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "rmse": 0.0,
    "method": "zero_shortcut",
    "n_free": 0,
    "null_channels": [
      "no_gap",
      "no_retaliation",
      "no_strain",
      "no_inertia"
    ],
    "population": "Samara",
    "session": "Samara_P_S2",
    "knockout_active_channels": [],
    "knockout_null_channels": [
      "no_gap",
      "no_retaliation",
      "no_strain",
      "no_inertia"
    ],
    "active_channels": [],
    "gap_classification": "gap-null",
    "behavioral_profile": "cooperator",
    "contribution_trajectory": [
      20,
      20,
      20,
      20,
      15,
      10,
      10,
      10,
      15,
      10
    ],
    "punishment_sent_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "punishment_received_trajectory": [
      2,
      0,
      0,
      0,
      0,
      1,
      0,
      0,
      0,
      1
    ],
    "total_voluntary_spend_trajectory": [
      20,
      20,
      20,
      20,
      15,
      10,
      10,
      10,
      15,
      10
    ],
    "others_mean_trajectory": [
      8.7,
      5.0,
      7.7,
      8.7,
      3.7,
      9.0,
      8.3,
      8.3,
      7.0,
      11.3
    ],
    "mean_contribution": 15.0,
    "mean_punishment_sent": 0.0,
    "mean_punishment_received": 0.4,
    "mean_total_voluntary_spend": 15.0,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 0,
    "antisocial_ratio": 0.0,
    "group_id": "804"
  },
  "814": {
    "params": {
      "p_base": 0.0,
      "p_scale": 1.0,
      "gap_weight": 0.0,
      "gap_direction": 0.0,
      "retaliation_w": 0.0,
      "strain_rate": 0.05,
      "strain_initial": 0.0,
      "discharge_thresh": 5.0,
      "discharge_frac": 0.1,
      "inertia_w": 0.0,
      "decay_rate": 1.0
    },
    "params_list": [
      0.0,
      1.0,
      0.0,
      0.0,
      0.0,
      0.05,
      0.0,
      5.0,
      0.1,
      0.0,
      1.0
    ],
    "actual": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "predicted": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "rmse": 0.0,
    "method": "zero_shortcut",
    "n_free": 0,
    "null_channels": [
      "no_gap",
      "no_retaliation",
      "no_strain",
      "no_inertia"
    ],
    "population": "Samara",
    "session": "Samara_P_S2",
    "knockout_active_channels": [],
    "knockout_null_channels": [
      "no_gap",
      "no_retaliation",
      "no_strain",
      "no_inertia"
    ],
    "active_channels": [],
    "gap_classification": "gap-null",
    "behavioral_profile": "cooperator",
    "contribution_trajectory": [
      10,
      15,
      18,
      20,
      20,
      17,
      20,
      20,
      20,
      20
    ],
    "punishment_sent_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "punishment_received_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      10,
      15,
      18,
      20,
      20,
      17,
      20,
      20,
      20,
      20
    ],
    "others_mean_trajectory": [
      11.7,
      15.0,
      20.0,
      19.7,
      18.3,
      19.7,
      19.7,
      19.3,
      20.0,
      20.0
    ],
    "mean_contribution": 18.0,
    "mean_punishment_sent": 0.0,
    "mean_punishment_received": 0.0,
    "mean_total_voluntary_spend": 18.0,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 0,
    "antisocial_ratio": 0.0,
    "group_id": "801"
  },
  "816": {
    "params": {
      "p_base": 0.0,
      "p_scale": 1.0,
      "gap_weight": 0.0,
      "gap_direction": 0.0,
      "retaliation_w": 0.0,
      "strain_rate": 0.05,
      "strain_initial": 0.0,
      "discharge_thresh": 5.0,
      "discharge_frac": 0.1,
      "inertia_w": 0.0,
      "decay_rate": 1.0
    },
    "params_list": [
      0.0,
      1.0,
      0.0,
      0.0,
      0.0,
      0.05,
      0.0,
      5.0,
      0.1,
      0.0,
      1.0
    ],
    "actual": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "predicted": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "rmse": 0.0,
    "method": "zero_shortcut",
    "n_free": 0,
    "null_channels": [
      "no_gap",
      "no_retaliation",
      "no_strain",
      "no_inertia"
    ],
    "population": "Samara",
    "session": "Samara_P_S2",
    "knockout_active_channels": [],
    "knockout_null_channels": [
      "no_gap",
      "no_retaliation",
      "no_strain",
      "no_inertia"
    ],
    "active_channels": [],
    "gap_classification": "gap-null",
    "behavioral_profile": "cooperator",
    "contribution_trajectory": [
      15,
      20,
      20,
      20,
      15,
      20,
      20,
      19,
      20,
      20
    ],
    "punishment_sent_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "punishment_received_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      15,
      20,
      20,
      20,
      15,
      20,
      20,
      19,
      20,
      20
    ],
    "others_mean_trajectory": [
      10.0,
      13.3,
      19.3,
      19.7,
      20.0,
      18.7,
      19.7,
      19.7,
      20.0,
      20.0
    ],
    "mean_contribution": 18.9,
    "mean_punishment_sent": 0.0,
    "mean_punishment_received": 0.0,
    "mean_total_voluntary_spend": 18.9,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 0,
    "antisocial_ratio": 0.0,
    "group_id": "801"
  },
  "806": {
    "params": {
      "p_base": 0.01784607036150382,
      "p_scale": 29.460329271428996,
      "gap_weight": 0.9900001632063075,
      "gap_direction": 0.9668918402727598,
      "retaliation_w": 0.008325837797812208,
      "strain_rate": 1.3203647631783437,
      "strain_initial": 1.664374954106746,
      "discharge_thresh": 3.9845022548661664,
      "discharge_frac": 0.9162503876065521,
      "inertia_w": -0.18270796238845666,
      "decay_rate": 0.9615944410917767
    },
    "params_list": [
      0.01784607036150382,
      29.460329271428996,
      0.9900001632063075,
      0.9668918402727598,
      0.008325837797812208,
      1.3203647631783437,
      1.664374954106746,
      3.9845022548661664,
      0.9162503876065521,
      -0.18270796238845666,
      0.9615944410917767
    ],
    "actual": [
      1,
      0,
      0,
      0,
      0,
      3,
      0,
      0,
      0,
      0
    ],
    "predicted": [
      1,
      0,
      0,
      0,
      0,
      2,
      0,
      0,
      0,
      0
    ],
    "rmse": 0.31622776601683794,
    "method": "de_full_11D",
    "n_free": 11,
    "null_channels": [],
    "population": "Samara",
    "session": "Samara_P_S2",
    "knockout_active_channels": [
      "gap"
    ],
    "knockout_null_channels": [
      "no_retaliation",
      "no_strain",
      "no_inertia"
    ],
    "active_channels": [
      "gap"
    ],
    "gap_classification": "prosocial",
    "behavioral_profile": "free-rider",
    "contribution_trajectory": [
      5,
      4,
      5,
      5,
      5,
      8,
      5,
      5,
      5,
      3
    ],
    "punishment_sent_trajectory": [
      1,
      0,
      0,
      0,
      0,
      3,
      0,
      0,
      0,
      0
    ],
    "punishment_received_trajectory": [
      1,
      2,
      0,
      1,
      2,
      0,
      1,
      0,
      0,
      1
    ],
    "total_voluntary_spend_trajectory": [
      6,
      4,
      5,
      5,
      5,
      11,
      5,
      5,
      5,
      3
    ],
    "others_mean_trajectory": [
      7.7,
      7.7,
      5.3,
      8.3,
      6.7,
      7.0,
      6.7,
      6.0,
      6.3,
      4.7
    ],
    "mean_contribution": 5.0,
    "mean_punishment_sent": 0.4,
    "mean_punishment_received": 0.8,
    "mean_total_voluntary_spend": 5.4,
    "antisocial_punishment_total": 1,
    "prosocial_punishment_total": 3,
    "antisocial_ratio": 0.25,
    "group_id": "803"
  },
  "810": {
    "params": {
      "p_base": 0.41652920530281556,
      "p_scale": 7.053662942916356,
      "gap_weight": 0.7181229167291434,
      "gap_direction": 0.71754322875924,
      "retaliation_w": 0.8358580111844969,
      "strain_rate": 0.8641540641067654,
      "strain_initial": 0.851706462874696,
      "discharge_thresh": 3.3456665448873943,
      "discharge_frac": 0.5395256700763176,
      "inertia_w": -0.26249498166581703,
      "decay_rate": 0.2965232479221341
    },
    "params_list": [
      0.41652920530281556,
      7.053662942916356,
      0.7181229167291434,
      0.71754322875924,
      0.8358580111844969,
      0.8641540641067654,
      0.851706462874696,
      3.3456665448873943,
      0.5395256700763176,
      -0.26249498166581703,
      0.2965232479221341
    ],
    "actual": [
      3,
      0,
      5,
      1,
      2,
      3,
      3,
      2,
      3,
      0
    ],
    "predicted": [
      3,
      1,
      3,
      1,
      3,
      3,
      2,
      2,
      3,
      1
    ],
    "rmse": 0.8944271909999159,
    "method": "de_full_11D",
    "n_free": 11,
    "null_channels": [],
    "population": "Samara",
    "session": "Samara_P_S2",
    "knockout_active_channels": [],
    "knockout_null_channels": [
      "no_gap",
      "no_retaliation",
      "no_strain",
      "no_inertia"
    ],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "mixed",
    "contribution_trajectory": [
      10,
      0,
      10,
      6,
      0,
      12,
      10,
      0,
      9,
      9
    ],
    "punishment_sent_trajectory": [
      3,
      0,
      5,
      1,
      2,
      3,
      3,
      2,
      3,
      0
    ],
    "punishment_received_trajectory": [
      0,
      3,
      0,
      5,
      3,
      0,
      0,
      6,
      0,
      3
    ],
    "total_voluntary_spend_trajectory": [
      13,
      0,
      15,
      7,
      2,
      15,
      13,
      2,
      12,
      9
    ],
    "others_mean_trajectory": [
      12.0,
      11.7,
      11.0,
      13.3,
      8.7,
      8.3,
      8.3,
      11.7,
      9.0,
      11.7
    ],
    "mean_contribution": 6.6,
    "mean_punishment_sent": 2.2,
    "mean_punishment_received": 2.0,
    "mean_total_voluntary_spend": 8.8,
    "antisocial_punishment_total": 6,
    "prosocial_punishment_total": 16,
    "antisocial_ratio": 0.273,
    "group_id": "804"
  },
  "811": {
    "params": {
      "p_base": 0.07577683716966538,
      "p_scale": 11.747354887000515,
      "gap_weight": 0.5243415016694984,
      "gap_direction": 0.6889912664394493,
      "retaliation_w": 0.9040825244683653,
      "strain_rate": 1.6791140637412842,
      "strain_initial": 0.45568634158429244,
      "discharge_thresh": 4.302818288600777,
      "discharge_frac": 0.45670619370654775,
      "inertia_w": -0.06319771537644386,
      "decay_rate": 0.48125525029205185
    },
    "params_list": [
      0.07577683716966538,
      11.747354887000515,
      0.5243415016694984,
      0.6889912664394493,
      0.9040825244683653,
      1.6791140637412842,
      0.45568634158429244,
      4.302818288600777,
      0.45670619370654775,
      -0.06319771537644386,
      0.48125525029205185
    ],
    "actual": [
      1,
      2,
      0,
      7,
      2,
      0,
      0,
      6,
      0,
      2
    ],
    "predicted": [
      1,
      1,
      1,
      5,
      1,
      2,
      2,
      6,
      0,
      3
    ],
    "rmse": 1.2649110640673518,
    "method": "de_full_11D",
    "n_free": 11,
    "null_channels": [],
    "population": "Samara",
    "session": "Samara_P_S2",
    "knockout_active_channels": [
      "retaliation"
    ],
    "knockout_null_channels": [
      "no_gap",
      "no_strain",
      "no_inertia"
    ],
    "active_channels": [
      "retaliation"
    ],
    "gap_classification": "prosocial",
    "behavioral_profile": "mixed",
    "contribution_trajectory": [
      10,
      5,
      3,
      10,
      5,
      5,
      5,
      20,
      2,
      5
    ],
    "punishment_sent_trajectory": [
      1,
      2,
      0,
      7,
      2,
      0,
      0,
      6,
      0,
      2
    ],
    "punishment_received_trajectory": [
      0,
      1,
      6,
      0,
      2,
      2,
      3,
      0,
      4,
      1
    ],
    "total_voluntary_spend_trajectory": [
      11,
      7,
      3,
      17,
      7,
      5,
      5,
      26,
      2,
      7
    ],
    "others_mean_trajectory": [
      12.0,
      10.0,
      13.3,
      12.0,
      7.0,
      10.7,
      10.0,
      5.0,
      11.3,
      13.0
    ],
    "mean_contribution": 7.0,
    "mean_punishment_sent": 2.0,
    "mean_punishment_received": 1.9,
    "mean_total_voluntary_spend": 9.0,
    "antisocial_punishment_total": 5,
    "prosocial_punishment_total": 15,
    "antisocial_ratio": 0.25,
    "group_id": "804"
  },
  "815": {
    "params": {
      "p_base": 0.03172944336467698,
      "p_scale": 12.776791177063144,
      "gap_weight": 0.7357250804304821,
      "gap_direction": 0.8343213903748452,
      "retaliation_w": 0.8757531901528899,
      "strain_rate": 0.8787300410663188,
      "strain_initial": 0.04508641097656607,
      "discharge_thresh": 0.4808114622642137,
      "discharge_frac": 0.20345992078122022,
      "inertia_w": -0.4101298653589276,
      "decay_rate": 0.5435719756965887
    },
    "params_list": [
      0.03172944336467698,
      12.776791177063144,
      0.7357250804304821,
      0.8343213903748452,
      0.8757531901528899,
      0.8787300410663188,
      0.04508641097656607,
      0.4808114622642137,
      0.20345992078122022,
      -0.4101298653589276,
      0.5435719756965887
    ],
    "actual": [
      0,
      2,
      1,
      0,
      2,
      0,
      0,
      1,
      1,
      3
    ],
    "predicted": [
      0,
      2,
      0,
      0,
      2,
      0,
      0,
      1,
      1,
      3
    ],
    "rmse": 0.31622776601683794,
    "method": "de_full_11D",
    "n_free": 11,
    "null_channels": [],
    "population": "Samara",
    "session": "Samara_P_S2",
    "knockout_active_channels": [
      "gap"
    ],
    "knockout_null_channels": [
      "no_retaliation",
      "no_strain",
      "no_inertia"
    ],
    "active_channels": [
      "gap"
    ],
    "gap_classification": "prosocial",
    "behavioral_profile": "mixed",
    "contribution_trajectory": [
      6,
      10,
      10,
      10,
      6,
      10,
      10,
      5,
      10,
      20
    ],
    "punishment_sent_trajectory": [
      0,
      2,
      1,
      0,
      2,
      0,
      0,
      1,
      1,
      3
    ],
    "punishment_received_trajectory": [
      2,
      0,
      0,
      3,
      1,
      0,
      0,
      3,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      6,
      12,
      11,
      10,
      8,
      10,
      10,
      6,
      11,
      23
    ],
    "others_mean_trajectory": [
      13.3,
      8.3,
      11.0,
      12.0,
      6.7,
      9.0,
      8.3,
      10.0,
      8.7,
      8.0
    ],
    "mean_contribution": 9.7,
    "mean_punishment_sent": 1.0,
    "mean_punishment_received": 0.9,
    "mean_total_voluntary_spend": 10.7,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 10,
    "antisocial_ratio": 0.0,
    "group_id": "804"
  },
  "804": {
    "params": {
      "p_base": 0.12469163814984718,
      "p_scale": 1.1523051652629412,
      "gap_weight": 0.0,
      "gap_direction": -0.0042026032031633465,
      "retaliation_w": 0.0,
      "strain_rate": 1.7027799814672948,
      "strain_initial": 2.7606878058370734,
      "discharge_thresh": 2.9774770281740364,
      "discharge_frac": 0.7638981428596533,
      "inertia_w": 0.0,
      "decay_rate": 0.5637298403162688
    },
    "params_list": [
      0.12469163814984718,
      1.1523051652629412,
      0.0,
      -0.0042026032031633465,
      0.0,
      1.7027799814672948,
      2.7606878058370734,
      2.9774770281740364,
      0.7638981428596533,
      0.0,
      0.5637298403162688
    ],
    "actual": [
      0,
      1,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "predicted": [
      0,
      1,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "rmse": 0.0,
    "method": "de_channel_selective",
    "n_free": 8,
    "null_channels": [
      "no_gap",
      "no_retaliation",
      "no_inertia"
    ],
    "population": "Samara",
    "session": "Samara_P_S2",
    "knockout_active_channels": [
      "strain"
    ],
    "knockout_null_channels": [
      "no_gap",
      "no_retaliation",
      "no_inertia"
    ],
    "active_channels": [
      "strain"
    ],
    "gap_classification": "gap-null",
    "behavioral_profile": "mixed",
    "contribution_trajectory": [
      8,
      8,
      8,
      5,
      8,
      10,
      5,
      8,
      8,
      0
    ],
    "punishment_sent_trajectory": [
      0,
      1,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "punishment_received_trajectory": [
      1,
      1,
      1,
      0,
      0,
      0,
      2,
      2,
      0,
      5
    ],
    "total_voluntary_spend_trajectory": [
      8,
      9,
      8,
      5,
      8,
      10,
      5,
      8,
      8,
      0
    ],
    "others_mean_trajectory": [
      6.7,
      6.3,
      4.3,
      8.3,
      5.7,
      6.3,
      6.7,
      5.0,
      5.3,
      5.7
    ],
    "mean_contribution": 6.8,
    "mean_punishment_sent": 0.1,
    "mean_punishment_received": 1.2,
    "mean_total_voluntary_spend": 6.9,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 1,
    "antisocial_ratio": 0.0,
    "group_id": "803"
  },
  "802": {
    "params": {
      "p_base": 0.0024837500820601432,
      "p_scale": 13.103447736293198,
      "gap_weight": 0.598028135136631,
      "gap_direction": 0.9476763508572008,
      "retaliation_w": 0.10692715026784722,
      "strain_rate": 0.059715255134070944,
      "strain_initial": 0.2295790523828254,
      "discharge_thresh": 0.27295247523212973,
      "discharge_frac": 0.24265346354371076,
      "inertia_w": 0.004292003849814124,
      "decay_rate": 0.13400070047395696
    },
    "params_list": [
      0.0024837500820601432,
      13.103447736293198,
      0.598028135136631,
      0.9476763508572008,
      0.10692715026784722,
      0.059715255134070944,
      0.2295790523828254,
      0.27295247523212973,
      0.24265346354371076,
      0.004292003849814124,
      0.13400070047395696
    ],
    "actual": [
      0,
      0,
      0,
      1,
      1,
      1,
      1,
      0,
      0,
      1
    ],
    "predicted": [
      0,
      0,
      0,
      1,
      1,
      1,
      1,
      0,
      0,
      1
    ],
    "rmse": 0.0,
    "method": "de_full_11D",
    "n_free": 11,
    "null_channels": [],
    "population": "Samara",
    "session": "Samara_P_S2",
    "knockout_active_channels": [],
    "knockout_null_channels": [
      "no_gap",
      "no_retaliation",
      "no_strain",
      "no_inertia"
    ],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperative-enforcer",
    "contribution_trajectory": [
      8,
      10,
      10,
      15,
      10,
      15,
      15,
      20,
      20,
      20
    ],
    "punishment_sent_trajectory": [
      0,
      0,
      0,
      1,
      1,
      1,
      1,
      0,
      0,
      1
    ],
    "punishment_received_trajectory": [
      3,
      2,
      3,
      0,
      3,
      0,
      1,
      0,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      8,
      10,
      10,
      16,
      11,
      16,
      16,
      20,
      20,
      21
    ],
    "others_mean_trajectory": [
      16.7,
      14.0,
      18.3,
      13.3,
      12.3,
      13.3,
      13.3,
      20.0,
      18.7,
      18.3
    ],
    "mean_contribution": 14.3,
    "mean_punishment_sent": 0.5,
    "mean_punishment_received": 1.2,
    "mean_total_voluntary_spend": 14.8,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 5,
    "antisocial_ratio": 0.0,
    "group_id": "802"
  },
  "813": {
    "params": {
      "p_base": 0.14765819040450545,
      "p_scale": 5.395816141727577,
      "gap_weight": 0.715893793061138,
      "gap_direction": 0.25694310131665876,
      "retaliation_w": 0.26985960435195155,
      "strain_rate": 2.9773372404536067,
      "strain_initial": 3.925228922704591,
      "discharge_thresh": 4.8578502426262915,
      "discharge_frac": 0.8474606979475565,
      "inertia_w": 0.2545012245418061,
      "decay_rate": 0.6793710425406478
    },
    "params_list": [
      0.14765819040450545,
      5.395816141727577,
      0.715893793061138,
      0.25694310131665876,
      0.26985960435195155,
      2.9773372404536067,
      3.925228922704591,
      4.8578502426262915,
      0.8474606979475565,
      0.2545012245418061,
      0.6793710425406478
    ],
    "actual": [
      1,
      5,
      2,
      1,
      1,
      0,
      1,
      2,
      0,
      2
    ],
    "predicted": [
      1,
      5,
      2,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "rmse": 0.6324555320336759,
    "method": "de_full_11D",
    "n_free": 11,
    "null_channels": [],
    "population": "Samara",
    "session": "Samara_P_S2",
    "knockout_active_channels": [
      "strain"
    ],
    "knockout_null_channels": [
      "no_gap",
      "no_retaliation",
      "no_inertia"
    ],
    "active_channels": [
      "strain"
    ],
    "gap_classification": "neutral",
    "behavioral_profile": "antisocial-controller",
    "contribution_trajectory": [
      5,
      0,
      0,
      10,
      1,
      1,
      5,
      2,
      3,
      3
    ],
    "punishment_sent_trajectory": [
      1,
      5,
      2,
      1,
      1,
      0,
      1,
      2,
      0,
      2
    ],
    "punishment_received_trajectory": [
      2,
      3,
      2,
      0,
      1,
      5,
      2,
      1,
      1,
      1
    ],
    "total_voluntary_spend_trajectory": [
      6,
      5,
      2,
      11,
      2,
      1,
      6,
      4,
      3,
      5
    ],
    "others_mean_trajectory": [
      7.7,
      9.0,
      7.0,
      6.7,
      8.0,
      9.3,
      6.7,
      7.0,
      7.0,
      4.7
    ],
    "mean_contribution": 3.0,
    "mean_punishment_sent": 1.5,
    "mean_punishment_received": 1.8,
    "mean_total_voluntary_spend": 4.5,
    "antisocial_punishment_total": 12,
    "prosocial_punishment_total": 3,
    "antisocial_ratio": 0.8,
    "group_id": "803"
  },
  "812": {
    "params": {
      "p_base": 0.238356827007208,
      "p_scale": 1.8792752886193256,
      "gap_weight": 0.9903771939179802,
      "gap_direction": 0.9927035005155884,
      "retaliation_w": 0.7184003367369088,
      "strain_rate": 0.21197374811943615,
      "strain_initial": 9.660487141522545,
      "discharge_thresh": 0.7799657328136369,
      "discharge_frac": 0.45247116368581797,
      "inertia_w": -0.031032645483989707,
      "decay_rate": 0.2615926751783425
    },
    "params_list": [
      0.238356827007208,
      1.8792752886193256,
      0.9903771939179802,
      0.9927035005155884,
      0.7184003367369088,
      0.21197374811943615,
      9.660487141522545,
      0.7799657328136369,
      0.45247116368581797,
      -0.031032645483989707,
      0.2615926751783425
    ],
    "actual": [
      2,
      4,
      3,
      2,
      2,
      1,
      1,
      0,
      3,
      0
    ],
    "predicted": [
      2,
      3,
      3,
      2,
      2,
      1,
      1,
      0,
      1,
      0
    ],
    "rmse": 0.7071067811865476,
    "method": "de_full_11D",
    "n_free": 11,
    "null_channels": [],
    "population": "Samara",
    "session": "Samara_P_S2",
    "knockout_active_channels": [],
    "knockout_null_channels": [
      "no_gap",
      "no_retaliation",
      "no_strain",
      "no_inertia"
    ],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperative-enforcer",
    "contribution_trajectory": [
      15,
      20,
      20,
      20,
      15,
      20,
      20,
      20,
      20,
      15
    ],
    "punishment_sent_trajectory": [
      2,
      4,
      3,
      2,
      2,
      1,
      1,
      0,
      3,
      0
    ],
    "punishment_received_trajectory": [
      0,
      0,
      1,
      1,
      0,
      0,
      1,
      0,
      0,
      4
    ],
    "total_voluntary_spend_trajectory": [
      17,
      24,
      23,
      22,
      17,
      21,
      21,
      20,
      23,
      15
    ],
    "others_mean_trajectory": [
      14.3,
      10.7,
      15.0,
      11.7,
      10.7,
      11.7,
      11.7,
      20.0,
      18.7,
      20.0
    ],
    "mean_contribution": 18.5,
    "mean_punishment_sent": 1.8,
    "mean_punishment_received": 0.7,
    "mean_total_voluntary_spend": 20.3,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 18,
    "antisocial_ratio": 0.0,
    "group_id": "802"
  },
  "805": {
    "params": {
      "p_base": 0.20703254934841475,
      "p_scale": 2.332624475941902,
      "gap_weight": 0.4044311928563631,
      "gap_direction": 0.9829165906601041,
      "retaliation_w": 0.34036431966466657,
      "strain_rate": 0.6449281599496411,
      "strain_initial": 2.438109878852624,
      "discharge_thresh": 3.1635774727698736,
      "discharge_frac": 0.4592438960587464,
      "inertia_w": -0.30442002063282525,
      "decay_rate": 0.5388878823455827
    },
    "params_list": [
      0.20703254934841475,
      2.332624475941902,
      0.4044311928563631,
      0.9829165906601041,
      0.34036431966466657,
      0.6449281599496411,
      2.438109878852624,
      3.1635774727698736,
      0.4592438960587464,
      -0.30442002063282525,
      0.5388878823455827
    ],
    "actual": [
      0,
      0,
      1,
      1,
      2,
      0,
      1,
      0,
      0,
      2
    ],
    "predicted": [
      0,
      0,
      1,
      0,
      2,
      0,
      1,
      0,
      0,
      1
    ],
    "rmse": 0.4472135954999579,
    "method": "de_full_11D",
    "n_free": 11,
    "null_channels": [],
    "population": "Samara",
    "session": "Samara_P_S2",
    "knockout_active_channels": [],
    "knockout_null_channels": [
      "no_gap",
      "no_retaliation",
      "no_strain",
      "no_inertia"
    ],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "mixed",
    "contribution_trajectory": [
      15,
      2,
      15,
      0,
      2,
      0,
      0,
      20,
      16,
      20
    ],
    "punishment_sent_trajectory": [
      0,
      0,
      1,
      1,
      2,
      0,
      1,
      0,
      0,
      2
    ],
    "punishment_received_trajectory": [
      0,
      6,
      1,
      8,
      5,
      8,
      11,
      0,
      4,
      0
    ],
    "total_voluntary_spend_trajectory": [
      15,
      2,
      16,
      1,
      4,
      0,
      1,
      20,
      16,
      22
    ],
    "others_mean_trajectory": [
      14.3,
      16.7,
      16.7,
      18.3,
      15.0,
      18.3,
      18.3,
      20.0,
      20.0,
      18.3
    ],
    "mean_contribution": 9.0,
    "mean_punishment_sent": 0.7,
    "mean_punishment_received": 4.3,
    "mean_total_voluntary_spend": 9.7,
    "antisocial_punishment_total": 5,
    "prosocial_punishment_total": 2,
    "antisocial_ratio": 0.714,
    "group_id": "802"
  },
  "803": {
    "params": {
      "p_base": 0.03678864954085792,
      "p_scale": 28.878273387128665,
      "gap_weight": 0.9981546947405553,
      "gap_direction": 0.2624616956695247,
      "retaliation_w": 0.8511846851578667,
      "strain_rate": 2.73778077005856,
      "strain_initial": 0.24460320657429602,
      "discharge_thresh": 0.24833432284604084,
      "discharge_frac": 0.11960755537772577,
      "inertia_w": 0.09324802070231455,
      "decay_rate": 0.9411641692225253
    },
    "params_list": [
      0.03678864954085792,
      28.878273387128665,
      0.9981546947405553,
      0.2624616956695247,
      0.8511846851578667,
      2.73778077005856,
      0.24460320657429602,
      0.24833432284604084,
      0.11960755537772577,
      0.09324802070231455,
      0.9411641692225253
    ],
    "actual": [
      1,
      4,
      1,
      5,
      4,
      6,
      10,
      0,
      1,
      1
    ],
    "predicted": [
      1,
      4,
      1,
      4,
      6,
      7,
      6,
      2,
      2,
      1
    ],
    "rmse": 1.6431676725154984,
    "method": "de_full_11D",
    "n_free": 11,
    "null_channels": [],
    "population": "Samara",
    "session": "Samara_P_S2",
    "knockout_active_channels": [
      "gap"
    ],
    "knockout_null_channels": [
      "no_retaliation",
      "no_strain",
      "no_inertia"
    ],
    "active_channels": [
      "gap"
    ],
    "gap_classification": "neutral",
    "behavioral_profile": "cooperative-enforcer",
    "contribution_trajectory": [
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "punishment_sent_trajectory": [
      1,
      4,
      1,
      5,
      4,
      6,
      10,
      0,
      1,
      1
    ],
    "punishment_received_trajectory": [
      0,
      0,
      0,
      0,
      1,
      0,
      0,
      0,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      21,
      24,
      21,
      25,
      24,
      26,
      30,
      20,
      21,
      21
    ],
    "others_mean_trajectory": [
      12.7,
      10.7,
      15.0,
      11.7,
      9.0,
      11.7,
      11.7,
      20.0,
      18.7,
      18.3
    ],
    "mean_contribution": 20.0,
    "mean_punishment_sent": 3.3,
    "mean_punishment_received": 0.1,
    "mean_total_voluntary_spend": 23.3,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 33,
    "antisocial_ratio": 0.0,
    "group_id": "802"
  },
  "808": {
    "params": {
      "p_base": 0.18230774455587956,
      "p_scale": 4.452863286106959,
      "gap_weight": 0.9586978677897318,
      "gap_direction": 0.9363075095595832,
      "retaliation_w": 0.0,
      "strain_rate": 2.8392695431852966,
      "strain_initial": 0.7817790981877586,
      "discharge_thresh": 1.487191611592594,
      "discharge_frac": 0.5057214591887251,
      "inertia_w": 0.0,
      "decay_rate": 0.21712110762382097
    },
    "params_list": [
      0.18230774455587956,
      4.452863286106959,
      0.9586978677897318,
      0.9363075095595832,
      0.0,
      2.8392695431852966,
      0.7817790981877586,
      1.487191611592594,
      0.5057214591887251,
      0.0,
      0.21712110762382097
    ],
    "actual": [
      2,
      2,
      2,
      0,
      2,
      2,
      5,
      1,
      1,
      5
    ],
    "predicted": [
      2,
      3,
      2,
      1,
      2,
      2,
      5,
      1,
      1,
      3
    ],
    "rmse": 0.7745966692414834,
    "method": "de_channel_selective",
    "n_free": 9,
    "null_channels": [
      "no_retaliation",
      "no_inertia"
    ],
    "population": "Samara",
    "session": "Samara_P_S2",
    "knockout_active_channels": [
      "gap",
      "strain"
    ],
    "knockout_null_channels": [
      "no_retaliation",
      "no_inertia"
    ],
    "active_channels": [
      "gap",
      "strain"
    ],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperative-enforcer",
    "contribution_trajectory": [
      10,
      15,
      8,
      10,
      11,
      10,
      10,
      8,
      8,
      11
    ],
    "punishment_sent_trajectory": [
      2,
      2,
      2,
      0,
      2,
      2,
      5,
      1,
      1,
      5
    ],
    "punishment_received_trajectory": [
      0,
      2,
      1,
      0,
      0,
      0,
      1,
      0,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      12,
      17,
      10,
      10,
      13,
      12,
      15,
      9,
      9,
      16
    ],
    "others_mean_trajectory": [
      6.0,
      4.0,
      4.3,
      6.7,
      4.7,
      6.3,
      5.0,
      5.0,
      5.3,
      2.0
    ],
    "mean_contribution": 10.1,
    "mean_punishment_sent": 2.2,
    "mean_punishment_received": 0.4,
    "mean_total_voluntary_spend": 12.3,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 22,
    "antisocial_ratio": 0.0,
    "group_id": "803"
  },
  "901": {
    "params": {},
    "params_list": [],
    "actual": [
      15,
      17,
      10,
      12,
      15,
      19,
      19,
      20,
      20,
      20
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Samara",
    "session": "Samara_P_S3",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "antisocial",
    "behavioral_profile": "cooperative-enforcer",
    "contribution_trajectory": [
      15,
      17,
      10,
      12,
      15,
      19,
      19,
      20,
      20,
      20
    ],
    "punishment_sent_trajectory": [
      1,
      1,
      3,
      2,
      3,
      0,
      0,
      1,
      0,
      0
    ],
    "punishment_received_trajectory": [
      1,
      9,
      4,
      5,
      4,
      4,
      2,
      0,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      16,
      18,
      13,
      14,
      18,
      19,
      19,
      21,
      20,
      20
    ],
    "others_mean_trajectory": [
      11.666666666666666,
      13.666666666666666,
      16.0,
      17.0,
      16.666666666666668,
      18.333333333333332,
      20.0,
      20.0,
      20.0,
      20.0
    ],
    "mean_contribution": 16.7,
    "mean_punishment_sent": 1.1,
    "mean_punishment_received": 2.9,
    "mean_total_voluntary_spend": 17.8,
    "antisocial_punishment_total": 6,
    "prosocial_punishment_total": 5,
    "antisocial_ratio": 0.5454545454545454,
    "group_id": "901"
  },
  "902": {
    "params": {},
    "params_list": [],
    "actual": [
      9,
      9,
      10,
      10,
      14,
      10,
      9,
      10,
      7,
      10
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Samara",
    "session": "Samara_P_S3",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "antisocial",
    "behavioral_profile": "mixed",
    "contribution_trajectory": [
      9,
      9,
      10,
      10,
      14,
      10,
      9,
      10,
      7,
      10
    ],
    "punishment_sent_trajectory": [
      2,
      1,
      2,
      1,
      1,
      1,
      1,
      1,
      0,
      0
    ],
    "punishment_received_trajectory": [
      1,
      1,
      0,
      0,
      0,
      2,
      8,
      0,
      5,
      6
    ],
    "total_voluntary_spend_trajectory": [
      11,
      10,
      12,
      11,
      15,
      11,
      10,
      11,
      7,
      10
    ],
    "others_mean_trajectory": [
      13.333333333333334,
      12.666666666666666,
      15.333333333333334,
      16.0,
      15.666666666666666,
      14.333333333333334,
      14.0,
      13.0,
      17.333333333333332,
      18.666666666666668
    ],
    "mean_contribution": 9.8,
    "mean_punishment_sent": 1.0,
    "mean_punishment_received": 2.3,
    "mean_total_voluntary_spend": 10.8,
    "antisocial_punishment_total": 9,
    "prosocial_punishment_total": 1,
    "antisocial_ratio": 0.9,
    "group_id": "902"
  },
  "903": {
    "params": {},
    "params_list": [],
    "actual": [
      15,
      13,
      14,
      20,
      18,
      15,
      13,
      19,
      20,
      20
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Samara",
    "session": "Samara_P_S3",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperative-enforcer",
    "contribution_trajectory": [
      15,
      13,
      14,
      20,
      18,
      15,
      13,
      19,
      20,
      20
    ],
    "punishment_sent_trajectory": [
      0,
      0,
      0,
      0,
      0,
      1,
      2,
      0,
      0,
      4
    ],
    "punishment_received_trajectory": [
      1,
      0,
      1,
      0,
      1,
      2,
      3,
      0,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      15,
      13,
      14,
      20,
      18,
      16,
      15,
      19,
      20,
      24
    ],
    "others_mean_trajectory": [
      11.333333333333334,
      11.333333333333334,
      14.0,
      12.666666666666666,
      14.333333333333334,
      12.666666666666666,
      12.666666666666666,
      10.0,
      13.0,
      15.333333333333334
    ],
    "mean_contribution": 16.7,
    "mean_punishment_sent": 0.7,
    "mean_punishment_received": 0.8,
    "mean_total_voluntary_spend": 17.4,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 7,
    "antisocial_ratio": 0.0,
    "group_id": "902"
  },
  "904": {
    "params": {},
    "params_list": [],
    "actual": [
      5,
      10,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Samara",
    "session": "Samara_P_S3",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "antisocial",
    "behavioral_profile": "cooperative-enforcer",
    "contribution_trajectory": [
      5,
      10,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "punishment_sent_trajectory": [
      0,
      26,
      3,
      4,
      2,
      4,
      4,
      0,
      0,
      0
    ],
    "punishment_received_trajectory": [
      13,
      7,
      1,
      2,
      1,
      1,
      0,
      1,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      5,
      36,
      23,
      24,
      22,
      24,
      24,
      20,
      20,
      20
    ],
    "others_mean_trajectory": [
      15.0,
      16.0,
      12.666666666666666,
      14.333333333333334,
      15.0,
      18.0,
      19.666666666666668,
      20.0,
      20.0,
      20.0
    ],
    "mean_contribution": 17.5,
    "mean_punishment_sent": 4.3,
    "mean_punishment_received": 2.6,
    "mean_total_voluntary_spend": 21.8,
    "antisocial_punishment_total": 30,
    "prosocial_punishment_total": 13,
    "antisocial_ratio": 0.6976744186046512,
    "group_id": "901"
  },
  "905": {
    "params": {},
    "params_list": [],
    "actual": [
      10,
      5,
      5,
      3,
      5,
      7,
      10,
      3,
      5,
      4
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Samara",
    "session": "Samara_P_S3",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "mixed",
    "contribution_trajectory": [
      10,
      5,
      5,
      3,
      5,
      7,
      10,
      3,
      5,
      4
    ],
    "punishment_sent_trajectory": [
      4,
      1,
      0,
      1,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "punishment_received_trajectory": [
      0,
      1,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      14,
      6,
      5,
      4,
      5,
      7,
      10,
      3,
      5,
      4
    ],
    "others_mean_trajectory": [
      5.0,
      8.333333333333334,
      2.0,
      5.333333333333333,
      4.666666666666667,
      3.6666666666666665,
      2.3333333333333335,
      5.333333333333333,
      3.6666666666666665,
      3.6666666666666665
    ],
    "mean_contribution": 5.7,
    "mean_punishment_sent": 0.6,
    "mean_punishment_received": 0.1,
    "mean_total_voluntary_spend": 6.3,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 6,
    "antisocial_ratio": 0.0,
    "group_id": "903"
  },
  "906": {
    "params": {},
    "params_list": [],
    "actual": [
      5,
      12,
      4,
      10,
      9,
      5,
      3,
      7,
      7,
      7
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Samara",
    "session": "Samara_P_S3",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "mixed",
    "contribution_trajectory": [
      5,
      12,
      4,
      10,
      9,
      5,
      3,
      7,
      7,
      7
    ],
    "punishment_sent_trajectory": [
      1,
      2,
      0,
      1,
      1,
      0,
      2,
      0,
      2,
      3
    ],
    "punishment_received_trajectory": [
      1,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      6,
      14,
      4,
      11,
      10,
      5,
      5,
      7,
      9,
      10
    ],
    "others_mean_trajectory": [
      6.666666666666667,
      6.0,
      2.3333333333333335,
      3.0,
      3.3333333333333335,
      4.333333333333333,
      4.666666666666667,
      4.0,
      3.0,
      2.6666666666666665
    ],
    "mean_contribution": 6.9,
    "mean_punishment_sent": 1.2,
    "mean_punishment_received": 0.1,
    "mean_total_voluntary_spend": 8.1,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 12,
    "antisocial_ratio": 0.0,
    "group_id": "903"
  },
  "907": {
    "params": {},
    "params_list": [],
    "actual": [
      10,
      15,
      20,
      12,
      14,
      15,
      14,
      5,
      15,
      18
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Samara",
    "session": "Samara_P_S3",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperative-enforcer",
    "contribution_trajectory": [
      10,
      15,
      20,
      12,
      14,
      15,
      14,
      5,
      15,
      18
    ],
    "punishment_sent_trajectory": [
      0,
      0,
      0,
      0,
      1,
      3,
      4,
      0,
      2,
      0
    ],
    "punishment_received_trajectory": [
      0,
      1,
      0,
      1,
      1,
      0,
      0,
      5,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      10,
      15,
      20,
      12,
      15,
      18,
      18,
      5,
      17,
      18
    ],
    "others_mean_trajectory": [
      13.0,
      10.666666666666666,
      12.0,
      15.333333333333334,
      15.666666666666666,
      12.666666666666666,
      12.333333333333334,
      14.666666666666666,
      14.666666666666666,
      16.0
    ],
    "mean_contribution": 13.8,
    "mean_punishment_sent": 1.0,
    "mean_punishment_received": 0.8,
    "mean_total_voluntary_spend": 14.8,
    "antisocial_punishment_total": 3,
    "prosocial_punishment_total": 7,
    "antisocial_ratio": 0.3,
    "group_id": "902"
  },
  "908": {
    "params": {},
    "params_list": [],
    "actual": [
      15,
      20,
      14,
      15,
      12,
      10,
      14,
      20,
      20,
      20
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Samara",
    "session": "Samara_P_S3",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperator",
    "contribution_trajectory": [
      15,
      20,
      14,
      15,
      12,
      10,
      14,
      20,
      20,
      20
    ],
    "punishment_sent_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "punishment_received_trajectory": [
      0,
      0,
      0,
      1,
      2,
      13,
      3,
      1,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      15,
      20,
      14,
      15,
      12,
      10,
      14,
      20,
      20,
      20
    ],
    "others_mean_trajectory": [
      10.666666666666666,
      11.666666666666666,
      13.333333333333334,
      13.0,
      14.0,
      15.666666666666666,
      15.0,
      15.0,
      19.0,
      20.0
    ],
    "mean_contribution": 16.0,
    "mean_punishment_sent": 0.0,
    "mean_punishment_received": 2.0,
    "mean_total_voluntary_spend": 16.0,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 0,
    "antisocial_ratio": 0.0,
    "group_id": "904"
  },
  "909": {
    "params": {},
    "params_list": [],
    "actual": [
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Samara",
    "session": "Samara_P_S3",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperative-enforcer",
    "contribution_trajectory": [
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "punishment_sent_trajectory": [
      5,
      7,
      6,
      14,
      7,
      17,
      5,
      12,
      5,
      0
    ],
    "punishment_received_trajectory": [
      0,
      0,
      2,
      0,
      3,
      0,
      0,
      1,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      25,
      27,
      26,
      34,
      27,
      37,
      25,
      32,
      25,
      20
    ],
    "others_mean_trajectory": [
      9.0,
      11.666666666666666,
      11.333333333333334,
      11.333333333333334,
      11.333333333333334,
      12.333333333333334,
      13.0,
      15.0,
      19.0,
      20.0
    ],
    "mean_contribution": 20.0,
    "mean_punishment_sent": 7.8,
    "mean_punishment_received": 0.6,
    "mean_total_voluntary_spend": 27.8,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 78,
    "antisocial_ratio": 0.0,
    "group_id": "904"
  },
  "910": {
    "params": {},
    "params_list": [],
    "actual": [
      15,
      10,
      12,
      16,
      15,
      13,
      15,
      15,
      17,
      18
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Samara",
    "session": "Samara_P_S3",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperative-enforcer",
    "contribution_trajectory": [
      15,
      10,
      12,
      16,
      15,
      13,
      15,
      15,
      17,
      18
    ],
    "punishment_sent_trajectory": [
      1,
      1,
      0,
      0,
      0,
      1,
      4,
      4,
      3,
      2
    ],
    "punishment_received_trajectory": [
      1,
      0,
      1,
      0,
      0,
      2,
      0,
      0,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      16,
      11,
      12,
      16,
      15,
      14,
      19,
      19,
      20,
      20
    ],
    "others_mean_trajectory": [
      11.333333333333334,
      12.333333333333334,
      14.666666666666666,
      14.0,
      15.333333333333334,
      13.333333333333334,
      12.0,
      11.333333333333334,
      14.0,
      16.0
    ],
    "mean_contribution": 14.6,
    "mean_punishment_sent": 1.6,
    "mean_punishment_received": 0.4,
    "mean_total_voluntary_spend": 16.2,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 16,
    "antisocial_ratio": 0.0,
    "group_id": "902"
  },
  "911": {
    "params": {},
    "params_list": [],
    "actual": [
      10,
      15,
      10,
      11,
      10,
      15,
      20,
      20,
      20,
      20
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Samara",
    "session": "Samara_P_S3",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "antisocial",
    "behavioral_profile": "cooperative-enforcer",
    "contribution_trajectory": [
      10,
      15,
      10,
      11,
      10,
      15,
      20,
      20,
      20,
      20
    ],
    "punishment_sent_trajectory": [
      3,
      2,
      3,
      4,
      3,
      4,
      1,
      0,
      0,
      0
    ],
    "punishment_received_trajectory": [
      5,
      8,
      5,
      5,
      8,
      7,
      1,
      0,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      13,
      17,
      13,
      15,
      13,
      19,
      21,
      20,
      20,
      20
    ],
    "others_mean_trajectory": [
      13.333333333333334,
      14.333333333333334,
      16.0,
      17.333333333333332,
      18.333333333333332,
      19.666666666666668,
      19.666666666666668,
      20.0,
      20.0,
      20.0
    ],
    "mean_contribution": 15.1,
    "mean_punishment_sent": 2.0,
    "mean_punishment_received": 3.9,
    "mean_total_voluntary_spend": 17.1,
    "antisocial_punishment_total": 15,
    "prosocial_punishment_total": 5,
    "antisocial_ratio": 0.75,
    "group_id": "901"
  },
  "912": {
    "params": {},
    "params_list": [],
    "actual": [
      10,
      10,
      0,
      4,
      4,
      3,
      2,
      4,
      4,
      4
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Samara",
    "session": "Samara_P_S3",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "free-rider",
    "contribution_trajectory": [
      10,
      10,
      0,
      4,
      4,
      3,
      2,
      4,
      4,
      4
    ],
    "punishment_sent_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      1,
      1
    ],
    "punishment_received_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      1,
      0,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      10,
      10,
      0,
      4,
      4,
      3,
      2,
      4,
      5,
      5
    ],
    "others_mean_trajectory": [
      5.0,
      6.666666666666667,
      3.6666666666666665,
      5.0,
      5.0,
      5.0,
      5.0,
      5.0,
      4.0,
      3.6666666666666665
    ],
    "mean_contribution": 4.5,
    "mean_punishment_sent": 0.2,
    "mean_punishment_received": 0.1,
    "mean_total_voluntary_spend": 4.7,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 2,
    "antisocial_ratio": 0.0,
    "group_id": "903"
  },
  "913": {
    "params": {},
    "params_list": [],
    "actual": [
      0,
      3,
      2,
      2,
      1,
      3,
      2,
      5,
      0,
      0
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Samara",
    "session": "Samara_P_S3",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "free-rider",
    "contribution_trajectory": [
      0,
      3,
      2,
      2,
      1,
      3,
      2,
      5,
      0,
      0
    ],
    "punishment_sent_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "punishment_received_trajectory": [
      4,
      2,
      0,
      2,
      1,
      0,
      1,
      0,
      3,
      4
    ],
    "total_voluntary_spend_trajectory": [
      0,
      3,
      2,
      2,
      1,
      3,
      2,
      5,
      0,
      0
    ],
    "others_mean_trajectory": [
      8.333333333333334,
      9.0,
      3.0,
      5.666666666666667,
      6.0,
      5.0,
      5.0,
      4.666666666666667,
      5.333333333333333,
      5.0
    ],
    "mean_contribution": 1.8,
    "mean_punishment_sent": 0.0,
    "mean_punishment_received": 1.7,
    "mean_total_voluntary_spend": 1.8,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 0,
    "antisocial_ratio": 0.0,
    "group_id": "903"
  },
  "914": {
    "params": {},
    "params_list": [],
    "actual": [
      20,
      16,
      18,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Samara",
    "session": "Samara_P_S3",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperative-enforcer",
    "contribution_trajectory": [
      20,
      16,
      18,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "punishment_sent_trajectory": [
      15,
      4,
      4,
      3,
      6,
      5,
      1,
      0,
      0,
      0
    ],
    "punishment_received_trajectory": [
      0,
      9,
      3,
      1,
      1,
      1,
      3,
      0,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      35,
      20,
      22,
      23,
      26,
      25,
      21,
      20,
      20,
      20
    ],
    "others_mean_trajectory": [
      10.0,
      14.0,
      13.333333333333334,
      14.333333333333334,
      15.0,
      18.0,
      19.666666666666668,
      20.0,
      20.0,
      20.0
    ],
    "mean_contribution": 19.4,
    "mean_punishment_sent": 3.8,
    "mean_punishment_received": 1.8,
    "mean_total_voluntary_spend": 23.2,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 38,
    "antisocial_ratio": 0.0,
    "group_id": "901"
  },
  "915": {
    "params": {},
    "params_list": [],
    "actual": [
      7,
      8,
      10,
      10,
      12,
      15,
      15,
      15,
      20,
      20
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Samara",
    "session": "Samara_P_S3",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperative-enforcer",
    "contribution_trajectory": [
      7,
      8,
      10,
      10,
      12,
      15,
      15,
      15,
      20,
      20
    ],
    "punishment_sent_trajectory": [
      5,
      4,
      1,
      1,
      2,
      2,
      2,
      1,
      1,
      0
    ],
    "punishment_received_trajectory": [
      3,
      4,
      3,
      5,
      1,
      0,
      2,
      2,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      12,
      12,
      11,
      11,
      14,
      17,
      17,
      16,
      21,
      20
    ],
    "others_mean_trajectory": [
      13.333333333333334,
      15.666666666666666,
      14.666666666666666,
      14.666666666666666,
      14.0,
      14.0,
      14.666666666666666,
      16.666666666666668,
      19.0,
      20.0
    ],
    "mean_contribution": 13.2,
    "mean_punishment_sent": 1.9,
    "mean_punishment_received": 2.0,
    "mean_total_voluntary_spend": 15.1,
    "antisocial_punishment_total": 2,
    "prosocial_punishment_total": 17,
    "antisocial_ratio": 0.10526315789473684,
    "group_id": "904"
  },
  "916": {
    "params": {},
    "params_list": [],
    "actual": [
      5,
      7,
      10,
      9,
      10,
      12,
      10,
      10,
      17,
      20
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Samara",
    "session": "Samara_P_S3",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "antisocial",
    "behavioral_profile": "cooperative-enforcer",
    "contribution_trajectory": [
      5,
      7,
      10,
      9,
      10,
      12,
      10,
      10,
      17,
      20
    ],
    "punishment_sent_trajectory": [
      1,
      1,
      2,
      0,
      3,
      2,
      4,
      2,
      0,
      0
    ],
    "punishment_received_trajectory": [
      8,
      8,
      4,
      9,
      6,
      8,
      6,
      11,
      6,
      0
    ],
    "total_voluntary_spend_trajectory": [
      6,
      8,
      12,
      9,
      13,
      14,
      14,
      12,
      17,
      20
    ],
    "others_mean_trajectory": [
      14.0,
      16.0,
      14.666666666666666,
      15.0,
      14.666666666666666,
      15.0,
      16.333333333333332,
      18.333333333333332,
      20.0,
      20.0
    ],
    "mean_contribution": 11.0,
    "mean_punishment_sent": 1.5,
    "mean_punishment_received": 6.6,
    "mean_total_voluntary_spend": 12.5,
    "antisocial_punishment_total": 13,
    "prosocial_punishment_total": 2,
    "antisocial_ratio": 0.8666666666666667,
    "group_id": "904"
  },
  "4501": {
    "params": {},
    "params_list": [],
    "actual": [
      5,
      2,
      15,
      15,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Chengdu",
    "session": "Chengdu_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "antisocial",
    "behavioral_profile": "cooperative-enforcer",
    "contribution_trajectory": [
      5,
      2,
      15,
      15,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "punishment_sent_trajectory": [
      5,
      3,
      4,
      2,
      4,
      3,
      3,
      0,
      0,
      0
    ],
    "punishment_received_trajectory": [
      4,
      11,
      3,
      5,
      0,
      0,
      0,
      0,
      0,
      5
    ],
    "total_voluntary_spend_trajectory": [
      10,
      5,
      19,
      17,
      24,
      23,
      23,
      20,
      20,
      20
    ],
    "others_mean_trajectory": [
      15.0,
      13.333333333333334,
      18.333333333333332,
      18.333333333333332,
      18.666666666666668,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0
    ],
    "mean_contribution": 15.7,
    "mean_punishment_sent": 2.4,
    "mean_punishment_received": 2.8,
    "mean_total_voluntary_spend": 18.1,
    "antisocial_punishment_total": 22,
    "prosocial_punishment_total": 2,
    "antisocial_ratio": 0.9166666666666666,
    "group_id": "4501"
  },
  "4502": {
    "params": {},
    "params_list": [],
    "actual": [
      20,
      20,
      20,
      20,
      16,
      20,
      20,
      20,
      20,
      20
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Chengdu",
    "session": "Chengdu_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperative-enforcer",
    "contribution_trajectory": [
      20,
      20,
      20,
      20,
      16,
      20,
      20,
      20,
      20,
      20
    ],
    "punishment_sent_trajectory": [
      4,
      10,
      2,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "punishment_received_trajectory": [
      2,
      0,
      1,
      0,
      4,
      1,
      1,
      0,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      24,
      30,
      22,
      20,
      16,
      20,
      20,
      20,
      20,
      20
    ],
    "others_mean_trajectory": [
      10.0,
      7.333333333333333,
      16.666666666666668,
      16.666666666666668,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0
    ],
    "mean_contribution": 19.6,
    "mean_punishment_sent": 1.6,
    "mean_punishment_received": 0.9,
    "mean_total_voluntary_spend": 21.2,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 16,
    "antisocial_ratio": 0.0,
    "group_id": "4501"
  },
  "4503": {
    "params": {},
    "params_list": [],
    "actual": [
      20,
      15,
      15,
      15,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Chengdu",
    "session": "Chengdu_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperative-enforcer",
    "contribution_trajectory": [
      20,
      15,
      15,
      15,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "punishment_sent_trajectory": [
      4,
      4,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "punishment_received_trajectory": [
      2,
      1,
      6,
      2,
      1,
      1,
      1,
      2,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      24,
      19,
      15,
      15,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "others_mean_trajectory": [
      10.0,
      9.0,
      18.333333333333332,
      18.333333333333332,
      18.666666666666668,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0
    ],
    "mean_contribution": 18.5,
    "mean_punishment_sent": 0.8,
    "mean_punishment_received": 1.6,
    "mean_total_voluntary_spend": 19.3,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 8,
    "antisocial_ratio": 0.0,
    "group_id": "4501"
  },
  "4504": {
    "params": {},
    "params_list": [],
    "actual": [
      5,
      5,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Chengdu",
    "session": "Chengdu_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperative-enforcer",
    "contribution_trajectory": [
      5,
      5,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "punishment_sent_trajectory": [
      0,
      3,
      5,
      5,
      2,
      0,
      0,
      2,
      0,
      5
    ],
    "punishment_received_trajectory": [
      5,
      8,
      1,
      0,
      1,
      1,
      1,
      0,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      5,
      8,
      25,
      25,
      22,
      20,
      20,
      22,
      20,
      25
    ],
    "others_mean_trajectory": [
      15.0,
      12.333333333333334,
      16.666666666666668,
      16.666666666666668,
      18.666666666666668,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0
    ],
    "mean_contribution": 17.0,
    "mean_punishment_sent": 2.2,
    "mean_punishment_received": 1.7,
    "mean_total_voluntary_spend": 19.2,
    "antisocial_punishment_total": 7,
    "prosocial_punishment_total": 15,
    "antisocial_ratio": 0.3181818181818182,
    "group_id": "4501"
  },
  "4505": {
    "params": {},
    "params_list": [],
    "actual": [
      8,
      8,
      7,
      6,
      6,
      7,
      8,
      9,
      10,
      5
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Chengdu",
    "session": "Chengdu_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "mixed",
    "contribution_trajectory": [
      8,
      8,
      7,
      6,
      6,
      7,
      8,
      9,
      10,
      5
    ],
    "punishment_sent_trajectory": [
      1,
      2,
      1,
      0,
      1,
      2,
      0,
      1,
      0,
      5
    ],
    "punishment_received_trajectory": [
      0,
      0,
      0,
      0,
      1,
      2,
      1,
      1,
      1,
      2
    ],
    "total_voluntary_spend_trajectory": [
      9,
      10,
      8,
      6,
      7,
      9,
      8,
      10,
      10,
      10
    ],
    "others_mean_trajectory": [
      5.0,
      4.666666666666667,
      5.0,
      6.0,
      6.0,
      8.0,
      9.333333333333334,
      11.0,
      11.0,
      10.0
    ],
    "mean_contribution": 7.4,
    "mean_punishment_sent": 1.3,
    "mean_punishment_received": 0.8,
    "mean_total_voluntary_spend": 8.7,
    "antisocial_punishment_total": 6,
    "prosocial_punishment_total": 7,
    "antisocial_ratio": 0.46153846153846156,
    "group_id": "4502"
  },
  "4506": {
    "params": {},
    "params_list": [],
    "actual": [
      0,
      0,
      3,
      5,
      4,
      6,
      10,
      12,
      12,
      10
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Chengdu",
    "session": "Chengdu_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "mixed",
    "contribution_trajectory": [
      0,
      0,
      3,
      5,
      4,
      6,
      10,
      12,
      12,
      10
    ],
    "punishment_sent_trajectory": [
      0,
      1,
      0,
      0,
      0,
      1,
      0,
      1,
      0,
      1
    ],
    "punishment_received_trajectory": [
      3,
      3,
      2,
      0,
      4,
      4,
      0,
      0,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      0,
      1,
      3,
      5,
      4,
      7,
      10,
      13,
      12,
      11
    ],
    "others_mean_trajectory": [
      7.666666666666667,
      7.333333333333333,
      6.333333333333333,
      6.333333333333333,
      6.666666666666667,
      8.333333333333334,
      8.666666666666666,
      10.0,
      10.333333333333334,
      8.333333333333334
    ],
    "mean_contribution": 6.2,
    "mean_punishment_sent": 0.4,
    "mean_punishment_received": 1.6,
    "mean_total_voluntary_spend": 6.6,
    "antisocial_punishment_total": 2,
    "prosocial_punishment_total": 2,
    "antisocial_ratio": 0.5,
    "group_id": "4502"
  },
  "4507": {
    "params": {},
    "params_list": [],
    "actual": [
      5,
      6,
      6,
      7,
      8,
      8,
      8,
      9,
      11,
      10
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Chengdu",
    "session": "Chengdu_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "mixed",
    "contribution_trajectory": [
      5,
      6,
      6,
      7,
      8,
      8,
      8,
      9,
      11,
      10
    ],
    "punishment_sent_trajectory": [
      1,
      1,
      1,
      0,
      4,
      2,
      0,
      0,
      2,
      0
    ],
    "punishment_received_trajectory": [
      0,
      2,
      0,
      0,
      0,
      0,
      1,
      3,
      0,
      4
    ],
    "total_voluntary_spend_trajectory": [
      6,
      7,
      7,
      7,
      12,
      10,
      8,
      9,
      13,
      10
    ],
    "others_mean_trajectory": [
      6.0,
      5.333333333333333,
      5.333333333333333,
      5.666666666666667,
      5.333333333333333,
      7.666666666666667,
      9.333333333333334,
      11.0,
      10.666666666666666,
      8.333333333333334
    ],
    "mean_contribution": 7.8,
    "mean_punishment_sent": 1.1,
    "mean_punishment_received": 1.0,
    "mean_total_voluntary_spend": 8.9,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 11,
    "antisocial_ratio": 0.0,
    "group_id": "4502"
  },
  "4508": {
    "params": {},
    "params_list": [],
    "actual": [
      10,
      8,
      6,
      6,
      6,
      10,
      10,
      12,
      10,
      10
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Chengdu",
    "session": "Chengdu_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "mixed",
    "contribution_trajectory": [
      10,
      8,
      6,
      6,
      6,
      10,
      10,
      12,
      10,
      10
    ],
    "punishment_sent_trajectory": [
      1,
      1,
      0,
      0,
      1,
      1,
      2,
      2,
      0,
      1
    ],
    "punishment_received_trajectory": [
      0,
      0,
      0,
      0,
      1,
      0,
      0,
      0,
      1,
      1
    ],
    "total_voluntary_spend_trajectory": [
      11,
      9,
      6,
      6,
      7,
      11,
      12,
      14,
      10,
      11
    ],
    "others_mean_trajectory": [
      4.333333333333333,
      4.666666666666667,
      5.333333333333333,
      6.0,
      6.0,
      7.0,
      8.666666666666666,
      10.0,
      11.0,
      8.333333333333334
    ],
    "mean_contribution": 8.8,
    "mean_punishment_sent": 0.9,
    "mean_punishment_received": 0.3,
    "mean_total_voluntary_spend": 9.7,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 9,
    "antisocial_ratio": 0.0,
    "group_id": "4502"
  },
  "4509": {
    "params": {},
    "params_list": [],
    "actual": [
      10,
      12,
      13,
      20,
      20,
      20,
      20,
      20,
      20,
      0
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Chengdu",
    "session": "Chengdu_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperative-enforcer",
    "contribution_trajectory": [
      10,
      12,
      13,
      20,
      20,
      20,
      20,
      20,
      20,
      0
    ],
    "punishment_sent_trajectory": [
      1,
      0,
      0,
      2,
      1,
      0,
      0,
      2,
      0,
      0
    ],
    "punishment_received_trajectory": [
      0,
      0,
      1,
      0,
      0,
      0,
      0,
      0,
      0,
      4
    ],
    "total_voluntary_spend_trajectory": [
      11,
      12,
      13,
      22,
      21,
      20,
      20,
      22,
      20,
      0
    ],
    "others_mean_trajectory": [
      9.333333333333334,
      12.333333333333334,
      14.666666666666666,
      15.666666666666666,
      19.0,
      20.0,
      20.0,
      16.666666666666668,
      20.0,
      13.333333333333334
    ],
    "mean_contribution": 15.5,
    "mean_punishment_sent": 0.6,
    "mean_punishment_received": 0.5,
    "mean_total_voluntary_spend": 16.1,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 6,
    "antisocial_ratio": 0.0,
    "group_id": "4503"
  },
  "4510": {
    "params": {},
    "params_list": [],
    "actual": [
      12,
      13,
      14,
      17,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Chengdu",
    "session": "Chengdu_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperative-enforcer",
    "contribution_trajectory": [
      12,
      13,
      14,
      17,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "punishment_sent_trajectory": [
      0,
      0,
      0,
      1,
      0,
      0,
      0,
      1,
      0,
      6
    ],
    "punishment_received_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      12,
      13,
      14,
      18,
      20,
      20,
      20,
      21,
      20,
      26
    ],
    "others_mean_trajectory": [
      8.666666666666666,
      12.0,
      14.333333333333334,
      16.666666666666668,
      19.0,
      20.0,
      20.0,
      16.666666666666668,
      20.0,
      6.666666666666667
    ],
    "mean_contribution": 17.6,
    "mean_punishment_sent": 0.8,
    "mean_punishment_received": 0.0,
    "mean_total_voluntary_spend": 18.4,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 8,
    "antisocial_ratio": 0.0,
    "group_id": "4503"
  },
  "4511": {
    "params": {},
    "params_list": [],
    "actual": [
      6,
      12,
      15,
      16,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Chengdu",
    "session": "Chengdu_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperator",
    "contribution_trajectory": [
      6,
      12,
      15,
      16,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "punishment_sent_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      1,
      0,
      2
    ],
    "punishment_received_trajectory": [
      3,
      0,
      0,
      1,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      6,
      12,
      15,
      16,
      20,
      20,
      20,
      21,
      20,
      22
    ],
    "others_mean_trajectory": [
      10.666666666666666,
      12.333333333333334,
      14.0,
      17.0,
      19.0,
      20.0,
      20.0,
      16.666666666666668,
      20.0,
      6.666666666666667
    ],
    "mean_contribution": 16.9,
    "mean_punishment_sent": 0.3,
    "mean_punishment_received": 0.4,
    "mean_total_voluntary_spend": 17.2,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 3,
    "antisocial_ratio": 0.0,
    "group_id": "4503"
  },
  "4512": {
    "params": {},
    "params_list": [],
    "actual": [
      10,
      12,
      15,
      14,
      17,
      20,
      20,
      10,
      20,
      0
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Chengdu",
    "session": "Chengdu_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperator",
    "contribution_trajectory": [
      10,
      12,
      15,
      14,
      17,
      20,
      20,
      10,
      20,
      0
    ],
    "punishment_sent_trajectory": [
      2,
      0,
      1,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "punishment_received_trajectory": [
      0,
      0,
      0,
      2,
      1,
      0,
      0,
      4,
      0,
      4
    ],
    "total_voluntary_spend_trajectory": [
      12,
      12,
      16,
      14,
      17,
      20,
      20,
      10,
      20,
      0
    ],
    "others_mean_trajectory": [
      9.333333333333334,
      12.333333333333334,
      14.0,
      17.666666666666668,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      13.333333333333334
    ],
    "mean_contribution": 13.8,
    "mean_punishment_sent": 0.3,
    "mean_punishment_received": 1.1,
    "mean_total_voluntary_spend": 14.1,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 3,
    "antisocial_ratio": 0.0,
    "group_id": "4503"
  },
  "4513": {
    "params": {},
    "params_list": [],
    "actual": [
      0,
      5,
      20,
      16,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Chengdu",
    "session": "Chengdu_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperator",
    "contribution_trajectory": [
      0,
      5,
      20,
      16,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "punishment_sent_trajectory": [
      0,
      1,
      1,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "punishment_received_trajectory": [
      6,
      6,
      0,
      5,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      0,
      6,
      21,
      16,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "others_mean_trajectory": [
      8.333333333333334,
      8.0,
      14.0,
      19.333333333333332,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0
    ],
    "mean_contribution": 16.1,
    "mean_punishment_sent": 0.2,
    "mean_punishment_received": 1.7,
    "mean_total_voluntary_spend": 16.3,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 2,
    "antisocial_ratio": 0.0,
    "group_id": "4504"
  },
  "4514": {
    "params": {},
    "params_list": [],
    "actual": [
      15,
      10,
      15,
      18,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Chengdu",
    "session": "Chengdu_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperative-enforcer",
    "contribution_trajectory": [
      15,
      10,
      15,
      18,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "punishment_sent_trajectory": [
      15,
      11,
      6,
      1,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "punishment_received_trajectory": [
      0,
      0,
      0,
      2,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      30,
      21,
      21,
      19,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "others_mean_trajectory": [
      3.3333333333333335,
      6.333333333333333,
      15.666666666666666,
      18.666666666666668,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0
    ],
    "mean_contribution": 17.8,
    "mean_punishment_sent": 3.3,
    "mean_punishment_received": 0.2,
    "mean_total_voluntary_spend": 21.1,
    "antisocial_punishment_total": 1,
    "prosocial_punishment_total": 32,
    "antisocial_ratio": 0.030303030303030304,
    "group_id": "4504"
  },
  "4515": {
    "params": {},
    "params_list": [],
    "actual": [
      5,
      12,
      12,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Chengdu",
    "session": "Chengdu_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperative-enforcer",
    "contribution_trajectory": [
      5,
      12,
      12,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "punishment_sent_trajectory": [
      1,
      4,
      0,
      4,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "punishment_received_trajectory": [
      5,
      0,
      7,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      6,
      16,
      12,
      24,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "others_mean_trajectory": [
      6.666666666666667,
      5.666666666666667,
      16.666666666666668,
      18.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0
    ],
    "mean_contribution": 16.9,
    "mean_punishment_sent": 0.9,
    "mean_punishment_received": 1.2,
    "mean_total_voluntary_spend": 17.8,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 9,
    "antisocial_ratio": 0.0,
    "group_id": "4504"
  },
  "4516": {
    "params": {},
    "params_list": [],
    "actual": [
      5,
      2,
      15,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Chengdu",
    "session": "Chengdu_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperator",
    "contribution_trajectory": [
      5,
      2,
      15,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "punishment_sent_trajectory": [
      0,
      0,
      1,
      2,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "punishment_received_trajectory": [
      5,
      10,
      1,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      5,
      2,
      16,
      22,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "others_mean_trajectory": [
      6.666666666666667,
      9.0,
      15.666666666666666,
      18.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0
    ],
    "mean_contribution": 16.2,
    "mean_punishment_sent": 0.3,
    "mean_punishment_received": 1.6,
    "mean_total_voluntary_spend": 16.5,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 3,
    "antisocial_ratio": 0.0,
    "group_id": "4504"
  },
  "4517": {
    "params": {},
    "params_list": [],
    "actual": [
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Chengdu",
    "session": "Chengdu_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperator",
    "contribution_trajectory": [
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "punishment_sent_trajectory": [
      1,
      3,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "punishment_received_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      5
    ],
    "total_voluntary_spend_trajectory": [
      21,
      23,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "others_mean_trajectory": [
      18.333333333333332,
      18.333333333333332,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0
    ],
    "mean_contribution": 20.0,
    "mean_punishment_sent": 0.4,
    "mean_punishment_received": 0.5,
    "mean_total_voluntary_spend": 20.4,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 4,
    "antisocial_ratio": 0.0,
    "group_id": "4505"
  },
  "4518": {
    "params": {},
    "params_list": [],
    "actual": [
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Chengdu",
    "session": "Chengdu_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "antisocial",
    "behavioral_profile": "cooperative-enforcer",
    "contribution_trajectory": [
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "punishment_sent_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      15
    ],
    "punishment_received_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      35
    ],
    "others_mean_trajectory": [
      18.333333333333332,
      18.333333333333332,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0
    ],
    "mean_contribution": 20.0,
    "mean_punishment_sent": 1.5,
    "mean_punishment_received": 0.0,
    "mean_total_voluntary_spend": 21.5,
    "antisocial_punishment_total": 15,
    "prosocial_punishment_total": 0,
    "antisocial_ratio": 1.0,
    "group_id": "4505"
  },
  "4519": {
    "params": {},
    "params_list": [],
    "actual": [
      15,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Chengdu",
    "session": "Chengdu_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperator",
    "contribution_trajectory": [
      15,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "punishment_sent_trajectory": [
      0,
      1,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "punishment_received_trajectory": [
      1,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      5
    ],
    "total_voluntary_spend_trajectory": [
      15,
      21,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "others_mean_trajectory": [
      20.0,
      18.333333333333332,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0
    ],
    "mean_contribution": 19.5,
    "mean_punishment_sent": 0.1,
    "mean_punishment_received": 0.6,
    "mean_total_voluntary_spend": 19.6,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 1,
    "antisocial_ratio": 0.0,
    "group_id": "4505"
  },
  "4520": {
    "params": {},
    "params_list": [],
    "actual": [
      20,
      15,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Chengdu",
    "session": "Chengdu_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperator",
    "contribution_trajectory": [
      20,
      15,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "punishment_sent_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "punishment_received_trajectory": [
      0,
      4,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      5
    ],
    "total_voluntary_spend_trajectory": [
      20,
      15,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "others_mean_trajectory": [
      18.333333333333332,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0
    ],
    "mean_contribution": 19.5,
    "mean_punishment_sent": 0.0,
    "mean_punishment_received": 0.9,
    "mean_total_voluntary_spend": 19.5,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 0,
    "antisocial_ratio": 0.0,
    "group_id": "4505"
  },
  "401": {
    "params": {},
    "params_list": [],
    "actual": [
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Zurich",
    "session": "Zurich_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperator",
    "contribution_trajectory": [
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "punishment_sent_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "punishment_received_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "others_mean_trajectory": [
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      19.0
    ],
    "mean_contribution": 20.0,
    "mean_punishment_sent": 0.0,
    "mean_punishment_received": 0.0,
    "mean_total_voluntary_spend": 20.0,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 0,
    "antisocial_ratio": 0.0,
    "group_id": "401"
  },
  "402": {
    "params": {},
    "params_list": [],
    "actual": [
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      17
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Zurich",
    "session": "Zurich_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperator",
    "contribution_trajectory": [
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      17
    ],
    "punishment_sent_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "punishment_received_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      6
    ],
    "total_voluntary_spend_trajectory": [
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      17
    ],
    "others_mean_trajectory": [
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0
    ],
    "mean_contribution": 19.7,
    "mean_punishment_sent": 0.0,
    "mean_punishment_received": 0.6,
    "mean_total_voluntary_spend": 19.7,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 0,
    "antisocial_ratio": 0.0,
    "group_id": "401"
  },
  "403": {
    "params": {},
    "params_list": [],
    "actual": [
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Zurich",
    "session": "Zurich_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperator",
    "contribution_trajectory": [
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "punishment_sent_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      3
    ],
    "punishment_received_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      23
    ],
    "others_mean_trajectory": [
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      19.0
    ],
    "mean_contribution": 20.0,
    "mean_punishment_sent": 0.3,
    "mean_punishment_received": 0.0,
    "mean_total_voluntary_spend": 20.3,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 3,
    "antisocial_ratio": 0.0,
    "group_id": "401"
  },
  "404": {
    "params": {},
    "params_list": [],
    "actual": [
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Zurich",
    "session": "Zurich_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperator",
    "contribution_trajectory": [
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "punishment_sent_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      3
    ],
    "punishment_received_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      23
    ],
    "others_mean_trajectory": [
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      19.0
    ],
    "mean_contribution": 20.0,
    "mean_punishment_sent": 0.3,
    "mean_punishment_received": 0.0,
    "mean_total_voluntary_spend": 20.3,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 3,
    "antisocial_ratio": 0.0,
    "group_id": "401"
  },
  "405": {
    "params": {},
    "params_list": [],
    "actual": [
      5,
      7,
      10,
      10,
      15,
      17,
      20,
      20,
      20,
      20
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Zurich",
    "session": "Zurich_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "antisocial",
    "behavioral_profile": "cooperative-enforcer",
    "contribution_trajectory": [
      5,
      7,
      10,
      10,
      15,
      17,
      20,
      20,
      20,
      20
    ],
    "punishment_sent_trajectory": [
      3,
      2,
      2,
      5,
      3,
      3,
      1,
      2,
      2,
      0
    ],
    "punishment_received_trajectory": [
      3,
      4,
      0,
      3,
      0,
      0,
      0,
      1,
      1,
      1
    ],
    "total_voluntary_spend_trajectory": [
      8,
      9,
      12,
      15,
      18,
      20,
      21,
      22,
      22,
      20
    ],
    "others_mean_trajectory": [
      10.333333333333334,
      11.0,
      11.0,
      12.333333333333334,
      12.666666666666666,
      15.0,
      17.666666666666668,
      19.333333333333332,
      19.333333333333332,
      20.0
    ],
    "mean_contribution": 14.4,
    "mean_punishment_sent": 2.3,
    "mean_punishment_received": 1.3,
    "mean_total_voluntary_spend": 16.7,
    "antisocial_punishment_total": 12,
    "prosocial_punishment_total": 11,
    "antisocial_ratio": 0.5217391304347826,
    "group_id": "402"
  },
  "406": {
    "params": {},
    "params_list": [],
    "actual": [
      9,
      13,
      10,
      12,
      14,
      13,
      18,
      18,
      18,
      20
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Zurich",
    "session": "Zurich_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "antisocial",
    "behavioral_profile": "cooperative-enforcer",
    "contribution_trajectory": [
      9,
      13,
      10,
      12,
      14,
      13,
      18,
      18,
      18,
      20
    ],
    "punishment_sent_trajectory": [
      1,
      1,
      1,
      3,
      4,
      3,
      2,
      3,
      3,
      3
    ],
    "punishment_received_trajectory": [
      1,
      0,
      1,
      2,
      1,
      3,
      0,
      2,
      7,
      0
    ],
    "total_voluntary_spend_trajectory": [
      10,
      14,
      11,
      15,
      18,
      16,
      20,
      21,
      21,
      23
    ],
    "others_mean_trajectory": [
      9.0,
      9.0,
      11.0,
      11.666666666666666,
      13.0,
      16.333333333333332,
      18.333333333333332,
      20.0,
      20.0,
      20.0
    ],
    "mean_contribution": 14.5,
    "mean_punishment_sent": 2.4,
    "mean_punishment_received": 1.7,
    "mean_total_voluntary_spend": 16.9,
    "antisocial_punishment_total": 15,
    "prosocial_punishment_total": 9,
    "antisocial_ratio": 0.625,
    "group_id": "402"
  },
  "407": {
    "params": {},
    "params_list": [],
    "actual": [
      12,
      10,
      13,
      13,
      12,
      17,
      18,
      20,
      20,
      20
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Zurich",
    "session": "Zurich_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperative-enforcer",
    "contribution_trajectory": [
      12,
      10,
      13,
      13,
      12,
      17,
      18,
      20,
      20,
      20
    ],
    "punishment_sent_trajectory": [
      2,
      2,
      0,
      2,
      0,
      1,
      0,
      0,
      4,
      0
    ],
    "punishment_received_trajectory": [
      1,
      1,
      1,
      3,
      3,
      0,
      0,
      1,
      1,
      1
    ],
    "total_voluntary_spend_trajectory": [
      14,
      12,
      13,
      15,
      12,
      18,
      18,
      20,
      24,
      20
    ],
    "others_mean_trajectory": [
      8.0,
      10.0,
      10.0,
      11.333333333333334,
      13.666666666666666,
      15.0,
      18.333333333333332,
      19.333333333333332,
      19.333333333333332,
      20.0
    ],
    "mean_contribution": 15.5,
    "mean_punishment_sent": 1.1,
    "mean_punishment_received": 1.2,
    "mean_total_voluntary_spend": 16.6,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 11,
    "antisocial_ratio": 0.0,
    "group_id": "402"
  },
  "408": {
    "params": {},
    "params_list": [],
    "actual": [
      10,
      10,
      10,
      12,
      12,
      15,
      17,
      20,
      20,
      20
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Zurich",
    "session": "Zurich_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperator",
    "contribution_trajectory": [
      10,
      10,
      10,
      12,
      12,
      15,
      17,
      20,
      20,
      20
    ],
    "punishment_sent_trajectory": [
      0,
      1,
      0,
      0,
      0,
      0,
      0,
      0,
      1,
      0
    ],
    "punishment_received_trajectory": [
      1,
      1,
      1,
      2,
      3,
      4,
      3,
      1,
      1,
      1
    ],
    "total_voluntary_spend_trajectory": [
      10,
      11,
      10,
      12,
      12,
      15,
      17,
      20,
      21,
      20
    ],
    "others_mean_trajectory": [
      8.666666666666666,
      10.0,
      11.0,
      11.666666666666666,
      13.666666666666666,
      15.666666666666666,
      18.666666666666668,
      19.333333333333332,
      19.333333333333332,
      20.0
    ],
    "mean_contribution": 14.6,
    "mean_punishment_sent": 0.2,
    "mean_punishment_received": 1.8,
    "mean_total_voluntary_spend": 14.8,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 2,
    "antisocial_ratio": 0.0,
    "group_id": "402"
  },
  "409": {
    "params": {},
    "params_list": [],
    "actual": [
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Zurich",
    "session": "Zurich_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperator",
    "contribution_trajectory": [
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "punishment_sent_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "punishment_received_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      3
    ],
    "total_voluntary_spend_trajectory": [
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "others_mean_trajectory": [
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0
    ],
    "mean_contribution": 20.0,
    "mean_punishment_sent": 0.0,
    "mean_punishment_received": 0.3,
    "mean_total_voluntary_spend": 20.0,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 0,
    "antisocial_ratio": 0.0,
    "group_id": "403"
  },
  "410": {
    "params": {},
    "params_list": [],
    "actual": [
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Zurich",
    "session": "Zurich_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperator",
    "contribution_trajectory": [
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "punishment_sent_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "punishment_received_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      3
    ],
    "total_voluntary_spend_trajectory": [
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "others_mean_trajectory": [
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0
    ],
    "mean_contribution": 20.0,
    "mean_punishment_sent": 0.0,
    "mean_punishment_received": 0.3,
    "mean_total_voluntary_spend": 20.0,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 0,
    "antisocial_ratio": 0.0,
    "group_id": "403"
  },
  "411": {
    "params": {},
    "params_list": [],
    "actual": [
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Zurich",
    "session": "Zurich_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "antisocial",
    "behavioral_profile": "cooperative-enforcer",
    "contribution_trajectory": [
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "punishment_sent_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      9
    ],
    "punishment_received_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      29
    ],
    "others_mean_trajectory": [
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0
    ],
    "mean_contribution": 20.0,
    "mean_punishment_sent": 0.9,
    "mean_punishment_received": 0.0,
    "mean_total_voluntary_spend": 20.9,
    "antisocial_punishment_total": 9,
    "prosocial_punishment_total": 0,
    "antisocial_ratio": 1.0,
    "group_id": "403"
  },
  "412": {
    "params": {},
    "params_list": [],
    "actual": [
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Zurich",
    "session": "Zurich_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperator",
    "contribution_trajectory": [
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "punishment_sent_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "punishment_received_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      3
    ],
    "total_voluntary_spend_trajectory": [
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "others_mean_trajectory": [
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0
    ],
    "mean_contribution": 20.0,
    "mean_punishment_sent": 0.0,
    "mean_punishment_received": 0.3,
    "mean_total_voluntary_spend": 20.0,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 0,
    "antisocial_ratio": 0.0,
    "group_id": "403"
  },
  "413": {
    "params": {},
    "params_list": [],
    "actual": [
      4,
      2,
      2,
      5,
      4,
      4,
      3,
      3,
      4,
      3
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Zurich",
    "session": "Zurich_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "antisocial",
    "behavioral_profile": "antisocial-controller",
    "contribution_trajectory": [
      4,
      2,
      2,
      5,
      4,
      4,
      3,
      3,
      4,
      3
    ],
    "punishment_sent_trajectory": [
      3,
      2,
      3,
      2,
      1,
      1,
      2,
      1,
      2,
      1
    ],
    "punishment_received_trajectory": [
      5,
      4,
      14,
      5,
      4,
      3,
      0,
      1,
      5,
      2
    ],
    "total_voluntary_spend_trajectory": [
      7,
      4,
      5,
      7,
      5,
      5,
      5,
      4,
      6,
      4
    ],
    "others_mean_trajectory": [
      15.333333333333334,
      16.666666666666668,
      17.333333333333332,
      16.0,
      13.0,
      9.0,
      6.666666666666667,
      11.333333333333334,
      8.333333333333334,
      13.666666666666666
    ],
    "mean_contribution": 3.4,
    "mean_punishment_sent": 1.8,
    "mean_punishment_received": 4.3,
    "mean_total_voluntary_spend": 5.2,
    "antisocial_punishment_total": 15,
    "prosocial_punishment_total": 3,
    "antisocial_ratio": 0.8333333333333334,
    "group_id": "404"
  },
  "414": {
    "params": {},
    "params_list": [],
    "actual": [
      10,
      15,
      20,
      14,
      10,
      13,
      10,
      13,
      5,
      8
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Zurich",
    "session": "Zurich_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "antisocial",
    "behavioral_profile": "cooperative-enforcer",
    "contribution_trajectory": [
      10,
      15,
      20,
      14,
      10,
      13,
      10,
      13,
      5,
      8
    ],
    "punishment_sent_trajectory": [
      0,
      1,
      2,
      1,
      1,
      0,
      0,
      0,
      0,
      1
    ],
    "punishment_received_trajectory": [
      5,
      1,
      1,
      2,
      2,
      2,
      0,
      0,
      6,
      2
    ],
    "total_voluntary_spend_trajectory": [
      10,
      16,
      22,
      15,
      11,
      13,
      10,
      13,
      5,
      9
    ],
    "others_mean_trajectory": [
      13.333333333333334,
      12.333333333333334,
      11.333333333333334,
      13.0,
      11.0,
      6.0,
      4.333333333333333,
      8.0,
      8.0,
      12.0
    ],
    "mean_contribution": 11.8,
    "mean_punishment_sent": 0.6,
    "mean_punishment_received": 2.1,
    "mean_total_voluntary_spend": 12.4,
    "antisocial_punishment_total": 5,
    "prosocial_punishment_total": 1,
    "antisocial_ratio": 0.8333333333333334,
    "group_id": "404"
  },
  "415": {
    "params": {},
    "params_list": [],
    "actual": [
      16,
      15,
      12,
      19,
      14,
      14,
      10,
      6,
      5,
      13
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Zurich",
    "session": "Zurich_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperative-enforcer",
    "contribution_trajectory": [
      16,
      15,
      12,
      19,
      14,
      14,
      10,
      6,
      5,
      13
    ],
    "punishment_sent_trajectory": [
      6,
      4,
      4,
      4,
      4,
      4,
      4,
      1,
      0,
      3
    ],
    "punishment_received_trajectory": [
      3,
      1,
      7,
      2,
      0,
      2,
      0,
      1,
      6,
      0
    ],
    "total_voluntary_spend_trajectory": [
      22,
      19,
      16,
      23,
      18,
      18,
      14,
      7,
      5,
      16
    ],
    "others_mean_trajectory": [
      11.333333333333334,
      12.333333333333334,
      14.0,
      11.333333333333334,
      9.666666666666666,
      5.666666666666667,
      4.333333333333333,
      10.333333333333334,
      8.0,
      10.333333333333334
    ],
    "mean_contribution": 12.4,
    "mean_punishment_sent": 3.4,
    "mean_punishment_received": 2.2,
    "mean_total_voluntary_spend": 15.8,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 34,
    "antisocial_ratio": 0.0,
    "group_id": "404"
  },
  "416": {
    "params": {},
    "params_list": [],
    "actual": [
      20,
      20,
      20,
      15,
      15,
      0,
      0,
      15,
      15,
      20
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Zurich",
    "session": "Zurich_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperative-enforcer",
    "contribution_trajectory": [
      20,
      20,
      20,
      15,
      15,
      0,
      0,
      15,
      15,
      20
    ],
    "punishment_sent_trajectory": [
      5,
      0,
      15,
      3,
      1,
      5,
      0,
      0,
      15,
      0
    ],
    "punishment_received_trajectory": [
      1,
      1,
      2,
      1,
      1,
      3,
      6,
      0,
      0,
      1
    ],
    "total_voluntary_spend_trajectory": [
      25,
      20,
      35,
      18,
      16,
      5,
      0,
      15,
      30,
      20
    ],
    "others_mean_trajectory": [
      10.0,
      10.666666666666666,
      11.333333333333334,
      12.666666666666666,
      9.333333333333334,
      10.333333333333334,
      7.666666666666667,
      7.333333333333333,
      4.666666666666667,
      8.0
    ],
    "mean_contribution": 14.0,
    "mean_punishment_sent": 4.4,
    "mean_punishment_received": 1.6,
    "mean_total_voluntary_spend": 18.4,
    "antisocial_punishment_total": 6,
    "prosocial_punishment_total": 38,
    "antisocial_ratio": 0.13636363636363635,
    "group_id": "404"
  },
  "417": {
    "params": {},
    "params_list": [],
    "actual": [
      15,
      10,
      8,
      12,
      15,
      10,
      15,
      18,
      16,
      20
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Zurich",
    "session": "Zurich_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperative-enforcer",
    "contribution_trajectory": [
      15,
      10,
      8,
      12,
      15,
      10,
      15,
      18,
      16,
      20
    ],
    "punishment_sent_trajectory": [
      2,
      0,
      0,
      1,
      0,
      0,
      1,
      1,
      1,
      3
    ],
    "punishment_received_trajectory": [
      0,
      0,
      2,
      1,
      0,
      5,
      0,
      0,
      6,
      0
    ],
    "total_voluntary_spend_trajectory": [
      17,
      10,
      8,
      13,
      15,
      10,
      16,
      19,
      17,
      23
    ],
    "others_mean_trajectory": [
      3.3333333333333335,
      6.666666666666667,
      9.0,
      11.333333333333334,
      13.333333333333334,
      14.666666666666666,
      15.666666666666666,
      16.666666666666668,
      18.666666666666668,
      18.333333333333332
    ],
    "mean_contribution": 13.9,
    "mean_punishment_sent": 0.9,
    "mean_punishment_received": 1.4,
    "mean_total_voluntary_spend": 14.8,
    "antisocial_punishment_total": 1,
    "prosocial_punishment_total": 8,
    "antisocial_ratio": 0.1111111111111111,
    "group_id": "405"
  },
  "418": {
    "params": {},
    "params_list": [],
    "actual": [
      0,
      10,
      10,
      11,
      15,
      17,
      17,
      17,
      20,
      17
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Zurich",
    "session": "Zurich_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperative-enforcer",
    "contribution_trajectory": [
      0,
      10,
      10,
      11,
      15,
      17,
      17,
      17,
      20,
      17
    ],
    "punishment_sent_trajectory": [
      2,
      4,
      1,
      2,
      0,
      3,
      2,
      2,
      2,
      0
    ],
    "punishment_received_trajectory": [
      4,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      1,
      4
    ],
    "total_voluntary_spend_trajectory": [
      2,
      14,
      11,
      13,
      15,
      20,
      19,
      19,
      22,
      17
    ],
    "others_mean_trajectory": [
      8.333333333333334,
      6.666666666666667,
      8.333333333333334,
      11.666666666666666,
      13.333333333333334,
      12.333333333333334,
      15.0,
      17.0,
      17.333333333333332,
      19.333333333333332
    ],
    "mean_contribution": 13.4,
    "mean_punishment_sent": 1.8,
    "mean_punishment_received": 0.9,
    "mean_total_voluntary_spend": 15.2,
    "antisocial_punishment_total": 3,
    "prosocial_punishment_total": 15,
    "antisocial_ratio": 0.16666666666666666,
    "group_id": "405"
  },
  "419": {
    "params": {},
    "params_list": [],
    "actual": [
      10,
      5,
      10,
      15,
      13,
      15,
      17,
      18,
      18,
      20
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Zurich",
    "session": "Zurich_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperative-enforcer",
    "contribution_trajectory": [
      10,
      5,
      10,
      15,
      13,
      15,
      17,
      18,
      18,
      20
    ],
    "punishment_sent_trajectory": [
      6,
      0,
      1,
      1,
      0,
      1,
      1,
      1,
      1,
      0
    ],
    "punishment_received_trajectory": [
      0,
      4,
      0,
      0,
      2,
      0,
      0,
      0,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      16,
      5,
      11,
      16,
      13,
      16,
      18,
      19,
      19,
      20
    ],
    "others_mean_trajectory": [
      5.0,
      8.333333333333334,
      8.333333333333334,
      10.333333333333334,
      14.0,
      13.0,
      15.0,
      16.666666666666668,
      18.0,
      18.333333333333332
    ],
    "mean_contribution": 14.1,
    "mean_punishment_sent": 1.2,
    "mean_punishment_received": 0.6,
    "mean_total_voluntary_spend": 15.3,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 12,
    "antisocial_ratio": 0.0,
    "group_id": "405"
  },
  "420": {
    "params": {},
    "params_list": [],
    "actual": [
      0,
      5,
      7,
      8,
      12,
      12,
      13,
      15,
      18,
      18
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Zurich",
    "session": "Zurich_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperative-enforcer",
    "contribution_trajectory": [
      0,
      5,
      7,
      8,
      12,
      12,
      13,
      15,
      18,
      18
    ],
    "punishment_sent_trajectory": [
      0,
      2,
      2,
      0,
      2,
      2,
      0,
      0,
      3,
      2
    ],
    "punishment_received_trajectory": [
      6,
      2,
      2,
      3,
      0,
      1,
      4,
      4,
      0,
      1
    ],
    "total_voluntary_spend_trajectory": [
      0,
      7,
      9,
      8,
      14,
      14,
      13,
      15,
      21,
      20
    ],
    "others_mean_trajectory": [
      8.333333333333334,
      8.333333333333334,
      9.333333333333334,
      12.666666666666666,
      14.333333333333334,
      14.0,
      16.333333333333332,
      17.666666666666668,
      18.0,
      19.0
    ],
    "mean_contribution": 10.8,
    "mean_punishment_sent": 1.3,
    "mean_punishment_received": 2.3,
    "mean_total_voluntary_spend": 12.1,
    "antisocial_punishment_total": 6,
    "prosocial_punishment_total": 7,
    "antisocial_ratio": 0.46153846153846156,
    "group_id": "405"
  },
  "421": {
    "params": {},
    "params_list": [],
    "actual": [
      17,
      19,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Zurich",
    "session": "Zurich_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "antisocial",
    "behavioral_profile": "cooperative-enforcer",
    "contribution_trajectory": [
      17,
      19,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "punishment_sent_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      11
    ],
    "punishment_received_trajectory": [
      1,
      0,
      0,
      0,
      0,
      3,
      0,
      1,
      0,
      2
    ],
    "total_voluntary_spend_trajectory": [
      17,
      19,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      31
    ],
    "others_mean_trajectory": [
      17.666666666666668,
      19.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0
    ],
    "mean_contribution": 19.6,
    "mean_punishment_sent": 1.1,
    "mean_punishment_received": 0.7,
    "mean_total_voluntary_spend": 20.7,
    "antisocial_punishment_total": 11,
    "prosocial_punishment_total": 0,
    "antisocial_ratio": 1.0,
    "group_id": "406"
  },
  "422": {
    "params": {},
    "params_list": [],
    "actual": [
      15,
      18,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Zurich",
    "session": "Zurich_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperator",
    "contribution_trajectory": [
      15,
      18,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "punishment_sent_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "punishment_received_trajectory": [
      4,
      2,
      0,
      0,
      0,
      0,
      3,
      0,
      1,
      3
    ],
    "total_voluntary_spend_trajectory": [
      15,
      18,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "others_mean_trajectory": [
      18.333333333333332,
      19.333333333333332,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0
    ],
    "mean_contribution": 19.3,
    "mean_punishment_sent": 0.0,
    "mean_punishment_received": 1.3,
    "mean_total_voluntary_spend": 19.3,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 0,
    "antisocial_ratio": 0.0,
    "group_id": "406"
  },
  "423": {
    "params": {},
    "params_list": [],
    "actual": [
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Zurich",
    "session": "Zurich_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperator",
    "contribution_trajectory": [
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "punishment_sent_trajectory": [
      2,
      1,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "punishment_received_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      6
    ],
    "total_voluntary_spend_trajectory": [
      22,
      21,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "others_mean_trajectory": [
      16.666666666666668,
      18.666666666666668,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0
    ],
    "mean_contribution": 20.0,
    "mean_punishment_sent": 0.3,
    "mean_punishment_received": 0.6,
    "mean_total_voluntary_spend": 20.3,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 3,
    "antisocial_ratio": 0.0,
    "group_id": "406"
  },
  "424": {
    "params": {},
    "params_list": [],
    "actual": [
      18,
      19,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Zurich",
    "session": "Zurich_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "antisocial",
    "behavioral_profile": "cooperative-enforcer",
    "contribution_trajectory": [
      18,
      19,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "punishment_sent_trajectory": [
      3,
      1,
      0,
      0,
      0,
      3,
      3,
      1,
      1,
      4
    ],
    "punishment_received_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      4
    ],
    "total_voluntary_spend_trajectory": [
      21,
      20,
      20,
      20,
      20,
      23,
      23,
      21,
      21,
      24
    ],
    "others_mean_trajectory": [
      17.333333333333332,
      19.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0
    ],
    "mean_contribution": 19.7,
    "mean_punishment_sent": 1.6,
    "mean_punishment_received": 0.4,
    "mean_total_voluntary_spend": 21.3,
    "antisocial_punishment_total": 12,
    "prosocial_punishment_total": 4,
    "antisocial_ratio": 0.75,
    "group_id": "406"
  },
  "501": {
    "params": {},
    "params_list": [],
    "actual": [
      5,
      20,
      10,
      5,
      0,
      5,
      15,
      13,
      12,
      15
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Zurich",
    "session": "Zurich_P_S2",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "mixed",
    "contribution_trajectory": [
      5,
      20,
      10,
      5,
      0,
      5,
      15,
      13,
      12,
      15
    ],
    "punishment_sent_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "punishment_received_trajectory": [
      5,
      0,
      4,
      1,
      3,
      2,
      0,
      0,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      5,
      20,
      10,
      5,
      0,
      5,
      15,
      13,
      12,
      15
    ],
    "others_mean_trajectory": [
      12.333333333333334,
      16.666666666666668,
      20.0,
      10.0,
      6.666666666666667,
      6.666666666666667,
      9.666666666666666,
      14.0,
      15.333333333333334,
      11.666666666666666
    ],
    "mean_contribution": 10.0,
    "mean_punishment_sent": 0.0,
    "mean_punishment_received": 1.5,
    "mean_total_voluntary_spend": 10.0,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 0,
    "antisocial_ratio": 0.0,
    "group_id": "501"
  },
  "502": {
    "params": {},
    "params_list": [],
    "actual": [
      7,
      10,
      20,
      0,
      10,
      0,
      10,
      12,
      20,
      0
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Zurich",
    "session": "Zurich_P_S2",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "mixed",
    "contribution_trajectory": [
      7,
      10,
      20,
      0,
      10,
      0,
      10,
      12,
      20,
      0
    ],
    "punishment_sent_trajectory": [
      1,
      0,
      2,
      0,
      2,
      0,
      1,
      0,
      0,
      0
    ],
    "punishment_received_trajectory": [
      2,
      2,
      0,
      2,
      0,
      5,
      0,
      3,
      0,
      7
    ],
    "total_voluntary_spend_trajectory": [
      8,
      10,
      22,
      0,
      12,
      0,
      11,
      12,
      20,
      0
    ],
    "others_mean_trajectory": [
      11.666666666666666,
      20.0,
      16.666666666666668,
      11.666666666666666,
      3.3333333333333335,
      8.333333333333334,
      11.333333333333334,
      14.333333333333334,
      12.666666666666666,
      16.666666666666668
    ],
    "mean_contribution": 8.9,
    "mean_punishment_sent": 0.6,
    "mean_punishment_received": 2.1,
    "mean_total_voluntary_spend": 9.5,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 6,
    "antisocial_ratio": 0.0,
    "group_id": "501"
  },
  "503": {
    "params": {},
    "params_list": [],
    "actual": [
      20,
      20,
      20,
      20,
      10,
      10,
      10,
      15,
      15,
      15
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Zurich",
    "session": "Zurich_P_S2",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperative-enforcer",
    "contribution_trajectory": [
      20,
      20,
      20,
      20,
      10,
      10,
      10,
      15,
      15,
      15
    ],
    "punishment_sent_trajectory": [
      3,
      1,
      2,
      4,
      4,
      3,
      3,
      3,
      1,
      3
    ],
    "punishment_received_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      23,
      21,
      22,
      24,
      14,
      13,
      13,
      18,
      16,
      18
    ],
    "others_mean_trajectory": [
      7.333333333333333,
      16.666666666666668,
      16.666666666666668,
      5.0,
      3.3333333333333335,
      5.0,
      11.333333333333334,
      13.333333333333334,
      14.333333333333334,
      11.666666666666666
    ],
    "mean_contribution": 15.5,
    "mean_punishment_sent": 2.7,
    "mean_punishment_received": 0.0,
    "mean_total_voluntary_spend": 18.2,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 27,
    "antisocial_ratio": 0.0,
    "group_id": "501"
  },
  "504": {
    "params": {},
    "params_list": [],
    "actual": [
      10,
      20,
      20,
      10,
      0,
      10,
      9,
      15,
      11,
      20
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Zurich",
    "session": "Zurich_P_S2",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperative-enforcer",
    "contribution_trajectory": [
      10,
      20,
      20,
      10,
      0,
      10,
      9,
      15,
      11,
      20
    ],
    "punishment_sent_trajectory": [
      3,
      1,
      0,
      0,
      0,
      4,
      0,
      0,
      0,
      4
    ],
    "punishment_received_trajectory": [
      0,
      0,
      0,
      1,
      3,
      0,
      4,
      0,
      1,
      0
    ],
    "total_voluntary_spend_trajectory": [
      13,
      21,
      20,
      10,
      0,
      14,
      9,
      15,
      11,
      24
    ],
    "others_mean_trajectory": [
      10.666666666666666,
      16.666666666666668,
      16.666666666666668,
      8.333333333333334,
      6.666666666666667,
      5.0,
      11.666666666666666,
      13.333333333333334,
      15.666666666666666,
      10.0
    ],
    "mean_contribution": 12.5,
    "mean_punishment_sent": 1.2,
    "mean_punishment_received": 0.9,
    "mean_total_voluntary_spend": 13.7,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 12,
    "antisocial_ratio": 0.0,
    "group_id": "501"
  },
  "505": {
    "params": {},
    "params_list": [],
    "actual": [
      1,
      7,
      8,
      7,
      3,
      7,
      8,
      7,
      8,
      8
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Zurich",
    "session": "Zurich_P_S2",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "mixed",
    "contribution_trajectory": [
      1,
      7,
      8,
      7,
      3,
      7,
      8,
      7,
      8,
      8
    ],
    "punishment_sent_trajectory": [
      0,
      0,
      3,
      1,
      4,
      2,
      2,
      0,
      2,
      1
    ],
    "punishment_received_trajectory": [
      4,
      2,
      1,
      2,
      5,
      1,
      1,
      2,
      0,
      3
    ],
    "total_voluntary_spend_trajectory": [
      1,
      7,
      11,
      8,
      7,
      9,
      10,
      7,
      10,
      9
    ],
    "others_mean_trajectory": [
      7.666666666666667,
      7.666666666666667,
      8.0,
      7.666666666666667,
      9.0,
      6.333333333333333,
      7.0,
      7.666666666666667,
      6.666666666666667,
      7.333333333333333
    ],
    "mean_contribution": 6.4,
    "mean_punishment_sent": 1.5,
    "mean_punishment_received": 2.1,
    "mean_total_voluntary_spend": 7.9,
    "antisocial_punishment_total": 7,
    "prosocial_punishment_total": 8,
    "antisocial_ratio": 0.4666666666666667,
    "group_id": "502"
  },
  "506": {
    "params": {},
    "params_list": [],
    "actual": [
      5,
      10,
      10,
      8,
      12,
      8,
      8,
      8,
      8,
      8
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Zurich",
    "session": "Zurich_P_S2",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "mixed",
    "contribution_trajectory": [
      5,
      10,
      10,
      8,
      12,
      8,
      8,
      8,
      8,
      8
    ],
    "punishment_sent_trajectory": [
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      0,
      0,
      0
    ],
    "punishment_received_trajectory": [
      2,
      1,
      1,
      3,
      4,
      0,
      1,
      1,
      1,
      4
    ],
    "total_voluntary_spend_trajectory": [
      6,
      11,
      11,
      9,
      13,
      9,
      9,
      8,
      8,
      8
    ],
    "others_mean_trajectory": [
      6.333333333333333,
      6.666666666666667,
      7.333333333333333,
      7.333333333333333,
      6.0,
      6.0,
      7.0,
      7.333333333333333,
      6.666666666666667,
      7.333333333333333
    ],
    "mean_contribution": 8.5,
    "mean_punishment_sent": 0.7,
    "mean_punishment_received": 1.8,
    "mean_total_voluntary_spend": 9.2,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 7,
    "antisocial_ratio": 0.0,
    "group_id": "502"
  },
  "507": {
    "params": {},
    "params_list": [],
    "actual": [
      8,
      8,
      8,
      10,
      9,
      8,
      8,
      9,
      9,
      9
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Zurich",
    "session": "Zurich_P_S2",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "mixed",
    "contribution_trajectory": [
      8,
      8,
      8,
      10,
      9,
      8,
      8,
      9,
      9,
      9
    ],
    "punishment_sent_trajectory": [
      4,
      2,
      2,
      5,
      5,
      5,
      2,
      3,
      5,
      10
    ],
    "punishment_received_trajectory": [
      1,
      1,
      2,
      1,
      2,
      0,
      0,
      0,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      12,
      10,
      10,
      15,
      14,
      13,
      10,
      12,
      14,
      19
    ],
    "others_mean_trajectory": [
      5.333333333333333,
      7.333333333333333,
      8.0,
      6.666666666666667,
      7.0,
      6.0,
      7.0,
      7.0,
      6.333333333333333,
      7.0
    ],
    "mean_contribution": 8.6,
    "mean_punishment_sent": 4.3,
    "mean_punishment_received": 0.7,
    "mean_total_voluntary_spend": 12.9,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 43,
    "antisocial_ratio": 0.0,
    "group_id": "502"
  },
  "508": {
    "params": {},
    "params_list": [],
    "actual": [
      10,
      5,
      6,
      5,
      6,
      3,
      5,
      6,
      3,
      5
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Zurich",
    "session": "Zurich_P_S2",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "antisocial",
    "behavioral_profile": "mixed",
    "contribution_trajectory": [
      10,
      5,
      6,
      5,
      6,
      3,
      5,
      6,
      3,
      5
    ],
    "punishment_sent_trajectory": [
      2,
      3,
      2,
      3,
      3,
      1,
      2,
      2,
      1,
      1
    ],
    "punishment_received_trajectory": [
      0,
      2,
      4,
      4,
      2,
      8,
      5,
      2,
      7,
      5
    ],
    "total_voluntary_spend_trajectory": [
      12,
      8,
      8,
      8,
      9,
      4,
      7,
      8,
      4,
      6
    ],
    "others_mean_trajectory": [
      4.666666666666667,
      8.333333333333334,
      8.666666666666666,
      8.333333333333334,
      8.0,
      7.666666666666667,
      8.0,
      8.0,
      8.333333333333334,
      8.333333333333334
    ],
    "mean_contribution": 5.4,
    "mean_punishment_sent": 2.0,
    "mean_punishment_received": 3.9,
    "mean_total_voluntary_spend": 7.4,
    "antisocial_punishment_total": 18,
    "prosocial_punishment_total": 2,
    "antisocial_ratio": 0.9,
    "group_id": "502"
  },
  "509": {
    "params": {},
    "params_list": [],
    "actual": [
      7,
      12,
      16,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Zurich",
    "session": "Zurich_P_S2",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "antisocial",
    "behavioral_profile": "cooperative-enforcer",
    "contribution_trajectory": [
      7,
      12,
      16,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "punishment_sent_trajectory": [
      2,
      8,
      4,
      0,
      0,
      0,
      0,
      4,
      0,
      0
    ],
    "punishment_received_trajectory": [
      8,
      10,
      6,
      0,
      0,
      0,
      0,
      0,
      0,
      1
    ],
    "total_voluntary_spend_trajectory": [
      9,
      20,
      20,
      20,
      20,
      20,
      20,
      24,
      20,
      20
    ],
    "others_mean_trajectory": [
      15.0,
      18.333333333333332,
      19.666666666666668,
      20.0,
      20.0,
      20.0,
      20.0,
      13.333333333333334,
      20.0,
      20.0
    ],
    "mean_contribution": 17.5,
    "mean_punishment_sent": 1.8,
    "mean_punishment_received": 2.5,
    "mean_total_voluntary_spend": 19.3,
    "antisocial_punishment_total": 14,
    "prosocial_punishment_total": 4,
    "antisocial_ratio": 0.7777777777777778,
    "group_id": "503"
  },
  "510": {
    "params": {},
    "params_list": [],
    "actual": [
      17,
      20,
      19,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Zurich",
    "session": "Zurich_P_S2",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperative-enforcer",
    "contribution_trajectory": [
      17,
      20,
      19,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "punishment_sent_trajectory": [
      10,
      11,
      2,
      0,
      0,
      0,
      0,
      2,
      0,
      0
    ],
    "punishment_received_trajectory": [
      2,
      3,
      2,
      0,
      0,
      0,
      0,
      0,
      0,
      1
    ],
    "total_voluntary_spend_trajectory": [
      27,
      31,
      21,
      20,
      20,
      20,
      20,
      22,
      20,
      20
    ],
    "others_mean_trajectory": [
      11.666666666666666,
      15.666666666666666,
      18.666666666666668,
      20.0,
      20.0,
      20.0,
      20.0,
      13.333333333333334,
      20.0,
      20.0
    ],
    "mean_contribution": 19.6,
    "mean_punishment_sent": 2.5,
    "mean_punishment_received": 0.8,
    "mean_total_voluntary_spend": 22.1,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 25,
    "antisocial_ratio": 0.0,
    "group_id": "503"
  },
  "511": {
    "params": {},
    "params_list": [],
    "actual": [
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      0,
      20,
      20
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Zurich",
    "session": "Zurich_P_S2",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperator",
    "contribution_trajectory": [
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      0,
      20,
      20
    ],
    "punishment_sent_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "punishment_received_trajectory": [
      1,
      3,
      2,
      0,
      0,
      0,
      0,
      16,
      0,
      1
    ],
    "total_voluntary_spend_trajectory": [
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      0,
      20,
      20
    ],
    "others_mean_trajectory": [
      10.666666666666666,
      15.666666666666666,
      18.333333333333332,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0
    ],
    "mean_contribution": 18.0,
    "mean_punishment_sent": 0.0,
    "mean_punishment_received": 2.3,
    "mean_total_voluntary_spend": 18.0,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 0,
    "antisocial_ratio": 0.0,
    "group_id": "503"
  },
  "512": {
    "params": {},
    "params_list": [],
    "actual": [
      8,
      15,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Zurich",
    "session": "Zurich_P_S2",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperative-enforcer",
    "contribution_trajectory": [
      8,
      15,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "punishment_sent_trajectory": [
      4,
      4,
      6,
      0,
      0,
      0,
      0,
      10,
      0,
      3
    ],
    "punishment_received_trajectory": [
      5,
      7,
      2,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      12,
      19,
      26,
      20,
      20,
      20,
      20,
      30,
      20,
      23
    ],
    "others_mean_trajectory": [
      14.666666666666666,
      17.333333333333332,
      18.333333333333332,
      20.0,
      20.0,
      20.0,
      20.0,
      13.333333333333334,
      20.0,
      20.0
    ],
    "mean_contribution": 18.3,
    "mean_punishment_sent": 2.7,
    "mean_punishment_received": 1.4,
    "mean_total_voluntary_spend": 21.0,
    "antisocial_punishment_total": 4,
    "prosocial_punishment_total": 23,
    "antisocial_ratio": 0.14814814814814814,
    "group_id": "503"
  },
  "513": {
    "params": {},
    "params_list": [],
    "actual": [
      5,
      8,
      7,
      10,
      9,
      10,
      10,
      9,
      8,
      11
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Zurich",
    "session": "Zurich_P_S2",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "mixed",
    "contribution_trajectory": [
      5,
      8,
      7,
      10,
      9,
      10,
      10,
      9,
      8,
      11
    ],
    "punishment_sent_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      2
    ],
    "punishment_received_trajectory": [
      6,
      3,
      7,
      1,
      3,
      0,
      0,
      2,
      4,
      0
    ],
    "total_voluntary_spend_trajectory": [
      5,
      8,
      7,
      10,
      9,
      10,
      10,
      9,
      8,
      13
    ],
    "others_mean_trajectory": [
      11.333333333333334,
      12.333333333333334,
      13.0,
      12.0,
      12.0,
      11.0,
      11.0,
      10.666666666666666,
      10.333333333333334,
      7.0
    ],
    "mean_contribution": 8.7,
    "mean_punishment_sent": 0.2,
    "mean_punishment_received": 2.6,
    "mean_total_voluntary_spend": 8.9,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 2,
    "antisocial_ratio": 0.0,
    "group_id": "504"
  },
  "514": {
    "params": {},
    "params_list": [],
    "actual": [
      15,
      14,
      14,
      13,
      12,
      12,
      10,
      10,
      10,
      11
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Zurich",
    "session": "Zurich_P_S2",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperative-enforcer",
    "contribution_trajectory": [
      15,
      14,
      14,
      13,
      12,
      12,
      10,
      10,
      10,
      11
    ],
    "punishment_sent_trajectory": [
      4,
      2,
      4,
      1,
      2,
      0,
      0,
      1,
      2,
      5
    ],
    "punishment_received_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      1,
      0
    ],
    "total_voluntary_spend_trajectory": [
      19,
      16,
      18,
      14,
      14,
      12,
      10,
      11,
      12,
      16
    ],
    "others_mean_trajectory": [
      8.0,
      10.333333333333334,
      10.666666666666666,
      11.0,
      11.0,
      10.333333333333334,
      11.0,
      10.333333333333334,
      9.666666666666666,
      7.0
    ],
    "mean_contribution": 12.1,
    "mean_punishment_sent": 2.1,
    "mean_punishment_received": 0.1,
    "mean_total_voluntary_spend": 14.2,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 21,
    "antisocial_ratio": 0.0,
    "group_id": "504"
  },
  "515": {
    "params": {},
    "params_list": [],
    "actual": [
      10,
      12,
      13,
      12,
      11,
      11,
      11,
      10,
      10,
      0
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Zurich",
    "session": "Zurich_P_S2",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "mixed",
    "contribution_trajectory": [
      10,
      12,
      13,
      12,
      11,
      11,
      11,
      10,
      10,
      0
    ],
    "punishment_sent_trajectory": [
      1,
      0,
      1,
      0,
      0,
      0,
      0,
      0,
      3,
      0
    ],
    "punishment_received_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      7
    ],
    "total_voluntary_spend_trajectory": [
      11,
      12,
      14,
      12,
      11,
      11,
      11,
      10,
      13,
      0
    ],
    "others_mean_trajectory": [
      9.666666666666666,
      11.0,
      11.0,
      11.333333333333334,
      11.333333333333334,
      10.666666666666666,
      10.666666666666666,
      10.333333333333334,
      9.666666666666666,
      10.666666666666666
    ],
    "mean_contribution": 10.0,
    "mean_punishment_sent": 0.5,
    "mean_punishment_received": 0.7,
    "mean_total_voluntary_spend": 10.5,
    "antisocial_punishment_total": 2,
    "prosocial_punishment_total": 3,
    "antisocial_ratio": 0.4,
    "group_id": "504"
  },
  "516": {
    "params": {},
    "params_list": [],
    "actual": [
      9,
      11,
      12,
      11,
      13,
      10,
      12,
      12,
      11,
      10
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Zurich",
    "session": "Zurich_P_S2",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperative-enforcer",
    "contribution_trajectory": [
      9,
      11,
      12,
      11,
      13,
      10,
      12,
      12,
      11,
      10
    ],
    "punishment_sent_trajectory": [
      2,
      1,
      2,
      0,
      1,
      0,
      0,
      1,
      1,
      0
    ],
    "punishment_received_trajectory": [
      1,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      1,
      0
    ],
    "total_voluntary_spend_trajectory": [
      11,
      12,
      14,
      11,
      14,
      10,
      12,
      13,
      12,
      10
    ],
    "others_mean_trajectory": [
      10.0,
      11.333333333333334,
      11.333333333333334,
      11.666666666666666,
      10.666666666666666,
      11.0,
      10.333333333333334,
      9.666666666666666,
      9.333333333333334,
      7.333333333333333
    ],
    "mean_contribution": 11.1,
    "mean_punishment_sent": 0.8,
    "mean_punishment_received": 0.2,
    "mean_total_voluntary_spend": 11.9,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 8,
    "antisocial_ratio": 0.0,
    "group_id": "504"
  },
  "517": {
    "params": {},
    "params_list": [],
    "actual": [
      8,
      11,
      15,
      15,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Zurich",
    "session": "Zurich_P_S2",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperative-enforcer",
    "contribution_trajectory": [
      8,
      11,
      15,
      15,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "punishment_sent_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      6
    ],
    "punishment_received_trajectory": [
      0,
      1,
      1,
      0,
      1,
      0,
      0,
      0,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      8,
      11,
      15,
      15,
      20,
      20,
      20,
      20,
      20,
      26
    ],
    "others_mean_trajectory": [
      11.333333333333334,
      13.333333333333334,
      11.666666666666666,
      15.0,
      16.666666666666668,
      18.666666666666668,
      19.666666666666668,
      20.0,
      20.0,
      10.333333333333334
    ],
    "mean_contribution": 16.9,
    "mean_punishment_sent": 0.6,
    "mean_punishment_received": 0.3,
    "mean_total_voluntary_spend": 17.5,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 6,
    "antisocial_ratio": 0.0,
    "group_id": "505"
  },
  "518": {
    "params": {},
    "params_list": [],
    "actual": [
      15,
      13,
      15,
      16,
      17,
      20,
      20,
      20,
      20,
      0
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Zurich",
    "session": "Zurich_P_S2",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperative-enforcer",
    "contribution_trajectory": [
      15,
      13,
      15,
      16,
      17,
      20,
      20,
      20,
      20,
      0
    ],
    "punishment_sent_trajectory": [
      0,
      1,
      3,
      1,
      0,
      2,
      1,
      0,
      0,
      0
    ],
    "punishment_received_trajectory": [
      1,
      1,
      1,
      1,
      1,
      0,
      0,
      0,
      0,
      6
    ],
    "total_voluntary_spend_trajectory": [
      15,
      14,
      18,
      17,
      17,
      22,
      21,
      20,
      20,
      0
    ],
    "others_mean_trajectory": [
      9.0,
      12.666666666666666,
      11.666666666666666,
      14.666666666666666,
      17.666666666666668,
      18.666666666666668,
      19.666666666666668,
      20.0,
      20.0,
      17.0
    ],
    "mean_contribution": 15.6,
    "mean_punishment_sent": 0.8,
    "mean_punishment_received": 1.1,
    "mean_total_voluntary_spend": 16.4,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 8,
    "antisocial_ratio": 0.0,
    "group_id": "505"
  },
  "519": {
    "params": {},
    "params_list": [],
    "actual": [
      11,
      17,
      12,
      15,
      17,
      20,
      19,
      20,
      20,
      11
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Zurich",
    "session": "Zurich_P_S2",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperative-enforcer",
    "contribution_trajectory": [
      11,
      17,
      12,
      15,
      17,
      20,
      19,
      20,
      20,
      11
    ],
    "punishment_sent_trajectory": [
      1,
      2,
      0,
      1,
      0,
      1,
      0,
      0,
      0,
      0
    ],
    "punishment_received_trajectory": [
      1,
      1,
      0,
      0,
      0,
      1,
      2,
      0,
      0,
      3
    ],
    "total_voluntary_spend_trajectory": [
      12,
      19,
      12,
      16,
      17,
      21,
      19,
      20,
      20,
      11
    ],
    "others_mean_trajectory": [
      10.333333333333334,
      11.333333333333334,
      12.666666666666666,
      15.0,
      17.666666666666668,
      18.666666666666668,
      20.0,
      20.0,
      20.0,
      13.333333333333334
    ],
    "mean_contribution": 16.2,
    "mean_punishment_sent": 0.5,
    "mean_punishment_received": 0.8,
    "mean_total_voluntary_spend": 16.7,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 5,
    "antisocial_ratio": 0.0,
    "group_id": "505"
  },
  "520": {
    "params": {},
    "params_list": [],
    "actual": [
      8,
      10,
      8,
      14,
      16,
      16,
      20,
      20,
      20,
      20
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Zurich",
    "session": "Zurich_P_S2",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "antisocial",
    "behavioral_profile": "cooperative-enforcer",
    "contribution_trajectory": [
      8,
      10,
      8,
      14,
      16,
      16,
      20,
      20,
      20,
      20
    ],
    "punishment_sent_trajectory": [
      2,
      2,
      2,
      1,
      2,
      1,
      1,
      0,
      0,
      3
    ],
    "punishment_received_trajectory": [
      1,
      2,
      3,
      2,
      0,
      3,
      0,
      0,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      10,
      12,
      10,
      15,
      18,
      17,
      21,
      20,
      20,
      23
    ],
    "others_mean_trajectory": [
      11.333333333333334,
      13.666666666666666,
      14.0,
      15.333333333333334,
      18.0,
      20.0,
      19.666666666666668,
      20.0,
      20.0,
      10.333333333333334
    ],
    "mean_contribution": 15.2,
    "mean_punishment_sent": 1.4,
    "mean_punishment_received": 1.1,
    "mean_total_voluntary_spend": 16.6,
    "antisocial_punishment_total": 10,
    "prosocial_punishment_total": 4,
    "antisocial_ratio": 0.7142857142857143,
    "group_id": "505"
  },
  "521": {
    "params": {},
    "params_list": [],
    "actual": [
      15,
      15,
      16,
      8,
      18,
      18,
      20,
      17,
      16,
      16
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Zurich",
    "session": "Zurich_P_S2",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperative-enforcer",
    "contribution_trajectory": [
      15,
      15,
      16,
      8,
      18,
      18,
      20,
      17,
      16,
      16
    ],
    "punishment_sent_trajectory": [
      2,
      2,
      1,
      3,
      1,
      2,
      1,
      3,
      3,
      0
    ],
    "punishment_received_trajectory": [
      1,
      3,
      4,
      9,
      2,
      3,
      2,
      5,
      2,
      12
    ],
    "total_voluntary_spend_trajectory": [
      17,
      17,
      17,
      11,
      19,
      20,
      21,
      20,
      19,
      16
    ],
    "others_mean_trajectory": [
      12.0,
      14.333333333333334,
      14.333333333333334,
      17.0,
      17.666666666666668,
      18.666666666666668,
      19.0,
      13.333333333333334,
      18.0,
      19.333333333333332
    ],
    "mean_contribution": 15.9,
    "mean_punishment_sent": 1.8,
    "mean_punishment_received": 4.3,
    "mean_total_voluntary_spend": 17.7,
    "antisocial_punishment_total": 6,
    "prosocial_punishment_total": 12,
    "antisocial_ratio": 0.3333333333333333,
    "group_id": "506"
  },
  "522": {
    "params": {},
    "params_list": [],
    "actual": [
      20,
      20,
      15,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Zurich",
    "session": "Zurich_P_S2",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperative-enforcer",
    "contribution_trajectory": [
      20,
      20,
      15,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "punishment_sent_trajectory": [
      9,
      6,
      2,
      5,
      0,
      0,
      1,
      10,
      3,
      27
    ],
    "punishment_received_trajectory": [
      0,
      2,
      4,
      0,
      0,
      2,
      2,
      4,
      1,
      2
    ],
    "total_voluntary_spend_trajectory": [
      29,
      26,
      17,
      25,
      20,
      20,
      21,
      30,
      23,
      47
    ],
    "others_mean_trajectory": [
      10.333333333333334,
      12.666666666666666,
      14.666666666666666,
      13.0,
      17.0,
      18.0,
      19.0,
      12.333333333333334,
      16.666666666666668,
      18.0
    ],
    "mean_contribution": 19.5,
    "mean_punishment_sent": 6.3,
    "mean_punishment_received": 1.7,
    "mean_total_voluntary_spend": 25.8,
    "antisocial_punishment_total": 9,
    "prosocial_punishment_total": 54,
    "antisocial_ratio": 0.14285714285714285,
    "group_id": "506"
  },
  "523": {
    "params": {},
    "params_list": [],
    "actual": [
      8,
      15,
      15,
      16,
      17,
      20,
      20,
      20,
      16,
      20
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Zurich",
    "session": "Zurich_P_S2",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperative-enforcer",
    "contribution_trajectory": [
      8,
      15,
      15,
      16,
      17,
      20,
      20,
      20,
      16,
      20
    ],
    "punishment_sent_trajectory": [
      0,
      3,
      0,
      2,
      0,
      3,
      2,
      8,
      0,
      1
    ],
    "punishment_received_trajectory": [
      7,
      3,
      4,
      1,
      2,
      0,
      2,
      4,
      4,
      11
    ],
    "total_voluntary_spend_trajectory": [
      8,
      18,
      15,
      18,
      17,
      23,
      22,
      28,
      16,
      21
    ],
    "others_mean_trajectory": [
      14.333333333333334,
      14.333333333333334,
      14.666666666666666,
      14.333333333333334,
      18.0,
      18.0,
      19.0,
      12.333333333333334,
      18.0,
      18.0
    ],
    "mean_contribution": 16.7,
    "mean_punishment_sent": 1.9,
    "mean_punishment_received": 3.8,
    "mean_total_voluntary_spend": 18.6,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 19,
    "antisocial_ratio": 0.0,
    "group_id": "506"
  },
  "524": {
    "params": {},
    "params_list": [],
    "actual": [
      8,
      8,
      13,
      15,
      16,
      16,
      17,
      0,
      18,
      18
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Zurich",
    "session": "Zurich_P_S2",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "antisocial",
    "behavioral_profile": "cooperative-enforcer",
    "contribution_trajectory": [
      8,
      8,
      13,
      15,
      16,
      16,
      17,
      0,
      18,
      18
    ],
    "punishment_sent_trajectory": [
      2,
      6,
      12,
      2,
      4,
      4,
      6,
      11,
      3,
      6
    ],
    "punishment_received_trajectory": [
      5,
      9,
      3,
      2,
      1,
      4,
      4,
      19,
      2,
      9
    ],
    "total_voluntary_spend_trajectory": [
      10,
      14,
      25,
      17,
      20,
      20,
      23,
      11,
      21,
      24
    ],
    "others_mean_trajectory": [
      14.333333333333334,
      16.666666666666668,
      15.333333333333334,
      14.666666666666666,
      18.333333333333332,
      19.333333333333332,
      20.0,
      19.0,
      17.333333333333332,
      18.666666666666668
    ],
    "mean_contribution": 12.9,
    "mean_punishment_sent": 5.6,
    "mean_punishment_received": 5.8,
    "mean_total_voluntary_spend": 18.5,
    "antisocial_punishment_total": 50,
    "prosocial_punishment_total": 6,
    "antisocial_ratio": 0.8928571428571429,
    "group_id": "506"
  },
  "5901": {
    "params": {},
    "params_list": [],
    "actual": [
      5,
      5,
      5,
      5,
      5,
      5,
      5,
      5,
      5,
      1
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Athens",
    "session": "Athens_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "punitive-free-rider",
    "contribution_trajectory": [
      5,
      5,
      5,
      5,
      5,
      5,
      5,
      5,
      5,
      1
    ],
    "punishment_sent_trajectory": [
      27,
      3,
      15,
      3,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "punishment_received_trajectory": [
      2,
      15,
      11,
      7,
      14,
      5,
      2,
      1,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      32,
      8,
      20,
      8,
      5,
      5,
      5,
      5,
      5,
      1
    ],
    "others_mean_trajectory": [
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0
    ],
    "mean_contribution": 4.6,
    "mean_punishment_sent": 4.8,
    "mean_punishment_received": 5.7,
    "mean_total_voluntary_spend": 9.4,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 48,
    "antisocial_ratio": 0.0,
    "group_id": "5901"
  },
  "5902": {
    "params": {},
    "params_list": [],
    "actual": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Athens",
    "session": "Athens_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "antisocial",
    "behavioral_profile": "antisocial-controller",
    "contribution_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "punishment_sent_trajectory": [
      1,
      3,
      9,
      6,
      8,
      4,
      2,
      3,
      2,
      2
    ],
    "punishment_received_trajectory": [
      11,
      17,
      14,
      6,
      10,
      8,
      5,
      0,
      1,
      0
    ],
    "total_voluntary_spend_trajectory": [
      1,
      3,
      9,
      6,
      8,
      4,
      2,
      3,
      2,
      2
    ],
    "others_mean_trajectory": [
      1.6666666666666667,
      1.6666666666666667,
      1.6666666666666667,
      1.6666666666666667,
      1.6666666666666667,
      1.6666666666666667,
      1.6666666666666667,
      1.6666666666666667,
      1.6666666666666667,
      0.3333333333333333
    ],
    "mean_contribution": 0.0,
    "mean_punishment_sent": 4.0,
    "mean_punishment_received": 7.2,
    "mean_total_voluntary_spend": 4.0,
    "antisocial_punishment_total": 40,
    "prosocial_punishment_total": 0,
    "antisocial_ratio": 1.0,
    "group_id": "5901"
  },
  "5903": {
    "params": {},
    "params_list": [],
    "actual": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Athens",
    "session": "Athens_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "antisocial",
    "behavioral_profile": "antisocial-controller",
    "contribution_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "punishment_sent_trajectory": [
      6,
      20,
      15,
      20,
      20,
      20,
      0,
      0,
      0,
      2
    ],
    "punishment_received_trajectory": [
      9,
      12,
      14,
      3,
      9,
      3,
      6,
      2,
      2,
      1
    ],
    "total_voluntary_spend_trajectory": [
      6,
      20,
      15,
      20,
      20,
      20,
      0,
      0,
      0,
      2
    ],
    "others_mean_trajectory": [
      1.6666666666666667,
      1.6666666666666667,
      1.6666666666666667,
      1.6666666666666667,
      1.6666666666666667,
      1.6666666666666667,
      1.6666666666666667,
      1.6666666666666667,
      1.6666666666666667,
      0.3333333333333333
    ],
    "mean_contribution": 0.0,
    "mean_punishment_sent": 10.3,
    "mean_punishment_received": 6.1,
    "mean_total_voluntary_spend": 10.3,
    "antisocial_punishment_total": 103,
    "prosocial_punishment_total": 0,
    "antisocial_ratio": 1.0,
    "group_id": "5901"
  },
  "5904": {
    "params": {},
    "params_list": [],
    "actual": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Athens",
    "session": "Athens_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "antisocial",
    "behavioral_profile": "antisocial-controller",
    "contribution_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "punishment_sent_trajectory": [
      0,
      27,
      14,
      0,
      13,
      6,
      12,
      1,
      2,
      0
    ],
    "punishment_received_trajectory": [
      12,
      9,
      14,
      13,
      8,
      14,
      1,
      1,
      1,
      3
    ],
    "total_voluntary_spend_trajectory": [
      0,
      27,
      14,
      0,
      13,
      6,
      12,
      1,
      2,
      0
    ],
    "others_mean_trajectory": [
      1.6666666666666667,
      1.6666666666666667,
      1.6666666666666667,
      1.6666666666666667,
      1.6666666666666667,
      1.6666666666666667,
      1.6666666666666667,
      1.6666666666666667,
      1.6666666666666667,
      0.3333333333333333
    ],
    "mean_contribution": 0.0,
    "mean_punishment_sent": 7.5,
    "mean_punishment_received": 7.6,
    "mean_total_voluntary_spend": 7.5,
    "antisocial_punishment_total": 75,
    "prosocial_punishment_total": 0,
    "antisocial_ratio": 1.0,
    "group_id": "5901"
  },
  "5905": {
    "params": {},
    "params_list": [],
    "actual": [
      8,
      7,
      7,
      11,
      10,
      14,
      10,
      5,
      7,
      4
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Athens",
    "session": "Athens_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "mixed",
    "contribution_trajectory": [
      8,
      7,
      7,
      11,
      10,
      14,
      10,
      5,
      7,
      4
    ],
    "punishment_sent_trajectory": [
      0,
      3,
      3,
      2,
      7,
      6,
      4,
      0,
      3,
      3
    ],
    "punishment_received_trajectory": [
      3,
      1,
      1,
      6,
      1,
      3,
      5,
      0,
      0,
      5
    ],
    "total_voluntary_spend_trajectory": [
      8,
      10,
      10,
      13,
      17,
      20,
      14,
      5,
      10,
      7
    ],
    "others_mean_trajectory": [
      8.333333333333334,
      8.666666666666666,
      7.333333333333333,
      12.0,
      10.333333333333334,
      10.666666666666666,
      8.666666666666666,
      3.6666666666666665,
      5.666666666666667,
      10.0
    ],
    "mean_contribution": 8.3,
    "mean_punishment_sent": 3.1,
    "mean_punishment_received": 2.5,
    "mean_total_voluntary_spend": 11.4,
    "antisocial_punishment_total": 8,
    "prosocial_punishment_total": 23,
    "antisocial_ratio": 0.25806451612903225,
    "group_id": "5902"
  },
  "5906": {
    "params": {},
    "params_list": [],
    "actual": [
      10,
      10,
      10,
      6,
      8,
      10,
      8,
      0,
      5,
      5
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Athens",
    "session": "Athens_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "mixed",
    "contribution_trajectory": [
      10,
      10,
      10,
      6,
      8,
      10,
      8,
      0,
      5,
      5
    ],
    "punishment_sent_trajectory": [
      4,
      1,
      5,
      0,
      1,
      4,
      6,
      0,
      0,
      6
    ],
    "punishment_received_trajectory": [
      1,
      1,
      1,
      6,
      2,
      4,
      7,
      3,
      1,
      0
    ],
    "total_voluntary_spend_trajectory": [
      14,
      11,
      15,
      6,
      9,
      14,
      14,
      0,
      5,
      11
    ],
    "others_mean_trajectory": [
      7.666666666666667,
      7.666666666666667,
      6.333333333333333,
      13.666666666666666,
      11.0,
      12.0,
      9.333333333333334,
      5.333333333333333,
      6.333333333333333,
      9.666666666666666
    ],
    "mean_contribution": 7.2,
    "mean_punishment_sent": 2.7,
    "mean_punishment_received": 2.6,
    "mean_total_voluntary_spend": 9.9,
    "antisocial_punishment_total": 8,
    "prosocial_punishment_total": 19,
    "antisocial_ratio": 0.2962962962962963,
    "group_id": "5902"
  },
  "5907": {
    "params": {},
    "params_list": [],
    "actual": [
      10,
      6,
      7,
      10,
      18,
      17,
      13,
      6,
      7,
      20
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Athens",
    "session": "Athens_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperative-enforcer",
    "contribution_trajectory": [
      10,
      6,
      7,
      10,
      18,
      17,
      13,
      6,
      7,
      20
    ],
    "punishment_sent_trajectory": [
      2,
      1,
      1,
      1,
      3,
      2,
      3,
      3,
      3,
      5
    ],
    "punishment_received_trajectory": [
      1,
      1,
      2,
      6,
      1,
      3,
      7,
      0,
      1,
      8
    ],
    "total_voluntary_spend_trajectory": [
      12,
      7,
      8,
      11,
      21,
      19,
      16,
      9,
      10,
      25
    ],
    "others_mean_trajectory": [
      7.666666666666667,
      9.0,
      7.333333333333333,
      12.333333333333334,
      7.666666666666667,
      9.666666666666666,
      7.666666666666667,
      3.3333333333333335,
      5.666666666666667,
      4.666666666666667
    ],
    "mean_contribution": 11.4,
    "mean_punishment_sent": 2.4,
    "mean_punishment_received": 3.0,
    "mean_total_voluntary_spend": 13.8,
    "antisocial_punishment_total": 1,
    "prosocial_punishment_total": 23,
    "antisocial_ratio": 0.041666666666666664,
    "group_id": "5902"
  },
  "5908": {
    "params": {},
    "params_list": [],
    "actual": [
      5,
      10,
      5,
      20,
      5,
      5,
      5,
      5,
      5,
      5
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Athens",
    "session": "Athens_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "antisocial",
    "behavioral_profile": "mixed",
    "contribution_trajectory": [
      5,
      10,
      5,
      20,
      5,
      5,
      5,
      5,
      5,
      5
    ],
    "punishment_sent_trajectory": [
      3,
      1,
      1,
      15,
      3,
      9,
      15,
      0,
      0,
      0
    ],
    "punishment_received_trajectory": [
      4,
      3,
      6,
      0,
      10,
      11,
      9,
      0,
      4,
      1
    ],
    "total_voluntary_spend_trajectory": [
      8,
      11,
      6,
      35,
      8,
      14,
      20,
      5,
      5,
      5
    ],
    "others_mean_trajectory": [
      9.333333333333334,
      7.666666666666667,
      8.0,
      9.0,
      12.0,
      13.666666666666666,
      10.333333333333334,
      3.6666666666666665,
      6.333333333333333,
      9.666666666666666
    ],
    "mean_contribution": 7.0,
    "mean_punishment_sent": 4.7,
    "mean_punishment_received": 4.8,
    "mean_total_voluntary_spend": 11.7,
    "antisocial_punishment_total": 32,
    "prosocial_punishment_total": 15,
    "antisocial_ratio": 0.6808510638297872,
    "group_id": "5902"
  },
  "5909": {
    "params": {},
    "params_list": [],
    "actual": [
      0,
      0,
      0,
      0,
      3,
      0,
      2,
      2,
      0,
      0
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Athens",
    "session": "Athens_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "free-rider",
    "contribution_trajectory": [
      0,
      0,
      0,
      0,
      3,
      0,
      2,
      2,
      0,
      0
    ],
    "punishment_sent_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      2,
      0,
      0,
      0
    ],
    "punishment_received_trajectory": [
      0,
      1,
      9,
      7,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      0,
      0,
      0,
      0,
      3,
      0,
      4,
      2,
      0,
      0
    ],
    "others_mean_trajectory": [
      9.333333333333334,
      4.333333333333333,
      7.0,
      5.666666666666667,
      7.333333333333333,
      4.333333333333333,
      2.0,
      0.0,
      0.0,
      0.6666666666666666
    ],
    "mean_contribution": 0.7,
    "mean_punishment_sent": 0.2,
    "mean_punishment_received": 1.7,
    "mean_total_voluntary_spend": 0.9,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 2,
    "antisocial_ratio": 0.0,
    "group_id": "5903"
  },
  "5910": {
    "params": {},
    "params_list": [],
    "actual": [
      8,
      10,
      2,
      15,
      4,
      6,
      1,
      0,
      0,
      1
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Athens",
    "session": "Athens_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "punitive-free-rider",
    "contribution_trajectory": [
      8,
      10,
      2,
      15,
      4,
      6,
      1,
      0,
      0,
      1
    ],
    "punishment_sent_trajectory": [
      0,
      3,
      0,
      5,
      1,
      0,
      0,
      0,
      0,
      0
    ],
    "punishment_received_trajectory": [
      0,
      0,
      10,
      3,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      8,
      13,
      2,
      20,
      5,
      6,
      1,
      0,
      0,
      1
    ],
    "others_mean_trajectory": [
      6.666666666666667,
      1.0,
      6.333333333333333,
      0.6666666666666666,
      7.0,
      2.3333333333333335,
      2.3333333333333335,
      0.6666666666666666,
      0.0,
      0.3333333333333333
    ],
    "mean_contribution": 4.7,
    "mean_punishment_sent": 0.9,
    "mean_punishment_received": 1.3,
    "mean_total_voluntary_spend": 5.6,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 9,
    "antisocial_ratio": 0.0,
    "group_id": "5903"
  },
  "5911": {
    "params": {},
    "params_list": [],
    "actual": [
      20,
      3,
      19,
      2,
      18,
      7,
      5,
      0,
      0,
      1
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Athens",
    "session": "Athens_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "mixed",
    "contribution_trajectory": [
      20,
      3,
      19,
      2,
      18,
      7,
      5,
      0,
      0,
      1
    ],
    "punishment_sent_trajectory": [
      0,
      0,
      1,
      12,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "punishment_received_trajectory": [
      0,
      1,
      9,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      20,
      3,
      20,
      14,
      18,
      7,
      5,
      0,
      0,
      1
    ],
    "others_mean_trajectory": [
      2.6666666666666665,
      3.3333333333333335,
      0.6666666666666666,
      5.0,
      2.3333333333333335,
      2.0,
      1.0,
      0.6666666666666666,
      0.0,
      0.3333333333333333
    ],
    "mean_contribution": 7.5,
    "mean_punishment_sent": 1.3,
    "mean_punishment_received": 1.0,
    "mean_total_voluntary_spend": 8.8,
    "antisocial_punishment_total": 3,
    "prosocial_punishment_total": 10,
    "antisocial_ratio": 0.23076923076923078,
    "group_id": "5903"
  },
  "5912": {
    "params": {},
    "params_list": [],
    "actual": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Athens",
    "session": "Athens_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "antisocial",
    "behavioral_profile": "antisocial-controller",
    "contribution_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "punishment_sent_trajectory": [
      0,
      0,
      27,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "punishment_received_trajectory": [
      0,
      1,
      0,
      7,
      1,
      0,
      2,
      0,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      0,
      0,
      27,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "others_mean_trajectory": [
      9.333333333333334,
      4.333333333333333,
      7.0,
      5.666666666666667,
      8.333333333333334,
      4.333333333333333,
      2.6666666666666665,
      0.6666666666666666,
      0.0,
      0.6666666666666666
    ],
    "mean_contribution": 0.0,
    "mean_punishment_sent": 2.7,
    "mean_punishment_received": 1.1,
    "mean_total_voluntary_spend": 2.7,
    "antisocial_punishment_total": 27,
    "prosocial_punishment_total": 0,
    "antisocial_ratio": 1.0,
    "group_id": "5903"
  },
  "5913": {
    "params": {},
    "params_list": [],
    "actual": [
      3,
      5,
      3,
      0,
      3,
      6,
      5,
      4,
      6,
      20
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Athens",
    "session": "Athens_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "antisocial",
    "behavioral_profile": "mixed",
    "contribution_trajectory": [
      3,
      5,
      3,
      0,
      3,
      6,
      5,
      4,
      6,
      20
    ],
    "punishment_sent_trajectory": [
      4,
      3,
      15,
      0,
      0,
      0,
      24,
      0,
      3,
      0
    ],
    "punishment_received_trajectory": [
      2,
      2,
      3,
      3,
      2,
      4,
      1,
      2,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      7,
      8,
      18,
      0,
      3,
      6,
      29,
      4,
      9,
      20
    ],
    "others_mean_trajectory": [
      5.333333333333333,
      7.666666666666667,
      10.333333333333334,
      8.333333333333334,
      8.666666666666666,
      8.333333333333334,
      7.666666666666667,
      8.333333333333334,
      7.0,
      10.0
    ],
    "mean_contribution": 5.5,
    "mean_punishment_sent": 4.9,
    "mean_punishment_received": 1.9,
    "mean_total_voluntary_spend": 10.4,
    "antisocial_punishment_total": 45,
    "prosocial_punishment_total": 4,
    "antisocial_ratio": 0.9183673469387755,
    "group_id": "5904"
  },
  "5914": {
    "params": {},
    "params_list": [],
    "actual": [
      9,
      6,
      12,
      8,
      10,
      10,
      9,
      9,
      10,
      14
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Athens",
    "session": "Athens_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "mixed",
    "contribution_trajectory": [
      9,
      6,
      12,
      8,
      10,
      10,
      9,
      9,
      10,
      14
    ],
    "punishment_sent_trajectory": [
      3,
      1,
      2,
      3,
      2,
      2,
      2,
      2,
      1,
      2
    ],
    "punishment_received_trajectory": [
      0,
      4,
      6,
      3,
      2,
      0,
      10,
      0,
      1,
      0
    ],
    "total_voluntary_spend_trajectory": [
      12,
      7,
      14,
      11,
      12,
      12,
      11,
      11,
      11,
      16
    ],
    "others_mean_trajectory": [
      3.3333333333333335,
      7.333333333333333,
      7.333333333333333,
      5.666666666666667,
      6.333333333333333,
      7.0,
      6.333333333333333,
      6.666666666666667,
      5.666666666666667,
      12.0
    ],
    "mean_contribution": 9.7,
    "mean_punishment_sent": 2.0,
    "mean_punishment_received": 2.6,
    "mean_total_voluntary_spend": 11.7,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 20,
    "antisocial_ratio": 0.0,
    "group_id": "5904"
  },
  "5915": {
    "params": {},
    "params_list": [],
    "actual": [
      0,
      10,
      12,
      11,
      10,
      9,
      8,
      8,
      5,
      10
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Athens",
    "session": "Athens_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "mixed",
    "contribution_trajectory": [
      0,
      10,
      12,
      11,
      10,
      9,
      8,
      8,
      5,
      10
    ],
    "punishment_sent_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "punishment_received_trajectory": [
      7,
      2,
      6,
      2,
      2,
      2,
      11,
      0,
      2,
      0
    ],
    "total_voluntary_spend_trajectory": [
      0,
      10,
      12,
      11,
      10,
      9,
      8,
      8,
      5,
      10
    ],
    "others_mean_trajectory": [
      6.333333333333333,
      6.0,
      7.333333333333333,
      4.666666666666667,
      6.333333333333333,
      7.333333333333333,
      6.666666666666667,
      7.0,
      7.333333333333333,
      13.333333333333334
    ],
    "mean_contribution": 8.3,
    "mean_punishment_sent": 0.0,
    "mean_punishment_received": 3.4,
    "mean_total_voluntary_spend": 8.3,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 0,
    "antisocial_ratio": 0.0,
    "group_id": "5904"
  },
  "5916": {
    "params": {},
    "params_list": [],
    "actual": [
      7,
      7,
      7,
      6,
      6,
      6,
      6,
      8,
      6,
      6
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Athens",
    "session": "Athens_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "antisocial",
    "behavioral_profile": "mixed",
    "contribution_trajectory": [
      7,
      7,
      7,
      6,
      6,
      6,
      6,
      8,
      6,
      6
    ],
    "punishment_sent_trajectory": [
      3,
      5,
      3,
      5,
      4,
      5,
      5,
      0,
      0,
      0
    ],
    "punishment_received_trajectory": [
      1,
      1,
      5,
      0,
      0,
      1,
      9,
      0,
      1,
      2
    ],
    "total_voluntary_spend_trajectory": [
      10,
      12,
      10,
      11,
      10,
      11,
      11,
      8,
      6,
      6
    ],
    "others_mean_trajectory": [
      4.0,
      7.0,
      9.0,
      6.333333333333333,
      7.666666666666667,
      8.333333333333334,
      7.333333333333333,
      7.0,
      7.0,
      14.666666666666666
    ],
    "mean_contribution": 6.5,
    "mean_punishment_sent": 3.0,
    "mean_punishment_received": 2.0,
    "mean_total_voluntary_spend": 9.5,
    "antisocial_punishment_total": 22,
    "prosocial_punishment_total": 8,
    "antisocial_ratio": 0.7333333333333333,
    "group_id": "5904"
  },
  "2301": {
    "params": {},
    "params_list": [],
    "actual": [
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Boston",
    "session": "Boston_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperative-enforcer",
    "contribution_trajectory": [
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "punishment_sent_trajectory": [
      10,
      20,
      7,
      12,
      7,
      4,
      3,
      0,
      0,
      0
    ],
    "punishment_received_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      30,
      40,
      27,
      32,
      27,
      24,
      23,
      20,
      20,
      20
    ],
    "others_mean_trajectory": [
      8.333333333333334,
      6.666666666666667,
      11.666666666666666,
      13.333333333333334,
      15.0,
      16.666666666666668,
      18.333333333333332,
      20.0,
      20.0,
      20.0
    ],
    "mean_contribution": 20.0,
    "mean_punishment_sent": 6.3,
    "mean_punishment_received": 0.0,
    "mean_total_voluntary_spend": 26.3,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 63,
    "antisocial_ratio": 0.0,
    "group_id": "2301"
  },
  "2302": {
    "params": {},
    "params_list": [],
    "actual": [
      15,
      10,
      10,
      15,
      15,
      20,
      20,
      20,
      20,
      20
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Boston",
    "session": "Boston_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperative-enforcer",
    "contribution_trajectory": [
      15,
      10,
      10,
      15,
      15,
      20,
      20,
      20,
      20,
      20
    ],
    "punishment_sent_trajectory": [
      2,
      3,
      0,
      2,
      2,
      2,
      1,
      0,
      0,
      0
    ],
    "punishment_received_trajectory": [
      0,
      5,
      2,
      2,
      2,
      0,
      0,
      0,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      17,
      13,
      10,
      17,
      17,
      22,
      21,
      20,
      20,
      20
    ],
    "others_mean_trajectory": [
      10.0,
      10.0,
      15.0,
      15.0,
      16.666666666666668,
      16.666666666666668,
      18.333333333333332,
      20.0,
      20.0,
      20.0
    ],
    "mean_contribution": 16.5,
    "mean_punishment_sent": 1.2,
    "mean_punishment_received": 1.1,
    "mean_total_voluntary_spend": 17.7,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 12,
    "antisocial_ratio": 0.0,
    "group_id": "2301"
  },
  "2303": {
    "params": {},
    "params_list": [],
    "actual": [
      0,
      10,
      5,
      5,
      20,
      15,
      15,
      20,
      20,
      20
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Boston",
    "session": "Boston_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperator",
    "contribution_trajectory": [
      0,
      10,
      5,
      5,
      20,
      15,
      15,
      20,
      20,
      20
    ],
    "punishment_sent_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "punishment_received_trajectory": [
      12,
      5,
      5,
      12,
      0,
      3,
      4,
      0,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      0,
      10,
      5,
      5,
      20,
      15,
      15,
      20,
      20,
      20
    ],
    "others_mean_trajectory": [
      15.0,
      10.0,
      16.666666666666668,
      18.333333333333332,
      15.0,
      18.333333333333332,
      20.0,
      20.0,
      20.0,
      20.0
    ],
    "mean_contribution": 13.0,
    "mean_punishment_sent": 0.0,
    "mean_punishment_received": 4.1,
    "mean_total_voluntary_spend": 13.0,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 0,
    "antisocial_ratio": 0.0,
    "group_id": "2301"
  },
  "2304": {
    "params": {},
    "params_list": [],
    "actual": [
      10,
      0,
      20,
      20,
      10,
      15,
      20,
      20,
      20,
      20
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Boston",
    "session": "Boston_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperator",
    "contribution_trajectory": [
      10,
      0,
      20,
      20,
      10,
      15,
      20,
      20,
      20,
      20
    ],
    "punishment_sent_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "punishment_received_trajectory": [
      0,
      13,
      0,
      0,
      7,
      3,
      0,
      0,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      10,
      0,
      20,
      20,
      10,
      15,
      20,
      20,
      20,
      20
    ],
    "others_mean_trajectory": [
      11.666666666666666,
      13.333333333333334,
      11.666666666666666,
      13.333333333333334,
      18.333333333333332,
      18.333333333333332,
      18.333333333333332,
      20.0,
      20.0,
      20.0
    ],
    "mean_contribution": 15.5,
    "mean_punishment_sent": 0.0,
    "mean_punishment_received": 2.3,
    "mean_total_voluntary_spend": 15.5,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 0,
    "antisocial_ratio": 0.0,
    "group_id": "2301"
  },
  "2305": {
    "params": {},
    "params_list": [],
    "actual": [
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      0
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Boston",
    "session": "Boston_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperative-enforcer",
    "contribution_trajectory": [
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      0
    ],
    "punishment_sent_trajectory": [
      4,
      3,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "punishment_received_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      9
    ],
    "total_voluntary_spend_trajectory": [
      24,
      23,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      0
    ],
    "others_mean_trajectory": [
      9.333333333333334,
      15.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      13.333333333333334
    ],
    "mean_contribution": 18.0,
    "mean_punishment_sent": 0.7,
    "mean_punishment_received": 0.9,
    "mean_total_voluntary_spend": 18.7,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 7,
    "antisocial_ratio": 0.0,
    "group_id": "2302"
  },
  "2306": {
    "params": {},
    "params_list": [],
    "actual": [
      8,
      15,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Boston",
    "session": "Boston_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperative-enforcer",
    "contribution_trajectory": [
      8,
      15,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "punishment_sent_trajectory": [
      2,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      10
    ],
    "punishment_received_trajectory": [
      1,
      3,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      10,
      15,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      30
    ],
    "others_mean_trajectory": [
      13.333333333333334,
      16.666666666666668,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      6.666666666666667
    ],
    "mean_contribution": 18.3,
    "mean_punishment_sent": 1.2,
    "mean_punishment_received": 0.4,
    "mean_total_voluntary_spend": 19.5,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 12,
    "antisocial_ratio": 0.0,
    "group_id": "2302"
  },
  "2307": {
    "params": {},
    "params_list": [],
    "actual": [
      20,
      10,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Boston",
    "session": "Boston_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperative-enforcer",
    "contribution_trajectory": [
      20,
      10,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "punishment_sent_trajectory": [
      5,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      8
    ],
    "punishment_received_trajectory": [
      0,
      3,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      25,
      10,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      28
    ],
    "others_mean_trajectory": [
      9.333333333333334,
      18.333333333333332,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      6.666666666666667
    ],
    "mean_contribution": 19.0,
    "mean_punishment_sent": 1.3,
    "mean_punishment_received": 0.3,
    "mean_total_voluntary_spend": 20.3,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 13,
    "antisocial_ratio": 0.0,
    "group_id": "2302"
  },
  "2308": {
    "params": {},
    "params_list": [],
    "actual": [
      0,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      0
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Boston",
    "session": "Boston_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperator",
    "contribution_trajectory": [
      0,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      0
    ],
    "punishment_sent_trajectory": [
      0,
      3,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "punishment_received_trajectory": [
      10,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      9
    ],
    "total_voluntary_spend_trajectory": [
      0,
      23,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      0
    ],
    "others_mean_trajectory": [
      16.0,
      15.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      13.333333333333334
    ],
    "mean_contribution": 16.0,
    "mean_punishment_sent": 0.3,
    "mean_punishment_received": 1.9,
    "mean_total_voluntary_spend": 16.3,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 3,
    "antisocial_ratio": 0.0,
    "group_id": "2302"
  },
  "2309": {
    "params": {},
    "params_list": [],
    "actual": [
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Boston",
    "session": "Boston_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperator",
    "contribution_trajectory": [
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "punishment_sent_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "punishment_received_trajectory": [
      5,
      0,
      0,
      10,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "others_mean_trajectory": [
      10.333333333333334,
      13.333333333333334,
      14.0,
      20.0,
      14.0,
      13.333333333333334,
      14.666666666666666,
      8.666666666666666,
      14.0,
      8.666666666666666
    ],
    "mean_contribution": 20.0,
    "mean_punishment_sent": 0.0,
    "mean_punishment_received": 1.5,
    "mean_total_voluntary_spend": 20.0,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 0,
    "antisocial_ratio": 0.0,
    "group_id": "2303"
  },
  "2310": {
    "params": {},
    "params_list": [],
    "actual": [
      5,
      20,
      20,
      20,
      20,
      20,
      20,
      0,
      20,
      0
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Boston",
    "session": "Boston_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperative-enforcer",
    "contribution_trajectory": [
      5,
      20,
      20,
      20,
      20,
      20,
      20,
      0,
      20,
      0
    ],
    "punishment_sent_trajectory": [
      1,
      5,
      5,
      0,
      5,
      5,
      5,
      4,
      5,
      2
    ],
    "punishment_received_trajectory": [
      6,
      0,
      0,
      10,
      0,
      0,
      0,
      4,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      6,
      25,
      25,
      20,
      25,
      25,
      25,
      4,
      25,
      2
    ],
    "others_mean_trajectory": [
      15.333333333333334,
      13.333333333333334,
      14.0,
      20.0,
      14.0,
      13.333333333333334,
      14.666666666666666,
      15.333333333333334,
      14.0,
      15.333333333333334
    ],
    "mean_contribution": 14.5,
    "mean_punishment_sent": 3.7,
    "mean_punishment_received": 2.0,
    "mean_total_voluntary_spend": 18.2,
    "antisocial_punishment_total": 7,
    "prosocial_punishment_total": 30,
    "antisocial_ratio": 0.1891891891891892,
    "group_id": "2303"
  },
  "2311": {
    "params": {},
    "params_list": [],
    "actual": [
      6,
      0,
      2,
      20,
      2,
      0,
      4,
      6,
      2,
      6
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Boston",
    "session": "Boston_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "antisocial",
    "behavioral_profile": "antisocial-controller",
    "contribution_trajectory": [
      6,
      0,
      2,
      20,
      2,
      0,
      4,
      6,
      2,
      6
    ],
    "punishment_sent_trajectory": [
      15,
      0,
      0,
      30,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "punishment_received_trajectory": [
      1,
      6,
      7,
      0,
      10,
      10,
      9,
      5,
      5,
      2
    ],
    "total_voluntary_spend_trajectory": [
      21,
      0,
      2,
      50,
      2,
      0,
      4,
      6,
      2,
      6
    ],
    "others_mean_trajectory": [
      15.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      13.333333333333334,
      20.0,
      13.333333333333334
    ],
    "mean_contribution": 4.8,
    "mean_punishment_sent": 4.5,
    "mean_punishment_received": 5.5,
    "mean_total_voluntary_spend": 9.3,
    "antisocial_punishment_total": 40,
    "prosocial_punishment_total": 5,
    "antisocial_ratio": 0.8888888888888888,
    "group_id": "2303"
  },
  "2312": {
    "params": {},
    "params_list": [],
    "actual": [
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Boston",
    "session": "Boston_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperative-enforcer",
    "contribution_trajectory": [
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "punishment_sent_trajectory": [
      2,
      1,
      2,
      0,
      5,
      5,
      4,
      5,
      0,
      0
    ],
    "punishment_received_trajectory": [
      6,
      0,
      0,
      10,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      22,
      21,
      22,
      20,
      25,
      25,
      24,
      25,
      20,
      20
    ],
    "others_mean_trajectory": [
      10.333333333333334,
      13.333333333333334,
      14.0,
      20.0,
      14.0,
      13.333333333333334,
      14.666666666666666,
      8.666666666666666,
      14.0,
      8.666666666666666
    ],
    "mean_contribution": 20.0,
    "mean_punishment_sent": 2.4,
    "mean_punishment_received": 1.6,
    "mean_total_voluntary_spend": 22.4,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 24,
    "antisocial_ratio": 0.0,
    "group_id": "2303"
  },
  "2313": {
    "params": {},
    "params_list": [],
    "actual": [
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Boston",
    "session": "Boston_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperator",
    "contribution_trajectory": [
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "punishment_sent_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "punishment_received_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "others_mean_trajectory": [
      18.333333333333332,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0
    ],
    "mean_contribution": 20.0,
    "mean_punishment_sent": 0.0,
    "mean_punishment_received": 0.0,
    "mean_total_voluntary_spend": 20.0,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 0,
    "antisocial_ratio": 0.0,
    "group_id": "2304"
  },
  "2314": {
    "params": {},
    "params_list": [],
    "actual": [
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Boston",
    "session": "Boston_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperator",
    "contribution_trajectory": [
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "punishment_sent_trajectory": [
      1,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "punishment_received_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      21,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "others_mean_trajectory": [
      18.333333333333332,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0
    ],
    "mean_contribution": 20.0,
    "mean_punishment_sent": 0.1,
    "mean_punishment_received": 0.0,
    "mean_total_voluntary_spend": 20.1,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 1,
    "antisocial_ratio": 0.0,
    "group_id": "2304"
  },
  "2315": {
    "params": {},
    "params_list": [],
    "actual": [
      15,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Boston",
    "session": "Boston_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperator",
    "contribution_trajectory": [
      15,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "punishment_sent_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "punishment_received_trajectory": [
      1,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      15,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "others_mean_trajectory": [
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0
    ],
    "mean_contribution": 19.5,
    "mean_punishment_sent": 0.0,
    "mean_punishment_received": 0.1,
    "mean_total_voluntary_spend": 19.5,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 0,
    "antisocial_ratio": 0.0,
    "group_id": "2304"
  },
  "2316": {
    "params": {},
    "params_list": [],
    "actual": [
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Boston",
    "session": "Boston_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperator",
    "contribution_trajectory": [
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "punishment_sent_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "punishment_received_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "others_mean_trajectory": [
      18.333333333333332,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0
    ],
    "mean_contribution": 20.0,
    "mean_punishment_sent": 0.0,
    "mean_punishment_received": 0.0,
    "mean_total_voluntary_spend": 20.0,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 0,
    "antisocial_ratio": 0.0,
    "group_id": "2304"
  },
  "2317": {
    "params": {},
    "params_list": [],
    "actual": [
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Boston",
    "session": "Boston_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperative-enforcer",
    "contribution_trajectory": [
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "punishment_sent_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      3,
      1,
      4
    ],
    "punishment_received_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      23,
      21,
      24
    ],
    "others_mean_trajectory": [
      16.0,
      18.333333333333332,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      11.666666666666666,
      16.666666666666668,
      11.666666666666666
    ],
    "mean_contribution": 20.0,
    "mean_punishment_sent": 0.8,
    "mean_punishment_received": 0.0,
    "mean_total_voluntary_spend": 20.8,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 8,
    "antisocial_ratio": 0.0,
    "group_id": "2305"
  },
  "2318": {
    "params": {},
    "params_list": [],
    "actual": [
      10,
      15,
      20,
      20,
      20,
      20,
      20,
      15,
      10,
      0
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Boston",
    "session": "Boston_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperative-enforcer",
    "contribution_trajectory": [
      10,
      15,
      20,
      20,
      20,
      20,
      20,
      15,
      10,
      0
    ],
    "punishment_sent_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      10,
      0,
      0
    ],
    "punishment_received_trajectory": [
      4,
      1,
      0,
      0,
      0,
      0,
      0,
      0,
      1,
      4
    ],
    "total_voluntary_spend_trajectory": [
      10,
      15,
      20,
      20,
      20,
      20,
      20,
      25,
      10,
      0
    ],
    "others_mean_trajectory": [
      19.333333333333332,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      13.333333333333334,
      20.0,
      18.333333333333332
    ],
    "mean_contribution": 15.0,
    "mean_punishment_sent": 1.0,
    "mean_punishment_received": 1.0,
    "mean_total_voluntary_spend": 16.0,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 10,
    "antisocial_ratio": 0.0,
    "group_id": "2305"
  },
  "2319": {
    "params": {},
    "params_list": [],
    "actual": [
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      15
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Boston",
    "session": "Boston_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperator",
    "contribution_trajectory": [
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      15
    ],
    "punishment_sent_trajectory": [
      4,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "punishment_received_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      24,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      15
    ],
    "others_mean_trajectory": [
      16.0,
      18.333333333333332,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      11.666666666666666,
      16.666666666666668,
      13.333333333333334
    ],
    "mean_contribution": 19.5,
    "mean_punishment_sent": 0.4,
    "mean_punishment_received": 0.0,
    "mean_total_voluntary_spend": 19.9,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 4,
    "antisocial_ratio": 0.0,
    "group_id": "2305"
  },
  "2320": {
    "params": {},
    "params_list": [],
    "actual": [
      18,
      20,
      20,
      20,
      20,
      20,
      20,
      0,
      20,
      20
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Boston",
    "session": "Boston_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperator",
    "contribution_trajectory": [
      18,
      20,
      20,
      20,
      20,
      20,
      20,
      0,
      20,
      20
    ],
    "punishment_sent_trajectory": [
      1,
      1,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "punishment_received_trajectory": [
      1,
      0,
      0,
      0,
      0,
      0,
      0,
      13,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      19,
      21,
      20,
      20,
      20,
      20,
      20,
      0,
      20,
      20
    ],
    "others_mean_trajectory": [
      16.666666666666668,
      18.333333333333332,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      18.333333333333332,
      16.666666666666668,
      11.666666666666666
    ],
    "mean_contribution": 17.8,
    "mean_punishment_sent": 0.2,
    "mean_punishment_received": 1.4,
    "mean_total_voluntary_spend": 18.0,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 2,
    "antisocial_ratio": 0.0,
    "group_id": "2305"
  },
  "2321": {
    "params": {},
    "params_list": [],
    "actual": [
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Boston",
    "session": "Boston_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperator",
    "contribution_trajectory": [
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "punishment_sent_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "punishment_received_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "others_mean_trajectory": [
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0
    ],
    "mean_contribution": 20.0,
    "mean_punishment_sent": 0.0,
    "mean_punishment_received": 0.0,
    "mean_total_voluntary_spend": 20.0,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 0,
    "antisocial_ratio": 0.0,
    "group_id": "2306"
  },
  "2322": {
    "params": {},
    "params_list": [],
    "actual": [
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Boston",
    "session": "Boston_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperator",
    "contribution_trajectory": [
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "punishment_sent_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "punishment_received_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "others_mean_trajectory": [
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0
    ],
    "mean_contribution": 20.0,
    "mean_punishment_sent": 0.0,
    "mean_punishment_received": 0.0,
    "mean_total_voluntary_spend": 20.0,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 0,
    "antisocial_ratio": 0.0,
    "group_id": "2306"
  },
  "2323": {
    "params": {},
    "params_list": [],
    "actual": [
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Boston",
    "session": "Boston_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperator",
    "contribution_trajectory": [
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "punishment_sent_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "punishment_received_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "others_mean_trajectory": [
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0
    ],
    "mean_contribution": 20.0,
    "mean_punishment_sent": 0.0,
    "mean_punishment_received": 0.0,
    "mean_total_voluntary_spend": 20.0,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 0,
    "antisocial_ratio": 0.0,
    "group_id": "2306"
  },
  "2324": {
    "params": {},
    "params_list": [],
    "actual": [
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Boston",
    "session": "Boston_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperator",
    "contribution_trajectory": [
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "punishment_sent_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "punishment_received_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "others_mean_trajectory": [
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0
    ],
    "mean_contribution": 20.0,
    "mean_punishment_sent": 0.0,
    "mean_punishment_received": 0.0,
    "mean_total_voluntary_spend": 20.0,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 0,
    "antisocial_ratio": 0.0,
    "group_id": "2306"
  },
  "4201": {
    "params": {},
    "params_list": [],
    "actual": [
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Istanbul",
    "session": "Istanbul_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperative-enforcer",
    "contribution_trajectory": [
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "punishment_sent_trajectory": [
      0,
      5,
      3,
      10,
      3,
      10,
      0,
      10,
      0,
      10
    ],
    "punishment_received_trajectory": [
      3,
      0,
      3,
      0,
      0,
      0,
      0,
      0,
      3,
      3
    ],
    "total_voluntary_spend_trajectory": [
      20,
      25,
      23,
      30,
      23,
      30,
      20,
      30,
      20,
      30
    ],
    "others_mean_trajectory": [
      15.0,
      16.0,
      18.333333333333332,
      18.666666666666668,
      17.0,
      17.333333333333332,
      18.333333333333332,
      18.333333333333332,
      16.666666666666668,
      15.0
    ],
    "mean_contribution": 20.0,
    "mean_punishment_sent": 5.1,
    "mean_punishment_received": 1.2,
    "mean_total_voluntary_spend": 25.1,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 51,
    "antisocial_ratio": 0.0,
    "group_id": "4201"
  },
  "4202": {
    "params": {},
    "params_list": [],
    "actual": [
      13,
      13,
      15,
      16,
      15,
      14,
      15,
      15,
      15,
      15
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Istanbul",
    "session": "Istanbul_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "antisocial",
    "behavioral_profile": "cooperative-enforcer",
    "contribution_trajectory": [
      13,
      13,
      15,
      16,
      15,
      14,
      15,
      15,
      15,
      15
    ],
    "punishment_sent_trajectory": [
      3,
      0,
      3,
      2,
      0,
      2,
      7,
      5,
      3,
      3
    ],
    "punishment_received_trajectory": [
      0,
      4,
      4,
      12,
      2,
      11,
      1,
      12,
      3,
      1
    ],
    "total_voluntary_spend_trajectory": [
      16,
      13,
      18,
      18,
      15,
      16,
      22,
      20,
      18,
      18
    ],
    "others_mean_trajectory": [
      17.333333333333332,
      18.333333333333332,
      20.0,
      20.0,
      18.666666666666668,
      19.333333333333332,
      20.0,
      20.0,
      18.333333333333332,
      16.666666666666668
    ],
    "mean_contribution": 14.6,
    "mean_punishment_sent": 2.8,
    "mean_punishment_received": 5.0,
    "mean_total_voluntary_spend": 17.4,
    "antisocial_punishment_total": 28,
    "prosocial_punishment_total": 0,
    "antisocial_ratio": 1.0,
    "group_id": "4201"
  },
  "4203": {
    "params": {},
    "params_list": [],
    "actual": [
      17,
      20,
      20,
      20,
      20,
      18,
      20,
      20,
      20,
      20
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Istanbul",
    "session": "Istanbul_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperative-enforcer",
    "contribution_trajectory": [
      17,
      20,
      20,
      20,
      20,
      18,
      20,
      20,
      20,
      20
    ],
    "punishment_sent_trajectory": [
      0,
      1,
      0,
      0,
      0,
      1,
      1,
      2,
      5,
      3
    ],
    "punishment_received_trajectory": [
      0,
      0,
      0,
      2,
      0,
      0,
      7,
      5,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      17,
      21,
      20,
      20,
      20,
      19,
      21,
      22,
      25,
      23
    ],
    "others_mean_trajectory": [
      16.0,
      16.0,
      18.333333333333332,
      18.666666666666668,
      17.0,
      18.0,
      18.333333333333332,
      18.333333333333332,
      16.666666666666668,
      15.0
    ],
    "mean_contribution": 19.5,
    "mean_punishment_sent": 1.3,
    "mean_punishment_received": 1.4,
    "mean_total_voluntary_spend": 20.8,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 13,
    "antisocial_ratio": 0.0,
    "group_id": "4201"
  },
  "4204": {
    "params": {},
    "params_list": [],
    "actual": [
      15,
      15,
      20,
      20,
      16,
      20,
      20,
      20,
      15,
      10
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Istanbul",
    "session": "Istanbul_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperative-enforcer",
    "contribution_trajectory": [
      15,
      15,
      20,
      20,
      16,
      20,
      20,
      20,
      15,
      10
    ],
    "punishment_sent_trajectory": [
      0,
      1,
      1,
      2,
      1,
      0,
      0,
      0,
      0,
      0
    ],
    "punishment_received_trajectory": [
      0,
      3,
      0,
      0,
      2,
      2,
      0,
      0,
      2,
      12
    ],
    "total_voluntary_spend_trajectory": [
      15,
      16,
      21,
      22,
      17,
      20,
      20,
      20,
      15,
      10
    ],
    "others_mean_trajectory": [
      16.666666666666668,
      17.666666666666668,
      18.333333333333332,
      18.666666666666668,
      18.333333333333332,
      17.333333333333332,
      18.333333333333332,
      18.333333333333332,
      18.333333333333332,
      18.333333333333332
    ],
    "mean_contribution": 17.1,
    "mean_punishment_sent": 0.5,
    "mean_punishment_received": 2.1,
    "mean_total_voluntary_spend": 17.6,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 5,
    "antisocial_ratio": 0.0,
    "group_id": "4201"
  },
  "4205": {
    "params": {},
    "params_list": [],
    "actual": [
      16,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Istanbul",
    "session": "Istanbul_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperator",
    "contribution_trajectory": [
      16,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "punishment_sent_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "punishment_received_trajectory": [
      3,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      8
    ],
    "total_voluntary_spend_trajectory": [
      16,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "others_mean_trajectory": [
      16.666666666666668,
      18.666666666666668,
      20.0,
      18.666666666666668,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0
    ],
    "mean_contribution": 19.6,
    "mean_punishment_sent": 0.0,
    "mean_punishment_received": 1.1,
    "mean_total_voluntary_spend": 19.6,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 0,
    "antisocial_ratio": 0.0,
    "group_id": "4202"
  },
  "4206": {
    "params": {},
    "params_list": [],
    "actual": [
      10,
      16,
      20,
      16,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Istanbul",
    "session": "Istanbul_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "antisocial",
    "behavioral_profile": "cooperator",
    "contribution_trajectory": [
      10,
      16,
      20,
      16,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "punishment_sent_trajectory": [
      0,
      1,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "punishment_received_trajectory": [
      3,
      2,
      0,
      4,
      0,
      0,
      0,
      0,
      0,
      9
    ],
    "total_voluntary_spend_trajectory": [
      10,
      17,
      20,
      16,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "others_mean_trajectory": [
      18.666666666666668,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0
    ],
    "mean_contribution": 18.2,
    "mean_punishment_sent": 0.1,
    "mean_punishment_received": 1.8,
    "mean_total_voluntary_spend": 18.3,
    "antisocial_punishment_total": 1,
    "prosocial_punishment_total": 0,
    "antisocial_ratio": 1.0,
    "group_id": "4202"
  },
  "4207": {
    "params": {},
    "params_list": [],
    "actual": [
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Istanbul",
    "session": "Istanbul_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperator",
    "contribution_trajectory": [
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "punishment_sent_trajectory": [
      1,
      1,
      0,
      1,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "punishment_received_trajectory": [
      0,
      1,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      9
    ],
    "total_voluntary_spend_trajectory": [
      21,
      21,
      20,
      21,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "others_mean_trajectory": [
      15.333333333333334,
      18.666666666666668,
      20.0,
      18.666666666666668,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0
    ],
    "mean_contribution": 20.0,
    "mean_punishment_sent": 0.3,
    "mean_punishment_received": 1.0,
    "mean_total_voluntary_spend": 20.3,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 3,
    "antisocial_ratio": 0.0,
    "group_id": "4202"
  },
  "4208": {
    "params": {},
    "params_list": [],
    "actual": [
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Istanbul",
    "session": "Istanbul_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "antisocial",
    "behavioral_profile": "cooperative-enforcer",
    "contribution_trajectory": [
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20,
      20
    ],
    "punishment_sent_trajectory": [
      5,
      1,
      0,
      3,
      0,
      0,
      0,
      0,
      0,
      26
    ],
    "punishment_received_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      25,
      21,
      20,
      23,
      20,
      20,
      20,
      20,
      20,
      46
    ],
    "others_mean_trajectory": [
      15.333333333333334,
      18.666666666666668,
      20.0,
      18.666666666666668,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0,
      20.0
    ],
    "mean_contribution": 20.0,
    "mean_punishment_sent": 3.5,
    "mean_punishment_received": 0.0,
    "mean_total_voluntary_spend": 23.5,
    "antisocial_punishment_total": 26,
    "prosocial_punishment_total": 9,
    "antisocial_ratio": 0.7428571428571429,
    "group_id": "4202"
  },
  "4209": {
    "params": {},
    "params_list": [],
    "actual": [
      12,
      10,
      10,
      0,
      1,
      8,
      0,
      5,
      7,
      8
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Istanbul",
    "session": "Istanbul_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "mixed",
    "contribution_trajectory": [
      12,
      10,
      10,
      0,
      1,
      8,
      0,
      5,
      7,
      8
    ],
    "punishment_sent_trajectory": [
      8,
      9,
      11,
      6,
      0,
      0,
      2,
      0,
      0,
      0
    ],
    "punishment_received_trajectory": [
      4,
      5,
      10,
      12,
      6,
      1,
      4,
      0,
      5,
      0
    ],
    "total_voluntary_spend_trajectory": [
      20,
      19,
      21,
      6,
      1,
      8,
      2,
      5,
      7,
      8
    ],
    "others_mean_trajectory": [
      5.0,
      6.333333333333333,
      6.666666666666667,
      5.0,
      7.333333333333333,
      5.0,
      5.666666666666667,
      3.6666666666666665,
      2.3333333333333335,
      7.0
    ],
    "mean_contribution": 6.1,
    "mean_punishment_sent": 3.6,
    "mean_punishment_received": 4.7,
    "mean_total_voluntary_spend": 9.7,
    "antisocial_punishment_total": 8,
    "prosocial_punishment_total": 28,
    "antisocial_ratio": 0.2222222222222222,
    "group_id": "4203"
  },
  "4210": {
    "params": {},
    "params_list": [],
    "actual": [
      5,
      8,
      10,
      0,
      12,
      6,
      8,
      3,
      2,
      12
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Istanbul",
    "session": "Istanbul_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "antisocial",
    "behavioral_profile": "mixed",
    "contribution_trajectory": [
      5,
      8,
      10,
      0,
      12,
      6,
      8,
      3,
      2,
      12
    ],
    "punishment_sent_trajectory": [
      7,
      15,
      22,
      4,
      0,
      0,
      0,
      0,
      15,
      0
    ],
    "punishment_received_trajectory": [
      4,
      4,
      2,
      13,
      0,
      1,
      0,
      2,
      2,
      1
    ],
    "total_voluntary_spend_trajectory": [
      12,
      23,
      32,
      4,
      12,
      6,
      8,
      3,
      17,
      12
    ],
    "others_mean_trajectory": [
      7.333333333333333,
      7.0,
      6.666666666666667,
      5.0,
      3.6666666666666665,
      5.666666666666667,
      3.0,
      4.333333333333333,
      4.0,
      5.666666666666667
    ],
    "mean_contribution": 6.6,
    "mean_punishment_sent": 6.3,
    "mean_punishment_received": 2.9,
    "mean_total_voluntary_spend": 12.9,
    "antisocial_punishment_total": 37,
    "prosocial_punishment_total": 26,
    "antisocial_ratio": 0.5873015873015873,
    "group_id": "4203"
  },
  "4211": {
    "params": {},
    "params_list": [],
    "actual": [
      0,
      1,
      2,
      5,
      0,
      1,
      1,
      3,
      0,
      1
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Istanbul",
    "session": "Istanbul_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "antisocial",
    "behavioral_profile": "free-rider",
    "contribution_trajectory": [
      0,
      1,
      2,
      5,
      0,
      1,
      1,
      3,
      0,
      1
    ],
    "punishment_sent_trajectory": [
      0,
      0,
      1,
      0,
      0,
      1,
      0,
      0,
      0,
      1
    ],
    "punishment_received_trajectory": [
      11,
      17,
      24,
      11,
      7,
      4,
      6,
      2,
      9,
      5
    ],
    "total_voluntary_spend_trajectory": [
      0,
      1,
      3,
      5,
      0,
      2,
      1,
      3,
      0,
      2
    ],
    "others_mean_trajectory": [
      9.0,
      9.333333333333334,
      9.333333333333334,
      3.3333333333333335,
      7.666666666666667,
      7.333333333333333,
      5.333333333333333,
      4.333333333333333,
      4.666666666666667,
      9.333333333333334
    ],
    "mean_contribution": 1.4,
    "mean_punishment_sent": 0.3,
    "mean_punishment_received": 9.6,
    "mean_total_voluntary_spend": 1.7,
    "antisocial_punishment_total": 3,
    "prosocial_punishment_total": 0,
    "antisocial_ratio": 1.0,
    "group_id": "4203"
  },
  "4212": {
    "params": {},
    "params_list": [],
    "actual": [
      10,
      10,
      8,
      10,
      10,
      8,
      8,
      5,
      5,
      8
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Istanbul",
    "session": "Istanbul_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "mixed",
    "contribution_trajectory": [
      10,
      10,
      8,
      10,
      10,
      8,
      8,
      5,
      5,
      8
    ],
    "punishment_sent_trajectory": [
      6,
      7,
      10,
      26,
      13,
      5,
      8,
      4,
      6,
      5
    ],
    "punishment_received_trajectory": [
      2,
      5,
      8,
      0,
      0,
      0,
      0,
      0,
      5,
      0
    ],
    "total_voluntary_spend_trajectory": [
      16,
      17,
      18,
      36,
      23,
      13,
      16,
      9,
      11,
      13
    ],
    "others_mean_trajectory": [
      5.666666666666667,
      6.333333333333333,
      7.333333333333333,
      1.6666666666666667,
      4.333333333333333,
      5.0,
      3.0,
      3.6666666666666665,
      3.0,
      7.0
    ],
    "mean_contribution": 8.2,
    "mean_punishment_sent": 9.0,
    "mean_punishment_received": 2.0,
    "mean_total_voluntary_spend": 17.2,
    "antisocial_punishment_total": 4,
    "prosocial_punishment_total": 86,
    "antisocial_ratio": 0.044444444444444446,
    "group_id": "4203"
  },
  "4213": {
    "params": {},
    "params_list": [],
    "actual": [
      9,
      8,
      8,
      8,
      10,
      11,
      12,
      11,
      12,
      12
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Istanbul",
    "session": "Istanbul_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperative-enforcer",
    "contribution_trajectory": [
      9,
      8,
      8,
      8,
      10,
      11,
      12,
      11,
      12,
      12
    ],
    "punishment_sent_trajectory": [
      0,
      4,
      2,
      0,
      0,
      0,
      0,
      0,
      2,
      0
    ],
    "punishment_received_trajectory": [
      3,
      4,
      3,
      6,
      0,
      0,
      0,
      2,
      1,
      0
    ],
    "total_voluntary_spend_trajectory": [
      9,
      12,
      10,
      8,
      10,
      11,
      12,
      11,
      14,
      12
    ],
    "others_mean_trajectory": [
      11.666666666666666,
      10.666666666666666,
      9.666666666666666,
      11.666666666666666,
      10.666666666666666,
      11.333333333333334,
      8.666666666666666,
      11.333333333333334,
      8.0,
      4.0
    ],
    "mean_contribution": 10.1,
    "mean_punishment_sent": 0.8,
    "mean_punishment_received": 1.9,
    "mean_total_voluntary_spend": 10.9,
    "antisocial_punishment_total": 4,
    "prosocial_punishment_total": 4,
    "antisocial_ratio": 0.5,
    "group_id": "4204"
  },
  "4214": {
    "params": {},
    "params_list": [],
    "actual": [
      12,
      14,
      10,
      12,
      10,
      10,
      12,
      12,
      12,
      0
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Istanbul",
    "session": "Istanbul_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperative-enforcer",
    "contribution_trajectory": [
      12,
      14,
      10,
      12,
      10,
      10,
      12,
      12,
      12,
      0
    ],
    "punishment_sent_trajectory": [
      4,
      2,
      4,
      3,
      2,
      0,
      3,
      1,
      2,
      0
    ],
    "punishment_received_trajectory": [
      0,
      1,
      0,
      0,
      0,
      1,
      0,
      0,
      1,
      11
    ],
    "total_voluntary_spend_trajectory": [
      16,
      16,
      14,
      15,
      12,
      10,
      15,
      13,
      14,
      0
    ],
    "others_mean_trajectory": [
      10.666666666666666,
      8.666666666666666,
      9.0,
      10.333333333333334,
      10.666666666666666,
      11.666666666666666,
      8.666666666666666,
      11.0,
      8.0,
      8.0
    ],
    "mean_contribution": 10.4,
    "mean_punishment_sent": 2.1,
    "mean_punishment_received": 1.4,
    "mean_total_voluntary_spend": 12.5,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 21,
    "antisocial_ratio": 0.0,
    "group_id": "4204"
  },
  "4215": {
    "params": {},
    "params_list": [],
    "actual": [
      9,
      8,
      5,
      10,
      9,
      11,
      2,
      10,
      0,
      0
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Istanbul",
    "session": "Istanbul_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "antisocial",
    "behavioral_profile": "mixed",
    "contribution_trajectory": [
      9,
      8,
      5,
      10,
      9,
      11,
      2,
      10,
      0,
      0
    ],
    "punishment_sent_trajectory": [
      0,
      3,
      2,
      3,
      0,
      1,
      0,
      2,
      3,
      9
    ],
    "punishment_received_trajectory": [
      2,
      4,
      7,
      1,
      3,
      0,
      5,
      1,
      6,
      2
    ],
    "total_voluntary_spend_trajectory": [
      9,
      11,
      7,
      13,
      9,
      12,
      2,
      12,
      3,
      9
    ],
    "others_mean_trajectory": [
      11.666666666666666,
      10.666666666666666,
      10.666666666666666,
      11.0,
      11.0,
      11.333333333333334,
      12.0,
      11.666666666666666,
      12.0,
      8.0
    ],
    "mean_contribution": 6.4,
    "mean_punishment_sent": 2.3,
    "mean_punishment_received": 3.1,
    "mean_total_voluntary_spend": 8.7,
    "antisocial_punishment_total": 19,
    "prosocial_punishment_total": 4,
    "antisocial_ratio": 0.8260869565217391,
    "group_id": "4204"
  },
  "4216": {
    "params": {},
    "params_list": [],
    "actual": [
      14,
      10,
      14,
      13,
      13,
      13,
      12,
      12,
      12,
      12
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Istanbul",
    "session": "Istanbul_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "cooperative-enforcer",
    "contribution_trajectory": [
      14,
      10,
      14,
      13,
      13,
      13,
      12,
      12,
      12,
      12
    ],
    "punishment_sent_trajectory": [
      1,
      2,
      2,
      1,
      1,
      0,
      2,
      0,
      2,
      4
    ],
    "punishment_received_trajectory": [
      0,
      2,
      0,
      0,
      0,
      0,
      0,
      0,
      1,
      0
    ],
    "total_voluntary_spend_trajectory": [
      15,
      12,
      16,
      14,
      14,
      13,
      14,
      12,
      14,
      16
    ],
    "others_mean_trajectory": [
      10.0,
      10.0,
      7.666666666666667,
      10.0,
      9.666666666666666,
      10.666666666666666,
      8.666666666666666,
      11.0,
      8.0,
      4.0
    ],
    "mean_contribution": 12.5,
    "mean_punishment_sent": 1.5,
    "mean_punishment_received": 0.3,
    "mean_total_voluntary_spend": 14.0,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 15,
    "antisocial_ratio": 0.0,
    "group_id": "4204"
  },
  "4217": {
    "params": {},
    "params_list": [],
    "actual": [
      2,
      2,
      2,
      2,
      4,
      6,
      6,
      7,
      10,
      15
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Istanbul",
    "session": "Istanbul_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "mixed",
    "contribution_trajectory": [
      2,
      2,
      2,
      2,
      4,
      6,
      6,
      7,
      10,
      15
    ],
    "punishment_sent_trajectory": [
      7,
      2,
      0,
      0,
      0,
      1,
      2,
      2,
      1,
      2
    ],
    "punishment_received_trajectory": [
      0,
      0,
      0,
      1,
      2,
      1,
      1,
      4,
      2,
      6
    ],
    "total_voluntary_spend_trajectory": [
      9,
      4,
      2,
      2,
      4,
      7,
      8,
      9,
      11,
      17
    ],
    "others_mean_trajectory": [
      3.3333333333333335,
      2.6666666666666665,
      5.666666666666667,
      7.0,
      5.333333333333333,
      5.0,
      7.0,
      9.333333333333334,
      15.0,
      16.666666666666668
    ],
    "mean_contribution": 5.6,
    "mean_punishment_sent": 1.7,
    "mean_punishment_received": 1.7,
    "mean_total_voluntary_spend": 7.3,
    "antisocial_punishment_total": 6,
    "prosocial_punishment_total": 11,
    "antisocial_ratio": 0.35294117647058826,
    "group_id": "4205"
  },
  "4218": {
    "params": {},
    "params_list": [],
    "actual": [
      0,
      0,
      10,
      6,
      6,
      6,
      9,
      12,
      15,
      20
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Istanbul",
    "session": "Istanbul_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "mixed",
    "contribution_trajectory": [
      0,
      0,
      10,
      6,
      6,
      6,
      9,
      12,
      15,
      20
    ],
    "punishment_sent_trajectory": [
      0,
      0,
      0,
      0,
      6,
      3,
      3,
      6,
      4,
      12
    ],
    "punishment_received_trajectory": [
      5,
      3,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "total_voluntary_spend_trajectory": [
      0,
      0,
      10,
      6,
      12,
      9,
      12,
      18,
      19,
      32
    ],
    "others_mean_trajectory": [
      4.0,
      3.3333333333333335,
      3.0,
      5.666666666666667,
      4.666666666666667,
      5.0,
      6.0,
      7.666666666666667,
      13.333333333333334,
      15.0
    ],
    "mean_contribution": 8.4,
    "mean_punishment_sent": 3.4,
    "mean_punishment_received": 0.8,
    "mean_total_voluntary_spend": 11.8,
    "antisocial_punishment_total": 4,
    "prosocial_punishment_total": 30,
    "antisocial_ratio": 0.11764705882352941,
    "group_id": "4205"
  },
  "4219": {
    "params": {},
    "params_list": [],
    "actual": [
      0,
      5,
      5,
      5,
      5,
      5,
      6,
      9,
      10,
      20
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Istanbul",
    "session": "Istanbul_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "mixed",
    "contribution_trajectory": [
      0,
      5,
      5,
      5,
      5,
      5,
      6,
      9,
      10,
      20
    ],
    "punishment_sent_trajectory": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      2,
      0,
      4
    ],
    "punishment_received_trajectory": [
      4,
      0,
      0,
      0,
      2,
      1,
      2,
      3,
      3,
      3
    ],
    "total_voluntary_spend_trajectory": [
      0,
      5,
      5,
      5,
      5,
      5,
      6,
      11,
      10,
      24
    ],
    "others_mean_trajectory": [
      4.0,
      1.6666666666666667,
      4.666666666666667,
      6.0,
      5.0,
      5.333333333333333,
      7.0,
      8.666666666666666,
      15.0,
      15.0
    ],
    "mean_contribution": 7.0,
    "mean_punishment_sent": 0.6,
    "mean_punishment_received": 1.8,
    "mean_total_voluntary_spend": 7.6,
    "antisocial_punishment_total": 0,
    "prosocial_punishment_total": 6,
    "antisocial_ratio": 0.0,
    "group_id": "4205"
  },
  "4220": {
    "params": {},
    "params_list": [],
    "actual": [
      10,
      3,
      2,
      10,
      5,
      4,
      6,
      7,
      20,
      10
    ],
    "predicted": [],
    "rmse": 0.0,
    "method": "pending_v3_fit",
    "n_free": 0,
    "null_channels": [],
    "population": "Istanbul",
    "session": "Istanbul_P_S1",
    "knockout_active_channels": [],
    "knockout_null_channels": [],
    "active_channels": [],
    "gap_classification": "prosocial",
    "behavioral_profile": "mixed",
    "contribution_trajectory": [
      10,
      3,
      2,
      10,
      5,
      4,
      6,
      7,
      20,
      10
    ],
    "punishment_sent_trajectory": [
      3,
      1,
      0,
      1,
      0,
      0,
      0,
      1,
      0,
      0
    ],
    "punishment_received_trajectory": [
      1,
      0,
      0,
      0,
      2,
      2,
      2,
      4,
      0,
      9
    ],
    "total_voluntary_spend_trajectory": [
      13,
      4,
      2,
      11,
      5,
      4,
      6,
      8,
      20,
      10
    ],
    "others_mean_trajectory": [
      0.6666666666666666,
      2.3333333333333335,
      5.666666666666667,
      4.333333333333333,
      5.0,
      5.666666666666667,
      7.0,
      9.333333333333334,
      11.666666666666666,
      18.333333333333332
    ],
    "mean_contribution": 7.7,
    "mean_punishment_sent": 0.6,
    "mean_punishment_received": 2.0,
    "mean_total_voluntary_spend": 8.3,
    "antisocial_punishment_total": 1,
    "prosocial_punishment_total": 5,
    "antisocial_ratio": 0.16666666666666666,
    "group_id": "4205"
  }
}